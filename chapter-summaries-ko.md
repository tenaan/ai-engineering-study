# 챕터 요약

이 문서는 책에서 발췌한 각 챕터의 요약입니다. 일부 요약은 원본 챕터를 먼저 읽지 않은 독자에게는 이해하기 어려울 수 있지만, 이 책이 어떤 내용을 다루는지 감을 잡는 데 도움이 되길 바랍니다.

* [1장. 파운데이션 모델을 활용한 AI 애플리케이션 구축 입문](#1장-파운데이션-모델을-활용한-ai-애플리케이션-구축-입문)
* [2장. 파운데이션 모델 이해하기](#2장-파운데이션-모델-이해하기)
* [3장. 평가 방법론](#3장-평가-방법론)
* [4장. AI 시스템 평가](#4장-ai-시스템-평가)
* [5장. 프롬프트 엔지니어링](#5장-프롬프트-엔지니어링)
* [6장. RAG와 에이전트](#6장-rag와-에이전트)
* [7장. 파인튜닝](#7장-파인튜닝)
* [8장. 데이터셋 엔지니어링](#8장-데이터셋-엔지니어링)
* [9장. 추론 최적화](#9장-추론-최적화)
* [10장. AI 엔지니어링 아키텍처와 사용자 피드백](#10장-ai-엔지니어링-아키텍처와-사용자-피드백)

## 1장. 파운데이션 모델을 활용한 AI 애플리케이션 구축 입문
표 1-3. 소비자 및 기업용 애플리케이션에서의 일반적인 생성형 AI 사용 사례


| 카테고리 | 소비자 사용 사례 예시 | 기업 사용 사례 예시 |
|----------|----------------------|-------------------|
| 코딩 | 코딩 | 코딩 |
| 이미지 및 영상 제작 | 사진 및 영상 편집<br>디자인 | 프레젠테이션<br>광고 생성 |
| 글쓰기 | 이메일<br>소셜 미디어 및 블로그 포스트 | 카피라이팅<br>SEO<br>보고서, 메모, 설계 문서 |
| 교육 | 튜터링<br>에세이 채점 | 직원 온보딩<br>직원 역량 강화 교육 |
| 대화형 봇 | 범용 챗봇<br>AI 동반자 | 고객 지원<br>제품 코파일럿 |
| 정보 집계 | 요약<br>문서와 대화하기 | 요약<br>시장 조사 |
| 데이터 정리 | 이미지 검색<br>메멕스 | 지식 관리<br>문서 처리 |
| 워크플로우 자동화 | 여행 계획<br>이벤트 계획 | 데이터 추출, 입력, 주석<br>리드 생성 |
<br>

이 장은 두 가지 목적을 위해 작성되었습니다. 첫째는 파운데이션 모델의 가용성 덕분에 AI 엔지니어링이 하나의 학문 분야로 등장하게 된 배경을 설명하는 것입니다. 둘째는 이러한 모델 위에 애플리케이션을 구축하는 데 필요한 프로세스의 개요를 제공하는 것입니다. 이 장이 그 목표를 달성했기를 바랍니다. 개요 장으로서 많은 개념을 가볍게 다루었으며, 이러한 개념들은 책의 나머지 부분에서 더 자세히 탐구될 것입니다.

이 장에서는 최근 몇 년간 AI의 급격한 진화를 논의했습니다. 자기지도학습이라는 학습 방식 덕분에 언어 모델에서 대규모 언어 모델로의 전환을 시작으로 가장 주목할 만한 변화들을 살펴보았습니다. 그런 다음 언어 모델이 다른 데이터 양식을 통합하여 파운데이션 모델이 되고, 파운데이션 모델이 AI 엔지니어링의 탄생을 이끌어낸 과정을 추적했습니다.

AI 엔지니어링의 급속한 성장은 파운데이션 모델의 새로운 기능들이 가능하게 하는 수많은 애플리케이션에 의해 촉진되었습니다. 이 장에서는 소비자와 기업 모두를 위한 가장 성공적인 애플리케이션 패턴 중 일부를 논의했습니다. 이미 프로덕션에 있는 수많은 AI 애플리케이션에도 불구하고, 우리는 아직 AI 엔지니어링의 초기 단계에 있으며, 앞으로 구축될 무수히 많은 혁신이 남아 있습니다.

애플리케이션을 구축하기 전에, 종종 간과되지만 중요한 질문은 과연 그것을 구축해야 하는가입니다. 이 장에서는 이 질문과 함께 AI 애플리케이션 구축 시 주요 고려사항을 논의했습니다.

AI 엔지니어링은 새로운 용어이지만, 모든 ML 모델로 애플리케이션을 구축하는 것과 관련된 포괄적인 분야인 ML 엔지니어링에서 발전했습니다. ML 엔지니어링의 많은 원칙들이 여전히 AI 엔지니어링에 적용됩니다. 그러나 AI 엔지니어링은 새로운 도전과 해결책도 함께 가져옵니다. 이 장의 마지막 섹션에서는 ML 엔지니어링에서 어떻게 변화했는지를 포함하여 AI 엔지니어링 스택을 논의합니다.

글로 담기 특히 어려운 AI 엔지니어링의 한 측면은 커뮤니티가 가져오는 놀라운 양의 집단적 에너지, 창의성, 엔지니어링 재능입니다. 이러한 집단적 열정은 종종 압도적일 수 있는데, 끊임없이 발생하는 것처럼 보이는 새로운 기술, 발견, 엔지니어링 성과를 모두 따라잡는 것이 불가능하기 때문입니다.

한 가지 위안은 AI가 정보 집계에 뛰어나기 때문에 이러한 새로운 업데이트들을 집계하고 요약하는 데 도움을 줄 수 있다는 것입니다. 하지만 도구는 어느 정도까지만 도움이 됩니다. 분야가 압도적일수록 그것을 탐색하는 데 도움이 되는 프레임워크를 갖추는 것이 더욱 중요합니다. 이 책은 그러한 프레임워크를 제공하는 것을 목표로 합니다.

책의 나머지 부분에서는 AI 엔지니어링의 기본 구성 요소인 파운데이션 모델부터 시작하여 이 프레임워크를 단계별로 탐구할 것입니다. 파운데이션 모델은 수많은 놀라운 애플리케이션을 가능하게 합니다.

## 2장. 파운데이션 모델 이해하기
<center><img src="references/assets/rlhf.png" width="800"><br>
<i>사전학습, SFT, RLHF를 포함한 전체 학습 워크플로우. 이미지 출처: 저자의 <a href="https://huyenchip.com/2023/05/02/rlhf.html">RLHF 블로그 포스트</a> (2023년 5월)</i>
</center>
<br>

이 장에서는 파운데이션 모델을 구축할 때의 핵심 설계 결정들을 논의했습니다. 대부분의 사람들이 처음부터 모델을 학습시키는 대신 이미 만들어진 파운데이션 모델을 사용할 것이므로, 세부적인 학습 세부사항은 건너뛰고 어떤 모델을 사용할지, 어떻게 사용할지 결정하는 데 도움이 되는 모델링 요소에 집중했습니다.

모델의 성능에 영향을 미치는 중요한 요소는 학습 데이터입니다. 대규모 모델은 많은 양의 학습 데이터를 필요로 하며, 이를 획득하는 데 비용과 시간이 많이 들 수 있습니다. 따라서 모델 제공업체들은 종종 사용 가능한 모든 데이터를 활용합니다. 이로 인해 학습 데이터에 존재하는 많은 작업에서 잘 수행할 수 있는 모델이 만들어지지만, 이것이 여러분이 원하는 특정 작업을 포함하지 않을 수 있습니다. 이 장에서는 특정 언어, 특히 저자원 언어와 특정 도메인을 대상으로 하는 모델을 개발하기 위해 학습 데이터를 큐레이션하는 것이 왜 종종 필요한지 살펴보았습니다.

데이터를 확보한 후 모델 개발을 시작할 수 있습니다. 모델 학습이 종종 헤드라인을 장식하지만, 그 이전의 중요한 단계는 모델 아키텍처를 설계하는 것입니다. 이 장에서는 모델 아키텍처와 모델 크기와 같은 모델링 선택을 살펴보았습니다. 언어 기반 파운데이션 모델의 지배적인 아키텍처는 트랜스포머입니다. 이 장에서는 트랜스포머 아키텍처가 해결하도록 설계된 문제와 그 한계를 탐구했습니다.

모델의 규모는 파라미터 수, 학습 토큰 수, 학습에 필요한 FLOPs 수라는 세 가지 핵심 숫자로 측정할 수 있습니다. 모델 학습에 필요한 컴퓨팅 양에 영향을 미치는 두 가지 측면은 모델 크기와 데이터 크기입니다. 스케일링 법칙은 주어진 컴퓨팅 예산에서 최적의 파라미터 수와 토큰 수를 결정하는 데 도움을 줍니다. 이 장에서는 스케일링 병목현상도 살펴보았습니다. 지금까지 모델을 확장하면 일반적으로 더 좋아졌습니다. 하지만 이것이 언제까지 계속 사실일까요?

학습 데이터의 낮은 품질과 사전학습 중의 자기지도학습으로 인해, 결과 모델은 사용자가 원하는 것과 일치하지 않는 출력을 생성할 수 있습니다. 이것은 지도 파인튜닝과 선호도 파인튜닝의 두 단계로 구성된 후처리를 통해 해결됩니다. 인간의 선호도는 다양하고 단일 수학 공식으로 포착하기 불가능하므로, 기존 해결책은 완벽하지 않습니다.

이 장에서는 제가 가장 좋아하는 주제 중 하나인 샘플링도 다루었습니다. 샘플링은 모델이 출력 토큰을 생성하는 과정입니다. 샘플링은 AI 모델을 확률적으로 만듭니다. 이러한 확률적 특성이 ChatGPT와 Gemini 같은 모델을 창의적인 작업에 뛰어나게 만들고 대화하기 재미있게 만듭니다. 그러나 이러한 확률적 특성은 비일관성과 환각도 유발합니다.

AI 모델로 작업하려면 그들의 확률적 특성을 중심으로 워크플로우를 구축해야 합니다. 이 책의 나머지 부분에서는 AI 엔지니어링을 결정적이지는 않더라도 최소한 체계적으로 만드는 방법을 탐구할 것입니다. 체계적인 AI 엔지니어링을 향한 첫 번째 단계는 실패와 예상치 못한 변화를 감지하는 데 도움이 되는 견고한 평가 파이프라인을 구축하는 것입니다. 파운데이션 모델에 대한 평가는 매우 중요하기 때문에 다음 장부터 시작하여 두 개의 장을 할애했습니다.

## 3장. 평가 방법론
<center><img src="references/assets/ai-judge.png" width="600"><br>
<i>그림 3-8. 질문이 주어졌을 때 답변의 품질을 평가하는 AI 심사자의 예시.</i>
</center>
<br>

AI 모델이 강력해질수록 치명적인 실패의 가능성이 높아지며, 이는 평가를 더욱 중요하게 만듭니다. 동시에 개방형의 강력한 모델을 평가하는 것은 어렵습니다. 이러한 도전들로 인해 많은 팀들이 인간 평가로 전환하고 있습니다. 정신 건강 점검을 위해 사람을 루프에 포함시키는 것은 항상 도움이 되며, 많은 경우 인간 평가가 필수적입니다. 그러나 이 장에서는 자동 평가에 대한 다양한 접근 방식에 집중했습니다.

이 장은 왜 파운데이션 모델이 기존 ML 모델보다 평가하기 어려운지에 대한 논의로 시작합니다. 많은 새로운 평가 기법이 개발되고 있지만, 평가에 대한 투자는 여전히 모델 및 애플리케이션 개발에 대한 투자에 뒤처져 있습니다.

많은 파운데이션 모델이 언어 모델 구성요소를 가지고 있기 때문에, 퍼플렉시티와 크로스 엔트로피를 포함한 언어 모델링 지표를 자세히 살펴보았습니다. 제가 대화한 많은 사람들이 이러한 지표를 혼란스럽게 여기기 때문에, 이러한 지표를 해석하고 평가 및 데이터 처리에 활용하는 방법에 대한 섹션을 포함했습니다.

그런 다음 이 장은 기능적 정확성, 유사도 점수, AI-심사자를 포함하여 개방형 응답을 평가하는 다양한 접근 방식으로 초점을 전환했습니다. 처음 두 가지 평가 접근 방식은 정확한 반면, AI-심사자 평가는 주관적입니다.

정확한 평가와 달리 주관적 지표는 심사자에게 크게 의존합니다. 그들의 점수는 어떤 심사자가 사용되는지의 맥락에서 해석되어야 합니다. 서로 다른 AI 심사자가 동일한 품질을 측정하려는 점수는 비교할 수 없을 수 있습니다. AI 심사자는 모든 AI 애플리케이션과 마찬가지로 반복되어야 하며, 이는 그들의 판단이 변한다는 것을 의미합니다. 이것은 그들을 시간에 따른 애플리케이션 변화를 추적하기 위한 벤치마크로서 신뢰할 수 없게 만듭니다. 유망하지만, AI 심사자는 정확한 평가, 인간 평가, 또는 둘 다로 보완되어야 합니다.

모델을 평가할 때, 각 모델을 독립적으로 평가한 다음 점수별로 순위를 매길 수 있습니다. 또는 비교 신호를 사용하여 순위를 매길 수 있습니다: 두 모델 중 어느 것이 더 나은가? 비교 평가는 스포츠, 특히 체스에서 일반적이며, AI 평가에서도 주목받고 있습니다. 비교 평가와 후처리 정렬 프로세스 모두 수집 비용이 많이 드는 선호도 신호가 필요합니다. 이것이 선호도 모델의 개발을 촉진했습니다: 사용자가 어떤 응답을 선호하는지 예측하는 전문 AI 심사자입니다.

언어 모델링 지표와 수작업으로 설계된 유사도 측정은 한동안 존재해왔지만, AI-심사자와 비교 평가는 파운데이션 모델의 등장과 함께 채택되기 시작했습니다. 많은 팀들이 이것들을 평가 파이프라인에 통합하는 방법을 찾고 있습니다. 개방형 애플리케이션을 평가하기 위한 신뢰할 수 있는 평가 파이프라인을 구축하는 방법을 알아내는 것이 다음 장의 주제입니다.

## 4장. AI 시스템 평가
<center><img src="references/assets/evaluation-process.png" width="600"><br>
<i>그림 4-5. 애플리케이션에 맞는 모델을 평가하기 위한 평가 워크플로우 개요.</i>
</center>
<br>

이것은 AI에 관해 제가 작성한 것 중 가장 어렵지만 가장 중요한 주제 중 하나라고 생각합니다. 신뢰할 수 있는 평가 파이프라인이 없는 것은 AI 도입의 가장 큰 장애물 중 하나입니다. 평가에는 시간이 걸리지만, 신뢰할 수 있는 평가 파이프라인은 위험을 줄이고, 성능 개선 기회를 발견하며, 진행 상황을 벤치마킹할 수 있게 해주어 궁극적으로 시간과 골치 아픈 일을 절약해줄 것입니다.

점점 더 많은 파운데이션 모델이 쉽게 사용 가능해지면서, 대부분의 애플리케이션 개발자에게 도전은 더 이상 모델 개발이 아니라 애플리케이션에 적합한 모델을 선택하는 것입니다. 이 장에서는 애플리케이션용 모델을 평가하는 데 자주 사용되는 기준 목록과 그 평가 방법을 논의했습니다. 사실적 일관성과 안전성을 포함하여 도메인별 능력과 생성 능력을 평가하는 방법을 논의했습니다. 파운데이션 모델을 평가하는 많은 기준은 유창성, 일관성, 충실성을 포함하여 전통적인 NLP에서 발전했습니다.

모델을 호스팅할지 모델 API를 사용할지에 대한 질문에 답하기 위해, 이 장에서는 데이터 프라이버시, 데이터 계보, 성능, 기능, 제어, 비용을 포함한 일곱 가지 축을 따라 각 접근 방식의 장단점을 설명했습니다. 이 결정은 모든 구축 대 구매 결정과 마찬가지로 팀이 필요로 하는 것뿐만 아니라 팀이 원하는 것에 따라 각 팀마다 고유합니다.

이 장에서는 수천 개의 사용 가능한 공개 벤치마크도 탐구했습니다. 공개 벤치마크는 나쁜 모델을 걸러내는 데 도움이 될 수 있지만, 애플리케이션에 가장 적합한 모델을 찾는 데는 도움이 되지 않습니다. 공개 벤치마크는 또한 오염되었을 가능성이 높은데, 그 데이터가 많은 모델의 학습 데이터에 포함되어 있기 때문입니다. 여러 벤치마크를 집계하여 모델 순위를 매기는 공개 리더보드가 있지만, 벤치마크가 어떻게 선택되고 집계되는지는 명확한 프로세스가 아닙니다. 공개 리더보드에서 배운 교훈은 모델 선택에 도움이 되는데, 모델 선택은 필요에 따라 모델 순위를 매기는 비공개 리더보드를 만드는 것과 유사하기 때문입니다.

이 장은 지난 장에서 논의한 모든 평가 기법과 기준을 사용하는 방법과 애플리케이션을 위한 평가 파이프라인을 만드는 방법으로 마무리됩니다. 완벽한 평가 방법은 존재하지 않습니다. 고차원 시스템의 능력을 하나 또는 몇 개의 차원 점수로 포착하는 것은 불가능합니다. 현대 AI 시스템 평가와 관련된 많은 한계와 편향이 있습니다. 그러나 이것이 평가를 하지 말아야 한다는 의미는 아닙니다. 다양한 방법과 접근 방식을 결합하면 이러한 도전의 많은 부분을 완화하는 데 도움이 될 수 있습니다.

평가에 대한 전용 논의는 여기서 끝나지만, 평가는 책 전체에서뿐만 아니라 애플리케이션 개발 과정 전체에서 계속해서 등장할 것입니다. 6장에서는 검색 및 에이전트 시스템 평가를 탐구하고, 7장과 9장에서는 모델의 메모리 사용량, 지연 시간, 비용 계산에 집중합니다. 데이터 품질 검증은 8장에서, 프로덕션 애플리케이션 평가를 위한 사용자 피드백 활용은 10장에서 다룹니다.

이제 많은 사람들이 AI 엔지니어링과 연관짓는 주제인 프롬프트 엔지니어링부터 시작하여 실제 모델 적응 과정으로 넘어가겠습니다.

## 5장. 프롬프트 엔지니어링
<center><img src="references/assets/prompt-anatomy.png" width="600"><br>
<i>그림 5-1. 프롬프트의 구조를 보여주는 간단한 예시.</i>
</center>
<br>

파운데이션 모델은 많은 것을 할 수 있지만, 정확히 무엇을 원하는지 말해주어야 합니다. 모델이 원하는 것을 하도록 지시를 만드는 과정을 프롬프트 엔지니어링이라고 합니다. 얼마나 많은 작업이 필요한지는 모델이 프롬프트에 얼마나 민감한지에 따라 달라집니다. 작은 변화가 모델의 응답에 큰 변화를 일으킬 수 있다면, 더 많은 작업이 필요합니다.

프롬프트 엔지니어링을 인간-AI 커뮤니케이션으로 생각할 수 있습니다. 누구나 소통할 수 있지만, 모두가 잘 소통하는 것은 아닙니다. 프롬프트 엔지니어링은 시작하기 쉬워서 많은 사람들이 잘하기도 쉽다고 오해합니다.

이 장의 첫 번째 부분은 프롬프트의 구조, 인컨텍스트 학습이 왜 작동하는지, 최선의 프롬프트 엔지니어링 관행을 논의합니다. AI와 소통하든 다른 인간과 소통하든, 예시와 관련 정보가 포함된 명확한 지시가 필수적입니다. 모델에게 천천히 단계별로 생각하라고 요청하는 것과 같은 간단한 트릭이 놀라운 개선을 가져올 수 있습니다. 인간과 마찬가지로, AI 모델에도 생산적인 관계를 위해 고려해야 할 고유한 특성과 편향이 있습니다.

파운데이션 모델은 지시를 따를 수 있기 때문에 유용합니다. 그러나 이 능력은 악의적인 행위자가 모델에게 악의적인 지시를 따르도록 하는 프롬프트 공격에도 취약하게 만듭니다. 이 장에서는 다양한 공격 접근 방식과 그에 대한 잠재적 방어를 논의합니다. 보안은 끊임없이 진화하는 고양이와 쥐의 게임이므로, 어떤 보안 조치도 완벽하지 않습니다. 보안 위험은 고위험 환경에서 AI 도입에 상당한 장애물로 남을 것입니다.

이 장에서는 또한 모델이 원하는 것을 하도록 더 나은 지시를 작성하는 기법을 논의합니다. 그러나 작업을 수행하려면 모델에게 지시뿐만 아니라 관련 컨텍스트도 필요합니다. 모델에게 관련 정보를 제공하는 방법은 다음 장에서 논의할 것입니다.

## 6장. RAG와 에이전트
<center><img src="references/assets/rag-architecture.png" width="700"><br>
<i>그림 6-3. 임베딩 기반 또는 의미 기반 검색기가 작동하는 방식의 고수준 뷰.</i>
</center>
<br>

RAG의 인기와 에이전트의 잠재력을 고려할 때, 초기 독자들은 이 장이 가장 기대되는 장이라고 언급했습니다.

이 장은 둘 중 먼저 등장한 패턴인 RAG로 시작했습니다. 많은 작업은 종종 모델의 컨텍스트 윈도우를 초과하는 광범위한 배경 지식을 필요로 합니다. 예를 들어, 코드 코파일럿은 전체 코드베이스에 접근해야 할 수 있고, 연구 보조원은 여러 책을 분석해야 할 수 있습니다. 원래 모델의 컨텍스트 제한을 극복하기 위해 개발된 RAG는 또한 정보의 더 효율적인 사용을 가능하게 하여, 비용을 줄이면서 응답 품질을 향상시킵니다. 파운데이션 모델의 초기부터 RAG 패턴이 광범위한 애플리케이션에 매우 가치있을 것이 분명했고, 이후 소비자와 기업 사용 사례 모두에서 빠르게 채택되었습니다.

RAG는 두 단계 프로세스를 사용합니다. 먼저 외부 메모리에서 관련 정보를 검색한 다음 이 정보를 사용하여 더 정확한 응답을 생성합니다. RAG 시스템의 성공은 검색기의 품질에 달려 있습니다. 엘라스틱서치와 BM25와 같은 용어 기반 검색기는 구현하기 훨씬 가벼우며 강력한 기준선을 제공할 수 있습니다. 임베딩 기반 검색기는 계산 집약적이지만 용어 기반 알고리즘을 능가할 잠재력이 있습니다.

임베딩 기반 검색은 벡터 검색에 의해 구동되며, 이는 검색 및 추천 시스템과 같은 많은 핵심 인터넷 애플리케이션의 백본이기도 합니다. 이러한 애플리케이션을 위해 개발된 많은 벡터 검색 알고리즘을 RAG에 사용할 수 있습니다.

RAG 패턴은 검색기가 모델이 사용할 수 있는 도구인 에이전트의 특수한 경우로 볼 수 있습니다. 두 패턴 모두 모델이 컨텍스트 제한을 우회하고 더 최신 상태를 유지할 수 있게 해주지만, 에이전트 패턴은 그 이상의 것을 할 수 있습니다. 에이전트는 환경과 접근할 수 있는 도구에 의해 정의됩니다. AI 기반 에이전트에서 AI는 주어진 작업을 분석하고, 다양한 해결책을 고려하며, 가장 유망한 것을 선택하는 계획자입니다. 복잡한 작업은 해결하기 위해 많은 단계가 필요할 수 있으며, 이는 계획을 세우기 위해 강력한 모델을 필요로 합니다. 모델의 계획 능력은 진행 상황을 추적하는 데 도움이 되는 성찰과 메모리 시스템으로 강화될 수 있습니다.

모델에게 더 많은 도구를 제공할수록 모델의 능력이 향상되어 더 도전적인 작업을 해결할 수 있습니다. 그러나 에이전트가 더 자동화될수록 실패는 더 치명적입니다. 도구 사용은 에이전트를 5장에서 논의한 많은 보안 위험에 노출시킵니다. 에이전트가 현실 세계에서 작동하려면 엄격한 방어 메커니즘이 마련되어야 합니다.

RAG와 에이전트 모두 많은 정보를 다루며, 이는 종종 기본 모델의 최대 컨텍스트 길이를 초과합니다. 이것은 모델이 가진 모든 정보를 관리하고 사용하기 위한 메모리 시스템의 도입을 필요로 합니다. 이 장은 이 구성요소가 어떻게 생겼는지에 대한 짧은 논의로 마무리되었습니다.

RAG와 에이전트는 모두 모델 자체를 수정하지 않고 입력만을 통해 모델의 품질에 영향을 미치는 프롬프트 기반 방법입니다. 이들은 많은 놀라운 애플리케이션을 가능하게 할 수 있지만, 기본 모델을 수정하면 더 많은 가능성이 열릴 수 있습니다. 이를 어떻게 하는지는 다음 장의 주제가 될 것입니다.

## 7장. 파인튜닝
<center><img src="references/assets/rag-vs-finetune.png" width="700"><br>
<i>그림 7-3. 애플리케이션 개발 흐름 예시. 간단한 검색(예: 용어 기반 검색) 후, 더 복잡한 검색(예: 하이브리드 검색)을 실험할지 파인튜닝을 할지는 각 애플리케이션과 그 실패 모드에 따라 달라집니다.</i>
</center>
<br>

평가 장을 제외하고 파인튜닝은 작성하기 가장 어려운 장이었습니다. 전이학습(오래된 개념)과 PEFT(새로운 개념), 기본적인(저랭크 분해) 것과 실험적인(모델 병합) 것, 수학적인(메모리 계산) 것과 전술적인(하이퍼파라미터 튜닝) 것을 포함한 광범위한 개념을 다루었습니다. 이 모든 다양한 측면을 접근 가능하게 유지하면서 일관된 구조로 배열하는 것은 어려웠습니다.

파인튜닝 과정 자체는 어렵지 않습니다. 많은 파인튜닝 프레임워크가 학습 과정을 처리해줍니다. 이러한 프레임워크는 합리적인 기본 하이퍼파라미터와 함께 일반적인 파인튜닝 방법을 제안할 수도 있습니다.

그러나 파인튜닝을 둘러싼 맥락은 복잡합니다. 모델을 파인튜닝해야 하는지 여부부터 시작됩니다. 이 장은 파인튜닝을 하는 이유와 하지 않는 이유로 시작했습니다. 또한 제가 많이 받은 질문 중 하나인 언제 파인튜닝을 하고 언제 RAG를 해야 하는지도 논의했습니다.

초기에 파인튜닝은 사전학습과 유사했습니다—둘 다 모델의 전체 가중치를 업데이트하는 것을 포함했습니다. 그러나 모델 크기가 증가함에 따라 전체 파인튜닝은 대부분의 실무자에게 비현실적이 되었습니다. 파인튜닝 중 업데이트할 파라미터가 많을수록 파인튜닝에 더 많은 메모리가 필요합니다. 대부분의 실무자는 파운데이션 모델로 전체 파인튜닝을 수행할 충분한 리소스(하드웨어, 시간, 데이터)에 접근할 수 없습니다.

많은 파인튜닝 기법이 같은 동기로 개발되었습니다: 최소한의 메모리 사용량으로 강력한 성능을 달성하는 것입니다. 예를 들어, PEFT는 학습 가능한 파라미터 수를 줄여 파인튜닝의 메모리 요구 사항을 줄입니다. 반면 양자화 학습은 각 값을 표현하는 데 필요한 비트 수를 줄여 이 메모리 병목현상을 완화합니다.

PEFT의 개요를 제공한 후, 이 장은 LoRA—왜 작동하고 어떻게 작동하는지—를 자세히 살펴보았습니다. LoRA는 실무자들 사이에서 인기를 끄는 많은 특성을 가지고 있습니다. 파라미터 효율적이고 데이터 효율적일 뿐만 아니라 모듈식이어서 여러 LoRA 모델을 서빙하고 결합하기가 훨씬 쉽습니다.

파인튜닝된 모델을 결합하는 아이디어는 이 장을 모델 병합으로 이끌었습니다. 모델 병합의 목표는 여러 모델을 별도로 사용하는 것보다 더 잘 작동하는 하나의 모델로 결합하는 것입니다. 이 장에서는 온디바이스 배포부터 모델 업스케일링까지 모델 병합의 많은 사용 사례와 모델 병합에 대한 일반적인 접근 방식을 논의했습니다.

실무자들로부터 자주 듣는 말은 파인튜닝은 쉽지만 파인튜닝을 위한 데이터를 얻는 것은 어렵다는 것입니다. 고품질 주석 데이터, 특히 지시 데이터를 얻는 것은 어렵습니다. 다음 장에서 이러한 도전에 대해 자세히 살펴볼 것입니다.

## 8장. 데이터셋 엔지니어링
<center><img src="references/assets/model-perf-dataset.png" width="600"><br>
<i>그림 8-3. 다양한 데이터셋 크기에 따른 성능 향상 곡선은 추가 학습 예제가 모델 성능에 미치는 영향을 추정하는 데 도움이 됩니다.</i>
</center>
<br>

학습 데이터를 만드는 실제 과정은 매우 복잡하지만, 데이터셋을 만드는 원칙은 놀랍도록 간단합니다. 모델을 학습시키기 위한 데이터셋을 구축하려면, 모델이 배우길 원하는 행동을 먼저 생각한 다음 이러한 행동을 보여주는 데이터셋을 설계합니다. 데이터의 중요성으로 인해, 팀들은 프라이버시와 규정 준수를 보장하면서 적절한 데이터셋을 획득하는 책임을 맡은 전담 데이터 역할을 도입하고 있습니다.

어떤 데이터가 필요한지는 사용 사례뿐만 아니라 학습 단계에 따라서도 달라집니다. 사전학습은 지시 파인튜닝 및 선호도 파인튜닝과 다른 데이터가 필요합니다. 그러나 학습 단계 전반에 걸친 데이터셋 설계는 품질, 커버리지, 수량이라는 동일한 세 가지 핵심 기준을 공유합니다.

모델이 얼마나 많은 데이터로 학습되는지가 헤드라인을 장식해왔지만, 충분한 커버리지를 가진 고품질 데이터를 갖는 것도 그만큼 중요합니다. 소량의 고품질 데이터는 대량의 노이즈가 있는 데이터를 능가할 수 있습니다. 마찬가지로, 많은 팀들이 데이터셋의 다양성을 높이는 것이 모델 성능을 향상시키는 핵심이라는 것을 발견했습니다.

고품질 데이터를 획득하는 어려움으로 인해, 많은 팀들이 합성 데이터로 전환했습니다. 프로그래밍 방식으로 데이터를 생성하는 것은 오랜 목표였지만, AI가 현실적이고 복잡한 데이터를 생성할 수 있게 된 후에야 합성 데이터가 더 많은 사용 사례에 실용적인 해결책이 되었습니다. 이 장에서는 파인튜닝을 위한 지시 데이터 합성에 대한 심층 분석과 함께 데이터 합성을 위한 다양한 기법을 논의했습니다.

실제 데이터와 마찬가지로, 합성 데이터도 모델 학습에 사용되기 전에 품질을 보장하기 위해 평가되어야 합니다. AI가 생성한 데이터를 평가하는 것은 다른 AI 출력을 평가하는 것만큼 까다로우며, 사람들은 신뢰할 수 있게 평가할 수 있는 생성 데이터를 사용할 가능성이 더 높습니다.

데이터가 어려운 이유는 데이터셋 생성의 많은 단계가 쉽게 자동화되지 않기 때문입니다. 데이터에 주석을 다는 것은 어렵지만, 주석 가이드라인을 만드는 것은 더 어렵습니다. 데이터 생성을 자동화하는 것은 어렵지만, 그것을 검증하는 것을 자동화하는 것은 더 어렵습니다. 데이터 합성이 더 많은 데이터를 생성하는 데 도움이 되지만, 어떤 데이터를 원하는지 생각하는 것은 자동화할 수 없습니다. 주석 가이드라인은 쉽게 자동화할 수 없습니다. 세부 사항에 주의를 기울이는 것은 자동화할 수 없습니다.

어려운 문제는 창의적인 해결책으로 이어집니다. 이 장을 위한 조사를 하면서 눈에 띈 한 가지는 데이터셋 설계에 얼마나 많은 창의성이 관여하는지입니다. 사람들이 데이터를 구성하고 평가하는 방법은 매우 다양합니다. 이 장에서 논의한 다양한 데이터 합성 및 검증 기법이 데이터셋을 설계하는 방법에 대한 영감을 줄 수 있기를 바랍니다.

놀라운 모델을 학습시킬 수 있는 훌륭한 데이터셋을 큐레이션했다고 가정하면, 이 모델을 어떻게 서빙해야 할까요? 다음 장에서는 지연 시간과 비용을 위한 추론 최적화 방법을 논의할 것입니다.

## 9장. 추론 최적화
<center><img src="references/assets/inference-service.png" width="500"><br>
<i>그림 9-1. 간단한 추론 서비스.</i>
</center>
<br>

모델의 유용성은 추론 비용과 지연 시간에 크게 달려 있습니다. 더 저렴한 추론은 AI 기반 의사결정을 더 저렴하게 만들고, 더 빠른 추론은 AI를 더 많은 애플리케이션에 통합할 수 있게 합니다. 추론 최적화의 막대한 잠재적 영향을 고려할 때, 이는 혁신적인 접근 방식을 지속적으로 제시하는 놀라운 수의 재능 있는 개인들을 끌어들였습니다.

무언가를 더 효율적으로 만들기 시작하기 전에, 효율성이 어떻게 측정되는지 이해하는 것이 필요합니다. 이 장은 지연 시간, 처리량, 활용률에 대한 일반적인 효율성 지표로 시작했습니다. 언어 모델 기반 추론의 경우, 지연 시간은 프리필링 단계의 영향을 받는 **첫 번째 토큰까지의 시간**(TTFT)과 디코딩 단계의 영향을 받는 **출력 토큰당 시간**(TPOT)으로 나눌 수 있습니다. 처리량 지표는 비용과 직접적으로 관련됩니다. 지연 시간과 처리량 사이에는 트레이드오프가 있습니다. 증가된 지연 시간을 감수한다면 잠재적으로 비용을 줄일 수 있고, 지연 시간을 줄이는 것은 종종 비용 증가를 수반합니다.

모델이 얼마나 효율적으로 실행될 수 있는지는 실행되는 하드웨어에 따라 달라집니다. 이러한 이유로, 이 장에서는 AI 하드웨어에 대한 간략한 개요와 다양한 가속기에서 모델을 최적화하는 데 필요한 것들도 제공했습니다.

그런 다음 이 장은 추론 최적화를 위한 다양한 기법으로 계속되었습니다. 모델 API의 가용성을 고려할 때, 대부분의 애플리케이션 개발자는 이러한 기법을 직접 구현하는 대신 내장된 최적화가 있는 이러한 API를 사용할 것입니다. 이러한 기법이 모든 애플리케이션 개발자에게 관련이 없을 수 있지만, 어떤 기법이 가능한지 이해하는 것이 모델 API의 효율성을 평가하는 데 도움이 될 수 있다고 믿습니다.

이 장에서는 모델 수준과 추론 서비스 수준의 최적화에 집중했습니다. 모델 수준 최적화는 종종 모델 자체를 변경해야 하며, 이는 모델 행동의 변화로 이어질 수 있습니다. 반면 추론 서비스 수준 최적화는 일반적으로 모델을 그대로 유지하고 서빙 방법만 변경합니다.

모델 수준 기법에는 양자화와 지식 증류와 같은 모델에 구애받지 않는 기법이 포함됩니다. 다른 모델 아키텍처는 각자의 최적화가 필요합니다. 예를 들어, 트랜스포머 모델의 주요 병목현상이 어텐션 메커니즘에 있기 때문에, KV 캐시 관리와 어텐션 커널 작성을 포함하여 어텐션을 더 효율적으로 만드는 많은 최적화 기법이 있습니다. 자기회귀 언어 모델의 큰 병목현상은 자기회귀 디코딩 프로세스에 있으며, 결과적으로 이를 해결하기 위한 많은 기법도 개발되었습니다.

추론 서비스 수준 기법에는 다양한 배칭 및 병렬 처리 전략이 포함됩니다. 프리필링/디코딩 분리와 프롬프트 캐싱을 포함하여 자기회귀 언어 모델을 위해 특별히 개발된 기법도 있습니다.

최적화 기법의 선택은 워크로드에 따라 달라집니다. 예를 들어, KV 캐싱은 짧은 컨텍스트보다 긴 컨텍스트를 가진 워크로드에서 훨씬 더 중요합니다. 반면 프롬프트 캐싱은 긴 중복 프롬프트 세그먼트나 다중 턴 대화를 포함하는 워크로드에 중요합니다. 선택은 또한 성능 요구 사항에 따라 달라집니다. 예를 들어, 낮은 지연 시간이 비용보다 높은 우선순위라면, 레플리카 병렬 처리를 확장할 수 있습니다. 더 많은 레플리카는 추가 머신이 필요하지만, 각 머신은 더 적은 요청을 처리하여 요청당 더 많은 리소스를 할당할 수 있으므로 응답 시간을 개선할 수 있습니다.

그러나 다양한 사용 사례에서 가장 영향력 있는 기법은 일반적으로 양자화(일반적으로 모델 전반에 걸쳐 잘 작동함), 텐서 병렬 처리(지연 시간을 줄이고 더 큰 모델 서빙을 가능하게 함), 레플리카 병렬 처리(구현하기 비교적 간단함), 어텐션 메커니즘 최적화(트랜스포머 모델을 크게 가속화할 수 있음)입니다.

추론 최적화는 이 책에서 다루는 모델 적응 기법 목록을 마무리합니다. 다음 장에서는 이러한 기법을 일관된 시스템으로 통합하는 방법을 탐구할 것입니다.

## 10장. AI 엔지니어링 아키텍처와 사용자 피드백
<center><img src="references/assets/aie-architecture.png" width="800"><br>
<i>그림 10-10. 일반적인 생성형 AI 애플리케이션 아키텍처.</i>
</center>
<br>
각 이전 장이 AI 엔지니어링의 특정 측면에 집중했다면, 이 장은 파운데이션 모델 위에 애플리케이션을 구축하는 과정 전체를 살펴보았습니다.

이 장은 두 부분으로 구성되었습니다. 첫 번째 부분은 AI 애플리케이션의 일반적인 아키텍처를 논의했습니다. 애플리케이션의 정확한 아키텍처는 다를 수 있지만, 이 고수준 아키텍처는 다양한 구성요소가 어떻게 함께 맞물리는지 이해하기 위한 프레임워크를 제공합니다. 이 아키텍처를 구축하는 단계별 접근 방식을 사용하여 각 단계의 도전과 이를 해결하기 위해 사용할 수 있는 기법을 논의했습니다.

시스템을 모듈화하고 유지 관리 가능하게 유지하기 위해 구성요소를 분리하는 것이 필요하지만, 이 분리는 유동적입니다. 구성요소들이 기능에서 겹치는 많은 방법이 있습니다. 예를 들어, 가드레일은 추론 서비스, 모델 게이트웨이, 또는 독립 구성요소로 구현될 수 있습니다.

각 추가 구성요소는 잠재적으로 시스템을 더 capable하고, 더 안전하고, 더 빠르게 만들 수 있지만, 시스템의 복잡성도 증가시켜 새로운 실패 모드에 노출됩니다. 복잡한 시스템의 필수적인 부분 중 하나는 모니터링과 관측 가능성입니다. 관측 가능성은 시스템이 어떻게 실패하는지 이해하고, 실패 주변에 지표와 알림을 설계하며, 이러한 실패가 감지되고 추적 가능하도록 시스템을 설계하는 것을 포함합니다. 소프트웨어 엔지니어링과 전통적인 머신러닝의 많은 관측 가능성 모범 사례와 도구가 AI 엔지니어링 애플리케이션에 적용 가능하지만, 파운데이션 모델은 새로운 실패 모드를 도입하며, 이는 추가적인 지표와 설계 고려사항을 필요로 합니다.

동시에, 대화형 인터페이스는 새로운 유형의 사용자 피드백을 가능하게 하며, 이를 분석, 제품 개선, 데이터 플라이휠에 활용할 수 있습니다. 이 장의 두 번째 부분에서는 다양한 형태의 대화형 피드백과 이를 효과적으로 수집하기 위해 애플리케이션을 설계하는 방법을 논의했습니다.

전통적으로 사용자 피드백 설계는 엔지니어링보다는 제품 책임으로 여겨져 왔으며, 결과적으로 엔지니어들에 의해 종종 간과되어 왔습니다. 그러나 사용자 피드백이 AI 모델을 지속적으로 개선하기 위한 중요한 데이터 소스이기 때문에, 더 많은 AI 엔지니어들이 필요한 데이터를 받을 수 있도록 이 과정에 참여하고 있습니다. 이것은 전통적인 ML 엔지니어링과 비교하여 AI 엔지니어링이 제품에 더 가까워지고 있다는 1장의 아이디어를 강화합니다. 이것은 데이터 플라이휠과 제품 경험의 경쟁 우위로서의 중요성이 증가하기 때문입니다.

많은 AI 도전은 본질적으로 시스템 문제입니다. 이를 해결하기 위해서는 종종 한 발 물러서서 시스템 전체를 고려하는 것이 필요합니다. 단일 문제는 독립적으로 작동하는 다른 구성요소에 의해 해결될 수 있거나, 해결책이 여러 구성요소의 협력을 필요로 할 수 있습니다. 시스템에 대한 철저한 이해는 실제 문제를 해결하고, 새로운 가능성을 열고, 안전을 보장하는 데 필수적입니다.
