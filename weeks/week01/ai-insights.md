# Week 01 - AI Engineering 인사이트

각 팀원이 작성한 study-note를 바탕으로 개인별 인사이트와 학습 내용을 정리합니다.

---

## 김성언 (Kim Seong-Eon)

### 핵심 인사이트
- **자기 지도 학습(Self-supervised Learning)**이 LLM 성장의 핵심 동력: 데이터 레이블링 병목 현상을 극복하여 대규모 데이터셋 구축이 가능해졌고, 이것이 언어 모델을 대규모 언어 모델로 확장시킬 수 있었던 결정적 요인
- **AI 엔지니어링 스택의 3계층 구조**: 애플리케이션 개발(프롬프트 엔지니어링, 평가, 인터페이스) → 모델 개발(모델링/학습, 데이터셋 엔지니어링, 추론 최적화) → 인프라(모델 서빙, 컴퓨팅 관리, 모니터링)
- **AI 엔지니어링 vs ML 엔지니어링**: AI 엔지니어링은 모델의 직접 학습보다 **조정(프롬프트 엔지니어링, 파인튜닝)**에 중점을 두고, 더 크고 자원 소모가 많은 모델을 다루며, **개방형 출력**을 평가해야 한다는 차이점

### 독특한 관점 또는 흥미로운 발견
- **내부 배포와 폐쇄망 환경의 비즈니스 전략**: "내부 배포와 폐쇄망 환경을 통해 모델 파인튜닝을 진행하거나 하드웨어를 판매하는 비즈니스 모델을 함께 활용하는 것이 수익화에 좀 더 유리할 것"이라는 실용적 관점 제시
- **Face ID의 동적 업데이트에 대한 호기심**: "FaceID가 동적이라고 하면 사용자가 나이가 듦(10살→20살)에 따라 점차 업데이트를 진행하는 것일까?"라는 질문을 통해 동적 모델의 작동 방식을 깊이 탐구
- **학습 단계별 비용 구조 이해**: 사전학습(컴퓨팅 비용 98% 이상) → 파인튜닝(적은 자원) → 사후학습의 비용 차이를 명확히 구분

### 실무 적용 아이디어
- **모델 조정 기법 선택 기준**: 프롬프트 기반 기법(가중치 업데이트 X, 데이터 거의 불필요) vs 파인튜닝(가중치 업데이트 O, 품질/지연시간/비용 개선 가능) 중 프로젝트 요구사항에 따라 선택
- **AI 제품의 방어 가능성 고려**: PDF 파싱 애플리케이션처럼 파운데이션 모델 성능 향상으로 쓸모없어질 수 있는 제품을 피하고, 기술력/데이터/유통력 중심의 경쟁 우위 구축
- **Human-in-the-loop 전략**: MS의 크롤(사람 필수) → 워크(내부 직원과 상호작용) → 런(외부 사용자 직접 상호작용)으로 점진적 자동화

### 추가 학습이 필요한 부분
- 사전학습/파인튜닝/사후학습의 구체적인 비용 구조와 ROI 분석 방법
- 추론 최적화 기법(모델 압축, 양자화, 캐싱 등)의 실전 적용 사례
- 개방형 출력 평가를 위한 구체적인 지표 설계 방법론


---

## 안태현 (Ahn Tae-Hyun)

### 핵심 인사이트
- **파운데이션 모델의 멀티모달 능력**: 언어 모델이 텍스트뿐만 아니라 이미지, 동영상, 3D 에셋 등 다양한 데이터 형태를 처리할 수 있게 진화하면서 AI 연구의 전통적인 구조(NLP, CV 분리)에 획기적인 변화를 가져옴
- **AI 엔지니어링 빠른 성장의 3요인**: ① 범용 AI 능력(다양한 작업 수행 가능), ② AI 투자 증가(S&P 500 기업의 AI 언급 급증), ③ 낮아진 진입 장벽(MaaS, 오픈소스 도구 증가)
- **토큰화의 3가지 장점**: ① 단어를 의미 있는 구성 요소로 분리('요리하기'→'요리'+'하기'), ② 어휘 크기 감소로 효율성 향상, ③ 알려지지 않은 단어 처리 용이('chatgpting'→'chatgpt'+'-ing')

### 독특한 관점 또는 흥미로운 발견
- **CLIP의 자연어 지도(Natural Language Supervision)**: 각 이미지에 대한 레이블을 수동으로 생성하는 대신 인터넷에서 (이미지, 텍스트) 쌍을 수집하여 ImageNet보다 400배 큰 4억 개의 데이터셋을 생성. 이를 통해 추가 학습 없이도 여러 이미지 분류 작업 일반화
- **AI 제품의 방어 가능성(Defensibility)**: 경쟁 우위를 ① 기술력, ② 데이터, ③ 유통력으로 명확히 구분하고, 파운데이션 모델 성능 향상으로 제공 계층이 모델에 흡수될 위험 강조
- **크롤-워크-런(Crawl-Walk-Run) 프레임워크**: MS가 제안한 AI 자동화 점진적 증가 전략 - 크롤(사람 참여 필수) → 워크(AI와 내부 직원 상호작용) → 런(외부 사용자 직접 상호작용)

### 실무 적용 아이디어
- **AI 활용 사례별 적합성 평가**: 코딩(백엔드<프론트엔드), 글쓰기(위험부담 낮음), 교육(개인화), 데이터 체계화(비정형→정형 변환) 등 각 도메인별 AI 성능 차이를 고려한 전략적 접근
- **AI 역할 구분에 따른 설계**: 핵심적(정확성↑) vs 보완적, 반응형(지연시간↓) vs 선제형(품질↑), 동적(지속 업데이트) vs 정적(주기적 업데이트)에 따라 요구사항 차별화
- **마일스톤 계획 시 현실적 기대치**: 초기 데모가 좋아도 실제 제품 개발에는 몇 달~몇 년 소요될 수 있음을 인지하고, 목표 성능 달성에 필요한 자원이 예상 수익보다 클 수 있음을 사전 평가

### 추가 학습이 필요한 부분
- 마스크 언어 모델 vs 자기회귀 언어 모델의 실제 활용 사례 및 선택 기준
- 멀티모달 모델(GPT-4V, Gemini) 구현 시 텍스트-이미지 임베딩 통합 기술
- TTFT(Time To First Token), TPOT(Tokens Per Output Time) 등 지연 시간 지표의 측정 및 최적화 방법


---

## 이은정 (Lee Eun-Jeong)

### 핵심 인사이트
- **토큰화의 필요성과 효율성**: 토큰을 사용하는 3가지 이유 - ① 의미 있는 구성 요소 분리, ② 고유 토큰 수 감소로 어휘 크기 축소 및 모델 효율성 향상, ③ 알려지지 않은 단어 처리 시 구조 이해 지원
- **AI 애플리케이션 기획의 5단계**: ① 활용 사례 평가(왜 만들고 싶은가?), ② 기대치 설정(성공 지표), ③ 마일스톤 계획(측정 가능한 목표와 달성 계획), ④ 유지보수(시간에 따른 변화 대응), ⑤ 기타(비용-편익 분석, 규제 고려)
- **자기 지도 학습 vs 비지도 학습의 명확한 구분**: 자기 지도 학습은 입력 데이터에서 레이블을 추론하지만, 비지도 학습은 레이블이 전혀 필요하지 않음

### 독특한 관점 또는 흥미로운 발견
- **AI 역할의 3가지 축 구분**: ① 핵심적(AI 없이 작동 불가) vs 보완적(AI 없이도 작동), ② 반응형(사용자 요청에 응답) vs 선제형(적절한 시점에 먼저 제시), ③ 동적(지속적 업데이트) vs 정적(주기적 업데이트) - 각 축에 따라 요구되는 품질과 지연시간 기준이 달라짐
- **생성형 AI의 개방형 출력 특성**: 정해진 답 없이 개방형 출력을 생성하는 모델을 생성 모델(Generative Model)이라 부르며, 여기서 '생성형 AI(Generative AI)'라는 용어가 유래. 완성된 결과는 확률 기반 예측이므로 정확성이 보장되지 않음
- **ChatGPT 메모리 기능의 동적 방식**: 각 사용자가 자신의 데이터로 모델을 계속 파인튜닝하며 자신만의 모델을 갖게 되는 것이 AI의 동적 방식. 반면 정적 방식에서는 여러 사용자가 하나의 공유 모델을 함께 사용

### 실무 적용 아이디어
- **활용 사례 평가 시 위험도 중심 접근**: ① AI 경쟁사에게 밀려 생존 위협받는 경우(위험 높음) → ② 이익/생산성 증대 기회 포착 → ③ 기술 흐름 뒤처짐 불안(위험 낮음) 순으로 우선순위 설정
- **AI 역할별 요구사항 차별화**: 핵심적일수록 정확성↑, 반응형일수록 지연시간↓, 선제형일수록 품질↑ 필요. 예를 들어 챗봇(반응형)은 즉시 응답이 중요하지만, 구글 맵스 교통 알림(선제형)은 품질이 낮으면 불필요하게 느껴짐
- **모델 선택 기준**: 작업 특화(Task-specific) 모델은 더 작아서 빠르고 저렴하게 사용 가능. 파운데이션 모델 vs 작업 특화 모델의 '구매 또는 개발' 선택 문제는 요구사항과 자원에 따라 결정

### 추가 학습이 필요한 부분
- 개방형 출력을 평가하는 구체적인 방법론 및 지표(하나의 정답이 없는 상황에서 품질 측정)
- RAG(검색 증강 생성) vs 파인튜닝의 선택 기준 및 각각의 장단점 비교
- 데이터 레이블링 병목 현상을 극복하는 다른 기법들(약지도 학습, 능동 학습 등)


---

## 허채연 (Heo Chae-Yeon)

### 핵심 인사이트
- **AI 엔지니어링 진입 장벽의 극적 하락**: ① 범용 AI 능력(다양한 작업 수행 가능), ② AI 투자 증가(벤처캐피털, 기업), ③ 낮아진 진입 장벽(API 호출로 강력한 모델 접근 가능, AI가 코드 작성 지원) - 이 3가지 요인이 AI 엔지니어링을 엔지니어링 분야 중 가장 빠르게 성장하는 분야로 만듦
- **모델 조정 기법의 명확한 구분**: ① 프롬프트 엔지니어링(가중치 업데이트 X, 데이터 거의 불필요, 비교적 쉬움) vs ② 파인튜닝(가중치 업데이트 O, 더 많은 데이터 필요, 복잡하지만 품질/지연시간/비용 크게 개선)
- **자기회귀 언어 모델의 순차적 생성 방식**: 이전 토큰들만 보고 시퀀스의 다음 토큰을 예측하도록 학습하며, 토큰을 하나씩 순차적으로 생성. 정해진 유한한 어휘만 사용해서 무한히 다양한 결과물 생성 가능

### 독특한 관점 또는 흥미로운 발견
- **듀오링고(Duolingo) 사례를 통한 교육 분야 AI 활용**: AI가 객관식과 주관식 퀴즈를 모두 생성하고 응답을 평가할 수 있으며, 특히 수업 개인화 단계에서 가장 유용. 혁신적인 교수법으로 "AI가 생성한 글을 학생들에게 주고 오류를 찾아 수정하게 하는 방식" 제시
- **워크플로 자동화와 에이전트 개념**: 스스로 계획을 세우고 외부 도구에 접근하여 사용할 수 있는 AI를 '에이전트'라고 정의. 예약, 환불 요청, 여행 계획 등 지루한 작업 자동화가 궁극적 목표
- **낮은 진입 장벽의 양면성**: "낮은 진입 장벽은 축복이자 저주" - 내가 쉽게 만들 수 있다는 것은 경쟁사도 쉽게 만들 수 있다는 의미. 따라서 방어 가능성(Defensibility) 고려 필수

### 실무 적용 아이디어
- **AI 역할별 요구사항 설정**: 핵심적일수록 AI가 더 정확하고 신뢰할 수 있어야 함. 반응형(챗봇)은 지연시간↓, 선제형(구글 맵스 알림)은 품질↑ 필요. 동적 방식은 각 사용자가 자신만의 모델을 갖게 되고, 정적 방식은 여러 사용자가 하나의 공유 모델 사용
- **경쟁 우위의 3요소 확보 전략**: ① 기술력(모델 개발 능력, 최적화 기술), ② 데이터(고품질 학습 데이터, 도메인 특화 데이터), ③ 유통력(사용자에게 제품 전달 능력) 중 최소 하나 이상에서 강점 확보 필요
- **AI 애플리케이션 평가 전략**: 폐쇄형 ML 작업(모델 출력이 미리 정의된 값)은 정답 비교 가능하지만, 개방형 작업(챗봇)은 하나의 정답이 없어 평가 어려움. 따라서 품질 지표, TTFT/TPOT, 비용 지표, 해석 가능성/공정성 등 다각도 평가 필요

### 추가 학습이 필요한 부분
- 비정형 데이터(텍스트, 이미지) 처리 및 정형 데이터로 변환하는 구체적인 기법
- 추론 최적화 실전 사례(모델 압축, 양자화, 프루닝 등)와 비용-성능 트레이드오프
- 에이전트 시스템 구현 방법론(도구 사용, 계획 수립, 외부 API 연동)


---

## 통합 토론 주제

스터디 세션에서 함께 논의하면 좋을 질문들을 자유롭게 추가해주세요.

### 공통 질문
- 자기 지도 학습(Self-supervised Learning)이 AI 발전의 핵심이라고 모두 강조했는데, 현재 자기 지도 학습의 한계는 무엇이며 앞으로 어떻게 발전할까?
- 4명 모두 "프롬프트 엔지니어링 vs 파인튜닝"의 선택 기준을 언급했는데, 실무에서 어떤 상황에서 어떤 기법을 선택해야 할까? 구체적인 의사결정 트리를 만들 수 있을까?
- AI 제품의 "방어 가능성(Defensibility)"을 높이기 위한 구체적인 전략은? 기술력/데이터/유통력 중 우리 팀이 강점을 가질 수 있는 영역은?

### 심화 토론
- **AI 역할 구분의 실전 적용**: 핵심적/보완적, 반응형/선제형, 동적/정적의 3가지 축 구분에서, 각 축의 조합에 따라 실제 요구되는 품질/지연시간/비용은 어떻게 달라질까? (예: 핵심적+반응형+동적 = ?)
- **개방형 출력의 평가 문제**: 정답이 하나가 아닌 개방형 출력(챗봇, 글쓰기)을 평가하는 현실적인 방법은? LLM-as-a-Judge, 인간 평가, A/B 테스트 중 어떤 방법이 효과적일까?
- **멀티모달 모델의 미래**: CLIP의 자연어 지도(Natural Language Supervision) 방식이 텍스트-이미지 통합의 핵심이었는데, 텍스트-이미지-동영상-3D를 모두 통합하는 진정한 멀티모달 모델은 어떻게 구현될까?
- **AI 엔지니어링 vs ML 엔지니어링**: 우리가 현재 하고 있는 일은 AI 엔지니어링에 가까운가, ML 엔지니어링에 가까운가? 두 분야의 경계가 점점 흐려지는 현 시점에서 어떤 역량을 키워야 할까?

### 다음 주차 연결 포인트
- **2주차 주제(데이터/아키텍처/샘플링)**와의 연결: 이번 주차에서 "데이터셋 엔지니어링"의 중요성을 모두 언급했는데, 다음 주차에서 다룰 데이터 관련 내용이 AI 엔지니어링 스택에서 어떤 위치를 차지할까?
- 김성언님이 언급한 "추론 최적화(모델을 더 빠르고 저렴하게 만드는 것)"는 2주차에서 다룰 아키텍처와 어떻게 연결될까?
- 이은정님이 제기한 "RAG vs 파인튜닝 선택 기준"은 데이터 전략과 직결되는데, 2주차에서 더 깊이 다뤄볼 수 있을까?
