> AI 엔지니어링 책 스터디의 일환으로 책 내용을 기반으로 작성
> 
> [티스토리 게시글](https://armugona.tistory.com/entry/AIE-Ch1-%ED%8C%8C%EC%9A%B4%EB%8D%B0%EC%9D%B4%EC%85%98-%EB%AA%A8%EB%8D%B8%EC%9D%84-%ED%99%9C%EC%9A%A9%ED%95%9C-AI-%EC%95%A0%ED%94%8C%EB%A6%AC%EC%BC%80%EC%9D%B4%EC%85%98-%EC%9E%85%EB%AC%B8)

---

AI 애플리케이션에 대한 수요는 증가한 반면 AI 애플리케이션을 만드는 진입 장벽은 낮아졌다. 이로 인해 쉽게 사용할 수 있는 모델들을 기반으로 애플리케이션을 만드는 과정인 AI 엔지니어링은 엔지니어링 분야 중 가장 빠르게 성장하는 분야가 되었다.

1장에서는 **파운데이션 모델의 개요**를 시작으로 다양한 성공적인 **AI 활용 사례, AI의 강점과 한계**를 설명한다.

또한 새롭게 변화한 **AI 스택**, **AI 엔지니어의 역할이 전통적인 ML 엔지니어와 어떻게 다른지**에 대한 내용도 포함한다.

---

## AI 엔지니어링의 부상

#### 언어 모델에서 대규모 언어 모델로

언어 모델은 예전부터 존재했지만 **자기 지도 학습 _Self-supervised learning_** 덕분에 언어모델이 오늘날과 같은 규모로 성장할 수 있었다.

### 언어 모델 Language model

언어 모델은 여러 언어 대한 **통계 정보를 인코딩**한다. 직관적으로, 이 정보는 주어진 컨텍스트에서 어떤 단어가 나타날 것 같은지를 알려준다.

<img width="677" height="96" alt="image" src="https://github.com/user-attachments/assets/a596488f-0c81-484b-a8cd-1d9b6211909e" />


-   **토큰** : 언어 모델의 기본 단위, 모델에 따라 문자, 단어, 단어의 일부(-tion)가 될 수 있음
-   **토큰화 _Tokenization_** : 원문을 모델이 정한 길이로 나누는 과정
    -   GPT 4의 경우 토큰 하나의 평균 길이는 단어의 약 3/4, 100토큰은 약 75개의 단어에 해당한다
-   **어휘 _Vocabulary_** : 모델이 다룰 수 있는 모든 토큰의 집합  
    -   Mixtral 8x7B 모델은 어휘 크기가 32,000개, GPT-4의 어휘 크기는 100,256개
-   토큰화 방법과 어휘 크기는 모델 개발자가 결정한다

언어 모델이 토큰을 사용하는 이유 3가지

1.  토큰은 단어를 의미 있는 구성 요소로 나눌 수 있다 (e.g. '요리하기' $\\rightarrow$ '요리' '하기')
2.  고유한 토큰 수가 고유한 단어의 수보다 적기 때문에 모델의 어휘 크기가 줄어들어 모델이 더 효율적이게 된다
3.  토큰은 알려지지 않은 단어를 처리할 때 모델이 그 구조를 이해하는 데 도움이 된다 (e.g. 'chatgpting' \\rightarrow 'chatgpt' '-ing')

언어 모델은 토큰을 예측할 때 사용할 수 있는 정보에 따라 두 가지 유형으로 나뉘며, 마스크 언어 모델과 자기회귀 언어 모델이 있다.

-   **마스크 언어 모델 Masked language model**
    -   누락된 토큰 **전후 컨텍스트**를 사용해 시퀀스의 어느 위치에서든 **누락된 토큰(빈칸)을 예측**하도록 학습한다
    -   감정 분석, 텍스트 분류처럼 새로운 텍스트를 만들지 않는 작업에 주로 사용된다
    -   코드 디버깅처럼 전체 컨텍스트 이해가 필요한 작업에도 유용하다
    -   잘 알려진 마스크 언어 모델의 예시는 BERT
-   **자기회귀 언어 모델 Autoregressive language model**
    -   **이전 토큰**들만 보고 **시퀀스의 다음 토큰을 예측**하도록 학습한다
    -   토큰을 하나씩 순차적으로 생성할 수 있으며, 텍스트 생성 분야의 대세로 자리 잡아 마스크 언어 모델보다 큰 인기를 누리고 있다
    -   이 책에서 명시적으로 언급되지 않는 한, 언어 모델은 자기회귀 모델을 의미한다
    -   정해진 유한한 어휘를 사용해서 무한히 다양한 결과물을 만들어낼 수 있다. 이처럼 정해진 답 없이 개방형 출력을 생성하는 모델을 생성 모델 Generative Model이라 부르고 여기서 생성형 AI Generative AI라는 용어가 유래됐다

<img width="1296" height="902" alt="image" src="https://github.com/user-attachments/assets/d225cd7c-da6a-429d-a384-499d8aaa39c2" />


언어 모델은 텍스트(프롬프트)가 주어지면 해당 텍스트를 완성하려한다.

-   완성된 결과는 확률에 기반한 예측이며, 정확성이 보장되지 않는다.
-   언어 모델에 질의를 하면 질의에 답을 하는 대신 또 다른 질의로 문장을 완성할 수도 있다. 모델이 사용자의 요청에 적절히 응답하도록 만드는 방법도 존재한다.
-   2장에서 더 자세히 살펴볼 예정

#### 자기 지도 학습

언어 모델이 챗GPT 시대를 연 규모 확장 접근법의 핵심이 될 수 있었던 이유는 다른 모델들은 지도 학습 Supervised learning을 필요로 하는 반면, 언어 모델은 **자기 지도 학습 Self-supervised learning** 으로 학습할 수 있기 때문이다.

-   지도 학습의 단점은 데이터 레이블링에 많은 비용과 시간이 소요된다는 것 (**데이터 레이블링 병목 현상**)
    -   어떤 것에 레이블을 다느냐에 따라 단순하지 않은 레이블링 작업도 존재함 (e.g. 영어-라틴어 번역 모델을 위해 라틴어 번역문 만들기, CT 스캔에서 암의 징후가 있는 레이블을 다는 일)
-   **자기 지도 학습**은 데이터 레이블링 병목 현상을 극복해 모델이 학습할 수 있는 더 큰 데이터셋을 만들 수 있게 해주므로, 모델의 규모를 효과적으로 키울 수 있다
    -   명시적인 레이블이 필요하지 않고 모델이 입력 데이터에서 레이블을 추론할 수 있음
    -   언어 모델링은 각 입력 시퀀스가 레이블(예측할 토큰)과 모델이 예측하는데 사용할 수 있는 컨텍스트를 모두 제공함
    -   레이블링 없이 텍스트 시퀀스를 통해 학습할 수 있으며 텍스트 시퀀스는 방대한 양의 학습 데이터를 구축할 수 있음
-   자기 지도 학습은 데이터에서 레이블을 추론하지만, **비지도 학습**은 레이블이 전혀 필요하지 않은 것을 의미한다.

언어 모델이 얼마나 커야 **대규모 _Large_**로 간주될 수 있을까? 모델의 크기는 일반적으로 파라미터의 수로 측정된다.

-   첫 번째 GPT : 1억 1,700만 개
-   GPT-2 : 15억 개
-   이 책의 집필 시점에는 1,000억 개 파라미터를 가진 모델을 대규모로 본다
-   오늘 대규모라고 여겨지는 것이 내일이면 소규모로 여겨질 수 있다

**더 큰 모델은 왜 더 많은 데이터가 필요할까?**

-   모델이 클수록 학습할 수 있는 용량이 커지므로 성능을 극대화하려면 더 많은 학습 데이터가 필요하다
-   큰 모델을 작은 데이터셋으로 학습할 수 있지만, 이는 컴퓨팅 자원 낭비. 더 작은 모델을 사용했어도 비슷하거나 더 나은 결과를 얻을 수 있다

### 대규모 언어 모델에서 파운데이션 모델로

-   언어 모델은 글자에만 국한되어있고, AI가 실제 세상에서 유의미하게 작동하기 위해서는 글자 이상의 데이터를 처리하는 능력이 필요하다
-   언어 모델에 더 많은 데이터 모달리티를 통합하면 훨씬 강력해진다  
    -   GPT-4V, 클로드 3은 이미지와 텍스트를 이해할 수 있고 일부 모델은 동영상, 3D 에셋, 단백질 구조 등을 이해한다
-   제미나이와 GPT-4V를 LLM이라 부르지만 이들은 **파운데이션 모델 Foundation mode**l로 설명하는 것이 더 적절하다
    -   파운데이션이란 단어는 이 모델들이 AI 애플리케이션에서 갖는 중요성과 다양한 요구사항에 맞게 발전시킬 수 있다는 사실을 의미한다
-   그동안 AI 연구는 데이터 형태에 따라 구분되어 왔다. 파운데이션 모델은 AI 연구의 전통적인 구조에 획기적인 변화를 가져왔다.

-   둘 이상의 데이터 형태를 처리할 수 있는 모델을 **멀티모달 모델**이라고 한다
-   생성형 멀티모달 모델은 대규모 멀티모달 모델 LMM Large Multimodal Model이라고 한다 (이 또한 파운데이션 모델이라 책에서 지칭함)

<img width="700" alt="image" src="https://github.com/user-attachments/assets/4f523b90-2e6b-4795-b528-8e9ba68b4767" />


-   언어 모델이 텍스트 토큰에 기반해 토큰을 생성할 때, 멀티모달 모델은 텍스트와 이미지 토큰, 모델이 지원하는 다른 모달리티를 기반으로 다음 토큰을 생성한다.
    -   자기 지도 학습은 멀티모달 모델에서도 효과가 있다
    -   오픈 AI는 **자연어 지도 Natural Language supervision라는** 자기 지도의 변형을 사용해 언어 이미지 모델 CLIP을 학습했다
        -   각 이미지에 대한 레이블을 수동으로 생성하는 대신 인터넷에서 함께 발견되는 (이미지, 텍스트) 쌍을 수집했다
        -   수동 레이블링 비용없이 이미지넷보다 400배 더 큰 4억 개의 (이미지, 텍스트) 쌍으로 구성된 데이터셋을 생성할 수 있었다
        -   이 데이터셋 덕분에 CLIP은 최초로 추가 학습 없이도 여러 이미지 분류 작업을 일반화할 수 있었다
            -   CLIP은 생성모델이 아닌 임베딩 모델 embedding model로 플라밍고, LLaVA, 제미나이와 같은 생성형 멀티모달 모델의 핵심이다
-   파운데이션 모델은 특정 작업에 맞춘 모델에서 **범용 모델로 전환**하는 것을 의미한다
    -   이전에는 감정 분석이나 번역과 같은 특정 작업을 위해 모델이 개발되는 경우가 많았다. 그리고 각 모델은 자신이 학습된 Task 외에는 수행할 수 없었다
    -   파운데이션 모델은 **규모와 학습 방식 덕분에 다양한 작업을 수행할 수 있다** 
        -   하나의 LLM으로 여러 작업을 수행할 수 있다. 물론 특정 작업에 대해 성능을 올리고 싶다면 **파인튜닝 Fine-tuning**이 필요하다.

모델이 원하는 결과물을 내놓도록, 목적에 맞게 조정하는데 널리 쓰이는 대표적인 **AI 엔지니어링 기법**들을 이어지는 장들에서 자세하게 다룬다

-   **프롬프트 엔지니어링 Prompt engineering** : 원하는 예시와 함께 상세한 지시를 모델에 제공
-   **검색 증강 생성 Retrieval-augmented generation (RAG)** : 모델을 데이터베이스에 연결하여 더 나은 설명을 생성하도록
-   **파인튜닝**

-   모델을 조정하는 필요한 데이터의 정확한 양은 어떤 기술을 사용하는지에 따라 달라지며 이 또한 뒤에서 다룬다
-   작업 특화 Task-specific 모델은 보통 더 작기 때문에 빠르고 저렴하게 사용할 수 있다는 장점이 있다
-   직접 자체 모델을 만들지, 기존 모델을 활용할지는 스스로 결정해야 할 '구매 또는 개발' 선택의 문제이며, 이 책의 논의들이 이런 결정에 도움이 될 것

### 파운데이션 모델에서 AI 엔지니어링으로

---

## 파운데이션 모델 활용 사례

이 절에서는 애프리케이션에 대한 아이디어를 얻기 위해 업계에서 검증된 다양한 활용 사례와 유망한 사례들을 확인해보자

설문조사마다 다른 분류를 사용하기 때문에 분류하기 쉽지 않지만

-   AWS는 엔터프라이즈 생성형 AI 활용 사례를 **고객 경험, 직원 생산성, 프로세스 최적화**의 3가지 범주로 나누었다
-   오라일리 설문조사에서는 **프로그래밍, 데이터 분석, 고객 지원, 마케팅 글, 기타 글, 연구, 웹, 디자인, 예술 등 8가지 범주**로 나누었다
-   딜로이트 : **비용 절감, 프로세스 효율성, 성장, 혁신 가속화 등 가치 확보 측면**에서 활용 사례를 분류
    -   가치 확보와 관련해 가트너 Gartner는 생성형 AI를 도입하지 않으면 조직이 도태될 수 있다는 의미의 **'비즈니스 연속성'** 이라는 범주를 두고 있다

<img width="800" alt="image" src="https://github.com/user-attachments/assets/5e88facf-c2a1-4c19-9aa4-564187cad9d7" /> 

*AI가 어떤 활용 사례에 적합한지 보여주는 연구*

<img width="800" alt="image" src="https://github.com/user-attachments/assets/1014492b-b043-4444-8009-c671b5f71668" />

*참고용, 앞으로 책의 내용을 보다보면 파운데이션 모델이 어떤 활용 사례에 사용될 수 있고, 사용되어야 하는지 잘 파악할 수 있을 것*


-   파운데이션 모델을 활용해 만든 하나의 애플리케이션은 여러 범주에 속할 수 있다.

<img width="1143" height="766" alt="image" src="https://github.com/user-attachments/assets/8391864d-abef-4822-a141-6393e5a69afb" />

*비율이 작은건 단순히 오픈소스로 공개되지 않았다는 의미, 인기가 없다는 것이 아님*


-   기업들은 위험도가 낮은 애플리케이션을 선호한다

<img width="1148" height="506" alt="image" src="https://github.com/user-attachments/assets/5ecf73cf-047f-4eb9-a8e3-472c2af4e417" />


-   **코딩**
    -   일반적인 코딩을 돕는 도구 외에도 특정 코딩 작업에 특화된 도구가 많이 있다.
    -   AWS CEO는 가까운 미래에 대부분의 개발자가 코딩을 멈출 것이라고 말하기도 했다. 이는 SW 개발자의 종말을 의미하는 것이 아니라 단지 그들의 직무가 변화할 것이라는 뜻이다.
    -   AI는 분명 엔지니어의 생산성을 높일 수 있다. 아웃소싱 업무는 기업의 핵심 비즈니스 외의 단순한 업무가 많기 때문에 AI는 아웃소싱 산업에도 변화를 가져올 수 있다.
    -   소프트웨어 엔지니어링은 많은 작업으로 이루어진다. AI가 어떤 작업에서는 더 나은 성과를 보인다.

<img width="1131" height="885" alt="image" src="https://github.com/user-attachments/assets/fe9a21aa-799f-43a4-b2b6-ba5b0cc2344a" />


-   **이미지 및 동영상 제작**
    -   미드저니, 어도비 파이어플라이, 런웨이, 피카 랩스, 소라 등의 창의적 애플리케이션이 있다
    -   광고, 마케팅
-   **글쓰기**
    -   AI가 실수해도 위험부담이 적다
    -   독자의 선호도에 따라 줄거리가 바뀔 수 있음, 어린이용 독서 애플리케이션은 어려운 단어를 파악하고 이런 단어를 중심으로 이야기를 생성하기도 함
    -   메모 및 이메일 애플리케이션에서 글쓰기 보조 기능 지원
    -   영업, 마케팅, 팀 커뮤니케이션에 활용
    -   검색 엔진 최적화 SEO에 강한 면모를 보임 (저질 웹사이트 콘텐츠 양산 공장...)
-   **교육**
    -   언어 학습에서 큰 도움
    -   수업 개인화가 AI의 혜택을 가장 많이 받을 수 있는 단계
        -   혁신적인 교수법 중 하나 : 교사가 AI가 생성한 글을 학생들에게 주고 오류를 찾아 수정하게 하는 것

    <img width="1133" height="453" alt="image" src="https://github.com/user-attachments/assets/fe624b68-8a56-49c7-a4b9-816dbe68a115" />


-   **대화형 봇**
    -   정보 탐색, 개념 설명, 브레인스토밍
    -   사회 역학에 대한 연구 수행
    -   고객 지원 봇
    -   스마트 NPC : 플레이어가 몰입할 수 있게
-   **정보 집계**  
    -   문서와 대화하기
-   **데이터 체계화**
    -   비정형, 반정형 데이터 체계화는 필수 $\\rightarrow$ AI로 비정형 데이터에서 정형 데이터를 추출함
    -   이미지, 동영상에 대한 텍스트 설명 생성, 그에 맞는 시각 자료 매칭
    -   데이터 분석 : 데이터 시각화 생성, 이상치 식별, 매출 예측
-   **워크플로 자동화**
    -   예약, 환불 요청, 여행 계획, 양식 작성 등 지루한 작업 자동화
    -   잠재 고객 관리, 청구서 발행, 비용 정산 등과 같은 반복적인 작업 자동화
    -   AI를 사용해 데이터 합성, 모델 자체를 개선하는데 이를 사용
        -   스스로 계획을 세우고 외부 도구에 접근하여 사용할 수 있는 AI를 **에이전트**라고 한다

---

## AI 애플리케이션 기획

AI의 무한한 가능성을 보면 바로 애플리케이션 개발에 뛰어들고 싶어지지만 생계를 위해 이 일을 하려고 한다면 **왜, 어떻게** 해야하는지를 생각해보는 것이 좋다. 단순 재미를 위해서 + 멋진 데모를 만드는 것은 쉽지만 수익성 있는 제품을 만드는 것은 어렵다.

### 활용 사례 평가

**왜** 만들고 싶은가 : 보통 AI 애플리케이션을 만들기로 하는 것은 위험을 피하거나 새로운 기회를 잡기 위해서

아래는 위험 수준이 높은 것부터 낮은 순으로 정리한 예시이다.

1.  AI를 가진 경쟁사에게 밀려 생존을 위협받을 수 있는 경우
2.  이익과 생산성 증대를 위한 기회를 포착하려는 경우
3.  AI의 구체적인 활용법은 불확실하지만, 기술 흐름에 뒤처질 것을 불안해하는 경우

### 애플리케이션에서 AI와 사람의 역할

-   AI가 맡는 역할에 따라 애플리케이션의 개발 방식과 요구사항이 달라진다
    -   **핵심적 또는 보완적**
        -   AI가 핵심적일수록 AI 부분이 더 정확하고 신뢰할 수 있어야 한다
    -   **반응형 또는 선제형**
        -   반응형 : 사용자의 요청이나 행동에 응답, 지연시간이 짧아야 함
        -   선제형 : 사용자에게 유용하다고 판단되는 적절한 시점에 정보를 제시, 상대적으로 지연시간의 중요성이 덜함, 품질이 낮으면 성가시다고 여겨짐 일반적으로 훨씬 더 높은 품질 기준을 요구
    -   **동적 또는 정적**
        -   동적 : 사용자 피드백을 통해 지속적으로 업데이트됨 (e.g. 페이스 ID), 각 사용자가 자신의 데이터로 모델을 파인튜닝하며 자신만의 모델을 갖게 되는 것
        -   정적 : 주기적으로만 업데이트 (e.g. 구글 포토 객체 탐지 모델), 여러 사용자가 하나의 공유 모델을 사용
-   사람의 역할
    -   AI가 사람을 뒤에서 지원할 것인지 직접 결정을 내릴지, 둘 다 할 것인지
    -   AI의 의사 결정 과정에 참여시키는 것 : 휴먼 인 더 루프 Human-in-the-loop
    -   마이크로소프트는 AI 자동화를 점진적으로 증가시키기 위한 프레임워크로 크롤-워크-런 crawl-walk-run 제안
        -   크롤은 사람의 참여가 필수임을 의미
        -   워크는 AI가 내부 직원과 직접 상호작용할 수 있음을 의미
        -   런은 잠재적으로 외부 사용자와의 직접적인 AI 상호작용을 포함해 자동화가 향상됨을 의미

### AI 제품 방어 가능성

**방어 가능성 _defensibility_**을 고려하는 것이 중요하다.

내가 쉽게 만들 수 있는 것은 경쟁사도 쉽게 만들 수 있다. 파운데이션 모델의 성능이 좋아지면 제공하는 계층이 모델에 흡수되어 애플리케이션이 쓸모없게 될 수 있다.

AI 분야의 경쟁 우위는 크게 **기술력, 데이터, 유통력 (사용자에게 제품을 전달하는 능력)**으로 나눌 수 있다.

### 기대치 설정

성공을 어떻게 측정할 것인지 (비즈니스 지표 등등...)

제품을 고객이 실제로 사용할 만한 수준이 되려면 어느 정도의 성능이 필요한지 기준을 세워야 한다.

-   품질 지표
-   TTFT(첫 토큰까지 걸리는 시간), TPOT(출력 토큰당 시간), 전체 지연 시간을 포함하는 지연 시간 지표, 수용 가능한 지연 시간은 활용 사례에 따라 다르다
-   추론 요청당 비용 같은 비용 지표
-   해석 가능성과 공정성 같은 기타 지표

### 마일스톤 계획

측정 가능한 목표를 설정했다면, 이를 달성하기 위한 계획이 필요하다.

-   이미 존재하는 모델의 성능 평가, 능력 파악
    -   목표한 최소 성능을 달성하는데 드는 자원이 예상 수익보다 클 수도 있음
-   파운데이션 모델의 기본 성능이 이미 좋아서 데모를 만드는데 많은 시간이 걸리지 않을 수 있음
    -   좋은 초기 데모가 좋은 최종 제품을 보장하지는 않음, 실제 제품을 만드는 데는 몇 달, 몇 년이 걸릴 수도 있음

### 유지보수

AI는 빠르게 변화해서 AI 제품의 유지보수는 더욱 어렵다. 파운데이션 모델 위에 무언가를 만든다는 건 총알 열차에 올라타겠다는 뜻

많은 모델의 한계가 해결되고 있고 모델 출력은 더 좋아지고 있으며 추론은 더 빠르고 저렴해지고 있다.

<img width="1133" height="453" alt="image" src="https://github.com/user-attachments/assets/953eefd9-9467-4958-af21-bf2e06e50203" />


긍정적인 변화이지만 오늘 최선의 선택이 내일은 최악의 선택이 될 수 있다.

모델 제공 업체들이 비슷한 형태의 API를 사용하면서 API를 다른 것으로 교체하기 쉬워졌지만, 모델마다 특징이 있어 새 모델로 작업하는 개발자들은 작업 과정, 프롬프트, 데이터를 새 모델에 맞게 조정해야 한다. 버전 관리와 평가를 위한 적절한 인프라가 없다면 이 과정이 힘들 수 있다.

규제 등 적응하기 어려운 변화들도 있다.

---

## AI 엔지니어링 스택

AI 엔지니어링의 기본 구성 요소를 살펴보자.

-   **AI 엔지니어링은 ML 엔지니어링에서 발전**했다.
-   보통 기본 ML팀이 자연스럽게 이어서 파운데이션 모델을 실험하는 등 그 업무를 수행한다.
    -   일부 기업은 AI 엔지니어링을 ML 엔지니어링과 동일하게 취급한다.

AI 애플리케이션 개발 과정의 여러 계층에서 AI 엔지니어링과 전통적인 ML 엔지니어링의 각 역할을 살펴보자.

### AI의 세 가지 계층

<img width="941" height="609" alt="image" src="https://github.com/user-attachments/assets/94bd27c5-b16e-43c1-8d37-ab68a753db75" />


-   **애플리케이션 개발**
    -   모델을 쉽게 사용할 수 있게 되면서 누구나 이를 활용해 애플리케이션을 개발할 수 있다.
    -   적절한 프롬프트, 필요한 컨텍스트 제공
    -   철저한 평가, 좋은 인터페이스가 필요
-   **모델 개발**
    -   모델링, 학습, 파인튜닝, 추론 최적화를 위한 프레임워크를 포함해 모델을 개발하기 위한 도구를 제공
    -   데이터셋 엔지니어링도 포함
    -   철저한 평가 필요
-   **인프라**
    -   모델 서빙, 데이터 & 컴퓨팅 관리, 모니터링을 위한 도구

<img width="941" height="609" alt="image" src="https://github.com/user-attachments/assets/fb705c40-6a0e-4ba1-83c8-ac6ddd221d59" />


-   AI 애플리케이션 개발의 많은 원칙은 **동일하게 유지**되고 있다.
-   여전히 비즈니스 문제를 해결해야 하고, 비즈니스 지표와 ML 지표를 상호 연계하는 것이 중요
-   체계적인 실험 
    -   전통적인 ML 엔지니어링에서는 다양한 하이퍼파라미터로 실험
    -   파운데이션 모델에서는 서로 다른 모델, 프롬프트, 검색 알고리즘, 샘플링 변수 등으로 실험
-   모델을 빠르고 더 저렴하게 실행하는 것도 여전히 중요
-   피드백 루프 구축

지속적인 원칙 위에 AI 엔지니어링만의 혁신을 이 책에서 살펴볼 것

## AI 엔지니어링 vs ML 엔지니어링

무엇이 달라졌는지, 차이를 이해해보자. (편의를 위해 그냥 ML, AI 로 줄여서 작성하겠음)

1.  ML : 파운데이션 모델이 없음, AI : 학습시켜 놓은 모델을 가져다 쓴다 $\\rightarrow$ 모델링과 학습보다는 **모델 조정에 더 초점을 맞춘다는 의미**
2.  AI : 더 크고 많은 컴퓨팅 자원을 소비, 더 높은 지연 시간을 발생시키는 모델을 다룬다.
    -   **효율적인 학습과 추론 최적화에 대한 압박이 더 크다.**
    -   GPU와 대규모 클러스터를 다룰 줄 아는 엔지니어에 대한 수요 역시 늘어났다
3.  AI : 개방형 출력을 생성하는 모델을 다룬다. 작업에 대한 유연성을 제공하지만 그만큼 **평가하기 어렵다**.

 일반적으로 **모델 조정**은 **가중치를 업데이트해야 하는지 여부에 따라 두 가지 범주**로 나눈다.

-   프롬프트 엔지니어링을 포함한 **프롬프트 기반 기법은 가중치를 업데이트하지 않고도 모델의 동작을 조정**
    -   지시와 컨텍스트를 제공하여 원하는 방향으로 모델을 유도
    -   데이터도 거의 필요없다
    -   복잡한 작업이나 성능에 엄격한 기준이 있는 경우엔 충분하지 않을 수 있음
-   **파인튜닝은 모델 가중치를 업데이트해야 한다**
    -   더 복잡하고 더 많은 데이를 필요로 하지만 **품질, 지연 시간, 비용을 크게 개선할 수 있다.**

---

ML엔지니어들에게 익숙한 것부터 시작해서 애플리케이션 개발, 모델 개발 계층이 AI 엔지니어링과 어떻게 변화했는지 살펴보자.

### 모델 개발

**모델링과 학습, 데이터셋 엔지니어링, 추론 최적화** 세 가지 구성 요소가 있다

#### 모델링과 학습

모델 아키텍처를 고안하고, 학습하고, 파인튜닝하는 과정

도구의 예시로는 텐서플로우, 파이토치, 트랜스포머가 있다.

-   ML: 클러스터링, 로지스틱 회귀, 의사결정 트리, 협업 필터링 같은 ML 알고리즘, 피드포워드, 순환, 합성곱, 트랜스포머와 같은 신경망 아키텍처, 경사 하강법, 손실 함수, 정규화 등의 개념, 모델이 어떻게 학습하는지 알아야 한다.
-   파운데이션 모델을 사용할 수 있게 되면서 ML 지식이 더 이상 필수가 아니게 되었다.
-   하지만 ML 지식은 여전히 가치있다. 사용할 수 있는 도구의 폭을 넓혀주고 모델이 예상대로 작동하지 않을 때 문제를 해결하는데 도움을 준다.

학습도 여러 가지 의미로 해석될 수 있다. **사전학습, 파인튜닝, 사후학습**

-   **사전 학습** : 모델을 처음부터 학습하는 것, 압도적으로 많은 자원 필요로 함, 소수만이 경험할 수 있는 기술이 되었고 대규모 모델의 사전 학습 전문가를 찾는 곳이 많아졌다.
-   **파인튜닝** : 학습된 모델을 추가로 학습하는 것, 사전학습보다 적은 자원을 필요로 함
-   **사후 학습** : 파인튜닝과 거의 같은 과정이지만, '누가' 학습을 수행하는지를 기준으로 용어를 구분했다. 모델 제공업체가 수행하면 사후 학습이라고 한다. (파인튜닝은 애플리케이션 개발자)

### 데이터셋 엔지니어링

모델의 학습과 조정에 필요한 데이터를 선별하고 생성하고 주석을 다는 것

-   ML : 모델 출력은 미리 정의된 값들 중 하나만 될 수 있는 **폐쇄형**
-   파운데이션 모델은 **개방형** : 개방형 데이터에 주석을 다는 것이 **훨씬 어렵다, 더 큰 과제**

-   ML : **정형** 데이터를 많이 다룸
-   AI : **비정형** 데이터를 많이 다룸, 중복 제거, 토큰화, 컨텍스트 검색, 민감 정보 & 유해 데이터 제거를 포함한 **품질 관리**

모델의 학습 데이터는 해당 모델의 강점과 약점에 대한 중요한 단서를 제공한다. 데이터에 대한 전문성이 모델을 검토할 때 유용함

### 추론 최적화

모델을 더 빠르고 저렴하게 만드는 것

원래도 중요했지만 파운데이션 모델이 더 높은 추론 비용과 지연 시간을 발생시키게 되며 더욱 중요해짐

-   파운데이션 모델은 종종 자기회귀적 _autoregressive_이다. 긴 출력에는 더 많은 시간이 걸린다.

<img width="1196" height="375" alt="image" src="https://github.com/user-attachments/assets/02db18f7-de45-4b90-b707-c783eecc829d" />


### 애플리케이션 개발

-   ML : 자체 모델의 품질이 차별화 요소였다
-   AI : 같은 모델을 많이 사용하므로 애플리케이션 개발 과정을 통해 차별화를 이뤄야 함
    -   **평가, 프롬프트 엔지니어링, AI 인터페이스**로 구성됨

#### 평가

-   위험을 완화하고 기회를 발견하는 과정
    -   모델 선택, 진행 상황 벤치마크, 배포 준비 여부 판단, 운영 중 시스템 문제점 발굴, 개선 기회 발견
-   이것 또한 늘 중요했지만 여러 이유로 더욱 중요해짐
    -   **개방성, 확장성** : 하나의 정답이 없으며 조정 기술이 너무 많아 평가가 어려움

#### 프롬프트 엔지니어링 및 컨텍스트 구성

-   프롬프트만으로도 놀라운 성능 향상이 가능
-   단순히 무엇을 하라고 말하는 것이 아니라, 주어진 작업을 수행하는데 필요한 컨텍스트와 도구 제공
    -   롱 컨텍스트가 필요한 복잡한 작업의 경우, 모델이 자신의 기록을 추적할 수 있도록 메모리 관리 시스템을 제공해야 할 수도 있다.

#### AI 인터페이스

사용자가 AI와 상호작용하는 인터페이스

이전에는 조직의 제품에 통합되었으나, 이제는 독립 제품으로 제공하거나 다른 사람들이 개발한 제품에 탑재할 수 있다.

-   독립형 웹, 데스크탑, 모바일 애플리케이션
-   브라우저 확장 프로그램
-   슬랙, 디스코드, 위챗, 왓츠앱 등 채팅 애플리케이션에 통합된 챗봇
-   VS 코드, 쇼피파이, 마이크로소프트 365를 포함한 여러 제품이 개발자가 플러그인과 애드온 형태로 AI를 통합할 수 있는 API를 제공한다. (이런 API를 통해 AI Agent가 상호작용)
-   음성 기반, 실체화된 형태(VR, AR)일 수도 있음

<img width="1183" height="274" alt="image" src="https://github.com/user-attachments/assets/1ad9cb68-b344-4bc5-91ea-8da5f05f936c" />


## AI 엔지니어링 vs 풀스택 엔지니어링

이전에는 ML 프레임워크들이 대부분 파이썬 API만 지원했으나 LangChain.js, Transformers.js, 오픈AI의 Node 라이브러리, Vercel의 AI SDK 등 자바스크립트 API에 대한 지원이 늘어나고 있다.

아이디어를 빠르게 데모로 만들고, 피드백을 받고, 개선할 수 있는 능력이 있는 웹 개발이나 풀스택 배경을 가진 사람들이 점점 늘어나고 있다.

<img width="1226" height="398" alt="image" src="https://github.com/user-attachments/assets/b0d11b1e-7020-4bb3-894d-a1935fc07acf" />


-   ML: 모델 개발 & 제품 개발이 분리된 프로세스, ML 엔지니어는 제품의 의사 결정에 거의 참여하지 않았음
-   AI : AI 엔지니어가 제품 개발에 훨씬 더 많이 참여하는 경향이 있음

---

> **마치며**  
> AI 엔지니어링을 글로 설명할 때 가장 어려운 점은 커뮤니티가 보여주는 엄청난 에너지와 창의성, 그리고 뛰어난 기술력이다. 끊임없이 등장하는 새로운 기술과 발견, 엔지니어링 성과를 따라가기만으로도 매우 벅차서, 커뮤니티의 이러한 열기는 때로 감당하기 힘들 정도다.   
>   
> 다행히도 AI는 정보를 잘 모으고 정리할 수 있어 이런 새로운 업데이트들을 종합하고 요약하는데 도움을 줄 수 있으나 어디까지나 한계가 있는 법이다.   
> 한 분야가 압도적일수록 그것을 이해하는데 도움이 되는 프레임워크를 갖추는 것이 중요하고 이 책은 그런 프레임워크를 제공하는 것을 목표로 한다.
