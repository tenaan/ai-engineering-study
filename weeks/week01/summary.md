# 통합 정리

**정리자**: 이은정
**날짜**: 25.11.20

---
# Chap1. 파운데이션 모델을 활용한 AI 애플리케이션 입문
AI 애플리케이션에 대한 수요는 증가한 반면 AI 애플리케이션을 만드는 진입 장벽은 낮아졌다. 이로 인해 쉽게 사용할 수 있는 모델들을 기반으로 애플리케이션을 만드는 과정인 AI 엔지니어링은 엔지니어링 분야 중 가장 빠르게 성장하는 분야가 되었다.

이 장에서는 AI 엔지니어링의 폭발적인 성장의 원동력인 파운데이션 모델의 개요를 시작으로 다양한 성공적인 AI 활용 사례, AI가 잘하는 것과 아직 부족한 것을 설명한다.

## AI 모델의 규모가 커지면서 나타난 2가지 현상
### 1) 새로운 능력

- AI 모델이 더욱 강력해지고 더 많은 작업을 수행
- 단순히, 정확도가 좋아졌다는 것이 아닌 범용성(generality) 향상
- 과거엔 태스크마다 **별도의 모델을 훈련**해야 했지만 이제는 **한 모델이 수십 개 이상의 태스크를 처리**한다.

### **2) Model-as-a-Service(MaaS)의 등장**

- 소수의 기업만 감당 가능한 LLM 학습을 위한 데이터, 컴퓨팅 자원, 전문 인력 → MaaS의 등장
- 소수의 거대조직이 개발한 모델을 다른 사람들이 서비스로 이용

# AI 엔지니어링의 부상
## 언어 모델에서 대규모 언어 모델로
**자기지도 학습(self-supervised learning)** 덕분에 대규모 언어 모델(LLM)이 성장할 수 있었다.

### 언어 모델
- 언어 모델의 기본 단위는 토큰(*모델에 따라 문자, 단어, 단어의 일부가 될 수 있음)
- 토큰화 : 원문을 모델이 정한 길이로 나누는 과정
- 어휘 *vocabulary* : 모델이 다룰 수 있는 모든 토큰의 집합 [OpenAI Platform](https://platform.openai.com/tokenizer)
- 언어 모델의 출력에는 제한이 없고, 정해진 유한한 어휘만을 사용해서 무한히 다양한 결과물을 만들어낼 수 있기 때문에 우리는 **생성형 모델** *generative model* 이라고 부른다.
- 언어 모델을 텍스트(프롬프트)가 주어지면 해당 텍스트를 완성하는 완성 기계이고, **완성된 결과는 확률에 기반한 예측이므로, 정확성이 보장되지 않는다.**
  
**언어 모델이 토큰을 사용하는 이유 3가지**
1. 토큰은 단어를 의미 있는 구성 요소로 나눌 수 있다 (e.g. '요리하기' → '요리' '하기')
2. 고유한 토큰 수가 고유한 단어의 수보다 적기 때문에 모델의 어휘 크기가 줄어들어 모델이 더 효율적이게 된다
3. 토큰은 알려지지 않은 단어를 처리할 때 모델이 그 구조를 이해하는 데 도움이 된다 (e.g. 'chatgpting' -> 'chatgpt' '-ing')

언어 모델은 크게 두 가지로 나눌 수 있다.
1. 마스크 언어 모델
2. 자기회귀 언어 모델
   
#### 마스크 언어 모델(masked language model)
- 누락된 토큰 전후 컨텍스트를 사용해 시퀀스의 어느 위치에서든 **누락된 토큰을 예측**하도록 학습
- 기본적으로 빈칸을 채울 수 있도록 학습
- **감정 분석**이나 **텍스트 분류**처럼 새로운 텍스트를 만들지 않는 작업에 주로 사용된다.
**코드 디버깅**처럼 모델이 앞뒤 코드를 모두 이해해서 오류를 찾아야 하는 전체적인 컨텍스트 이해가 필요한 작업에도 유용
- ex) BERT
![](https://velog.velcdn.com/images/algorithm_cell/post/0f9e252e-10a9-4836-a09e-5dcee900180a/image.png)

#### 자기회귀 언어 모델(autoregressive language model)
- 이전 토큰들만 보고 시퀀스의 다음 토큰을 예측하도록 학습
- 토큰을 하나씩 순차적으로 생성할 수 있고 텍스트 생성 분야의 대세로 자리 잡아 마스크 언어 모델보다 훨씬 더 큰 인기
![](https://velog.velcdn.com/images/algorithm_cell/post/534237b7-b78f-4a3c-9c82-4384a2b7c895/image.png)

정해진 답 없이 개방형 출력을 생성하는 모델을 생성 모델(generative model)이라고 부르는데, 바로 여기에서 **생성형 AI(generative AI)** 라는 용어가 유래됐다.

언어 모델은 텍스트(프롬프트)가 주어지면 해당 텍스트를 완성하려는 일종의 완성 기계로 생각하면 된다. 완성된 결과가 확률에 기반한 예측이며, 정확성이 보장되지 않는다.

## 자기 지도 학습
- 언어 모델은 예전부터 존재했지만, **자기 지도 학습** *self-supervised learning* 덕분에 성장할 수 있었다. 
- 지도학습은 데이터 레이블링 작업으로 인해 많은 비용이 소모되는데, 자기 지도학습은 데이터 레이블링 병목 현상을 극복하는 데 도움이 된다.

### 과정
- 모델이 입력 데이터에서 레이블을 추론할 수 있다.
- `<BOS>` `<EOS>` 과 같은 마커를 통해 언어 모델이 여러 시퀀스를 구분해서 처리할 수 있도록 돕는다.
![](https://velog.velcdn.com/images/algorithm_cell/post/550e3927-78d0-4237-928f-a129a5fb0184/image.png)

### **대규모 모델의 정의**
- 얼마나 커야 대규모 모델로 간주할  수 있을까? 오늘의 대규모가 내일은 아주 작게 여겨질 수 있다.
- 시기별 대규모로 여겨진 모델들
    - 2018년 6월: GPT 1억 1,700만 개 파라미터
    - 2019년 2월 오픈 AI의 GPT-2 15억 개 파라미터 (기존 GPT는 소규모)
    - 2024년 12월: 1,000억 개의 파라미터 (100B)

## **대규모 언어 모델에서 파운데이션 모델로**
### **1) 글자 이상의 데이터 처리 능력**

- **GPT-4V**와 같은 최신 모델에서는 **이미지**와 같은 비텍스트 데이터를 처리할 수 있는 능력이 추가됐다.(추가적인 모달리티를 LLM의 통합)

### **2) 파운데이션 모델 (Foundation Models)**

- 언어 모델은 글자에만 국한되어 있다. ↔ 파운데이션 모델은 글자 이상의 처리 능력(멀티 모달리티; 둘 이상의 데이터를 처리할 수 있는 능력)를 갖는다.
ex) GPT-4V, Gemini
- **파운데이션 모델**은 하나의 모델이 **다양한 작업을 처리**할 수 있도록 학습된 **범용 모델**
    - ex) 텍스트 생성, 번역, 감정 분석, 이미지 이해 등 다양한 태스크를 처리 / cf) AI 생성 텍스트 판별
- 기존 연구들은 자연어처리(text), 컴퓨터비전(image)를 각각 독립적으로 처리했지만, 이런 다른 형태의 둘 이상의 데이터 형태를 처리할 수 있는 모델을 멀티모달 모델이라고 부른다.
- 생성형 멀티모달 모델은 LMM large multimodal model이라고 한다.

<aside>

책에서 ‘파운데이션 모델’: ‘대규모 언어 모델’과 ‘대규모 멀티모달 모델’을 모두 지칭

</aside>

- 멀티 모달에서도 효과적인 자기 지도 학습
    - 오픈 AI는 ‘자연어 지도(Natural Language Supervision)’이라는 자기 지도의 변형을 사용해 언어-이미지 임베딩 모델 CLIP을 학습
        
        → 인터넷에서 함께 발견되는 (이미지, 텍스트)쌍을 수집, **사상 최초로 추가 학습 없이도 여러 이미지 분류 작업을 일반화**
         
#### 모델이 원하는 결과물을 내놓도록 유도하는 기법
1. 프롬프트 엔지니어링(prompt engineering)
- 원하는 설명 예시와 함께 상세한 지시를 모델에 제공
2. 검색 증강 생성(retrieval-augmented generation, RAG)
- 데이터베이스를 활용해 지시를 보완하는 것
- ex. 고객 리뷰 데이터베이스에 연결해 더 나은 설명 생성
3. 추가로 파인튜닝
- 고품질의 제품 설명 데이터셋을 사용해 모델을 추가로 파인튜닝

책에서는 파운데이션 모델의 장점만 언급했으나 작업 특화(task-specific) 모델도 장점이 있다. 보통 더 작아서 빠르고 저렴하게 사용할 수 있다.

## 파운데이션 모델에서 AI 엔지니어링으로

### AI 엔지니어링 
파운데이션 모델을 기반으로 애플리케이션을 만드는 과정 

- 이 분야가 빠르게 성장한 이유
    1. 범용 AI 능력 : 파운데이션 모델을 많은 작업을 수행할 수 있다.
    2. AI 투자 증가 : 벤쳐 캐피터로가 기업에서의 AI에 대한 투자가 증가했다.
    3. AI 애플리케이션 개발에 대한 낮아진 진입 장벽 : API 호출을 통해 강력한 모델에 접근할 수 있으며, AI가 코드를 작성해주기 때문이다.

### AI 파운데이션 모델 활용 사례
![](https://velog.velcdn.com/images/algorithm_cell/post/1316c8dd-7e4b-46f1-b9c3-aaa74f604960/image.png)
1. 코딩
2. 이미지 및 동영상 제작
3. 글쓰기
4. 교육 
- 예시) 듀오링고
 AI는 객관식과 주관식 퀴즈를 모두 생성하고 응답을 평가할 수 있다. 특히, 개인화 단계에서 가장 유용하다.
![](https://velog.velcdn.com/images/algorithm_cell/post/5e8715ab-3078-4da8-8838-4e3e4faf2cda/image.png)
5. 대화형 챗봇
6. 정보 집계
7. 데이터 체계화
8. 워크플로 자동화
- AI의 궁극적인 목표는 가능한 한 많은 영역을 자동화하는 것
- 많은 작업을 수행하려면 외부 도구에 접근 필요하다. (ex. 레스토랑 예약하기 위해 검색 엔진 열어 전화번호 찾고, 일정을 캘린더에 추가할 수 있는 권한 등)
이때 스스로 계획을 세우고 도구를 사용할 수 있는 AI를 **에이전트**라고 한다.

## AI 애플리케이션 기획
### 1) 활용 사례 평가
- 가장 먼저 해야할 질문은 AI 애플리케이션을 **왜** 만들고 싶은지다.
  
### 애플리케이션에서 AI와 사람의 역할
- 애플의 ‘제품에 AI를 활용하는 방법’ 정리 문서
    - **핵심적(Core)**: AI가 있어야 작동할 수 있는 앱 VS **보완적(Auxiliary)**: AI 없이도 작동할 수 있는 앱
    - **반응형(Reactive)**: 사용자 요청에 반응 VS **선제형(Proactive)**: 사용자가 요청하기 전 **적절한 시점을** 예측하여 제공
    - **동적(Dynamic): 환경에 따라 사용자 피드백을 통한 업데이트** vs **정적(Static)**: 주기적으로 업데이트

> Q: FaceID가 동적이라고 그러면 사용자가 나이가 듦(10살 →20살)에 따라 점차 업데이트를 진행하는 것일까?

> ChatGPT의 답: 애플의 **Face ID**가 **동적**이라고 표현된 이유는 **사용자의 얼굴 변화**를 **지속적으로 인식하고 반영**하는 방식입니다. 그렇다면 **10살부터 20살까지** 얼굴이 **자연스럽게 변화**한다고 가정했을 때, **Face ID는 해당 변화를 반영**하는 방식으로 **동적으로 업데이트**됩니다. 이 과정은 매일 **사용자의 얼굴이 조금씩 변하는 것**을 감지하고, 이를 **점진적으로 반영**하는 방식으로 이루어집니다.

#### AI 제품 방어 가능성
- AI 애플리케이션을 독립형 제품으로 판매한다면 방어 가능성(defensibility)을 고려하는 것이 중요하다.
- 낮은 진입 장벽은 축복이자 저주다.(내가 쉽게 만들면 다른 사람도 쉽게 만든다.)
- 파운데이션 모델 위에 애플리케이션을 만든다는 건 모델들 위에 하나의 계층을 얹는 셈이다. 이는 파운데이션 모델의 성능이 좋아지면 우리가 제공하는 계층이 모델에 흡수되어 애플리케이션이 쓸모없게 될 수 있다는 것을 의미한다.
- AI 분야의 경쟁 우위는 **기술력, 데이터, 유통력**

### 2) 기대치 설정

- AI 애플리케이션을 개발할 때 **기대치**를 설정하는 것이 중요(성공이 어떤 모습일까?)

#### 2-1) 비즈니스 지표** (챗봇의 경우):

1. 자동화하고 싶은 고객 메시지의 비율은?
2. 얼마나 더 많은 메시지를 처리할 수 있어야 하는가?
3. 얼마나 더 빨리 응답할 수 있는가?
4. 얼마나 많은 인력을 절감할 수 있는가?

→ 이러한 충족이 반드시 사용자를 만족시킨다는 의미는 아님

#### 2-2) 사용자 만족을 위한 최소 성능 지표:

1. 챗봇 응답의 품질을 측정하는 품질 지표
2. **TTFT (Time to First Token)**: 첫 응답 시간이 얼마나 빠른지, **TPOT (Tokens per Output Time)**: 초당 생성되는 토큰 수
3. 추론 요청당 비용
4. 해석 가능성과 공정성 같은 지표

### 3) 마일스톤 계획

AI 애플리케이션의 **초기 데모가 최종 제품을 보장하지 않는다**

- **초기 프로토타입**이 잘 작동한다고 해서 **실제 서비스**가 잘 작동한다는 보장은 없다.
- **운영 환경에서의 안정성**, **확장성**, **비용 효율성** 등을 충분히 고려해야 함

### 4) 유지보수

- AI 추론 비용은 시간이 지나면서 급격히 감소한다. (앞으로도 그럴 것)
    - **모델 최적화, 컴퓨팅 자원 효율화, 효율적인 모델 등장**

![그림 1-11 AI 추론 비용은 시간이 지나면서 급격히 감소한다.](images/AIE_Page_69_Index_533.png)

그림 1-11 AI 추론 비용은 시간이 지나면서 급격히 감소한다.

## AI 엔지니어링 스택
AI 엔지니어링은 크게 **세 가지 계층**으로 나눠진다.

![그림 1-14 AI 엔지니어링 스택의 세 가지 계층](images/AIE_Page_73_Index_568.png)

그림 1-14 AI 엔지니어링 스택의 세 가지 계층

### **1) 애플리케이션 개발**

- 애플리케이션 개발 계층은 **AI 모델을 실제 사용자가 활용할 수 있는 형태로 구현**
- 모델에 적절한 프롬프트 + 필요한 컨텍스트를 제공
- 철저한 평가, 좋은 인터페이스 필수

### **2) 모델 개발**

- 모델 개발 계층은 **AI 모델 자체를 설계하고 훈련**하는 부분
- 모델링, 학습, 파인튜닝, 추론 최적화를 위한 프레임워크를 포함해 개발하기 위한 도구를 제공
- 전통적인 ML은 여기에 집중했다..

### **3) 인프라**

- 모델 서빙, 데이터와 컴퓨팅 관리, 모니터링을 위한 도구
- GPU, 분산 학습 시스템, API 배포

### AI 엔지니어링 vs ML 엔지니어링

1. **학습**
    - **ML 엔지니어링:** 파운데이션 모델이 없으므로, 필요한 모델을 직접 학습시켜야한다.
    - **AI 엔지니어링: 다른 사람이 학습시켜 놓은 모델을 가져다 쓴다(모델링과 학습보다는 모델 조정에 더 초점을 맞춘다)**
2. **컴퓨팅 자원**
    - AI 엔지니어링: ML 엔지니어링보다 더 크고, 더 많은 컴퓨팅 자원을 소비 / 더 높은 지연 시간을 발생시키는 모델을 다룸
        
        → 효율적인 학습과 추론 최적화에 대한 압박이 더 크다 / GPU와 대규모 클러스터를 다룰 줄 아는 엔지니어에 대한 수요 증가
        
3. **개방형 출력**
    - **AI 엔지니어링**: 모델은 **개방형 출력**을 제공하며 같은 **프롬프트**에도 수많은 **응답을 생성**할 수 있다.
    - 유연성을 제공하지만 그만큼 평가하는 것이 더 어렵다..

**+ ) 모델 조정**

  > AI 엔지니어링은 모델 개발보다는 **모델 조정과 평가에 더 중점**을 둔다는 점에서 ML 엔지니어링과 차이가 있다.
- **프롬프트 기반 기법**: **프롬프트**를 **최적화**하여 모델이 더 정확하고 적합한 답변을 생성하도록 유도 **(가중치 업데이트 필요 X)**
- **파인튜닝**: 기존 모델에 대해 **소규모의 데이터셋**을 활용하여 **모델의 성능을 개선(가중치 업데이트 필요 O)**



모델 조정 기법은 모델 가중치 업데이트 여부에 따라 두 가지 범주
1. **프롬프트 엔지니어링을 포함한 프롬프트 기반 기법은 모델 가중치를 업데이트하지 않고도 모델의 동작을 조정**
- 모델 자체를 바꾸는 대신 지시와 컨텍스트를 제공하여 모델의 반응을 원하는 방향으로 유도하는 것
- 프롬프트 엔지니어링은 비교적 쉽게 시작할 수 있고 데이터도 거의 필요 없다는 장점
- 하지만 복잡한 작업이나 성능에 대한 엄격한 기준이 있는 애플리케이션이라면, 프롬프트 엔지니어링만으로는 충분하지 않을 수 있다.

2. **파인튜닝은 모델 가중치를 업데이트 해야한다.**
- 모델 자체를 변경해 새로운 작업에 맞게 조정한다.
- 파인튜닝은 더 복잡하고 더 많은 데이터가 필요하지만 모델의 품질, 지연 시간, 비용을 크게 개선할 수 있다.
- 복잡한 작업에는 파인튜닝 기법이 많이 활용된다.

### 모델 개발
- 전통적인 ML 엔지니어링과 가장 밀접하게 연관된 계층
- **모델링과 학습, 데이터셋 엔지니어링, 추론 최적화** 라는 세가지 구성 요소가 있다.

#### 1) 모델링과 학습
- 모델 아키텍처를 고안하고 학습하고 파인튜닝하는 과정
ex) 구글의 텐서플로, 허깅페이스의 트랜스포머, 메타의 파이토치
- ML 모델을 개발하려면 전문적인 ML 지식(클러스터링, 협업 필터링 같은 다양한 ML 알고리즘과 피드포워드, 합성곱, 트랜스포머와 같은 신경망 아키텍처 그리고 경사하강법, 손실 함수 등의 개념을 포함해 모델이 어떻게 학습하는지)
- 파운데이션 모델을 사용할 수 있게 되면서 AI 애플리케이션을 개발하는 데 ML 지식이 더 이상 필수가 아니게 됐지만 여전히 ML 지식은 매우 가치가 있다. 사용할 수 있는 도구의 폭을 넓혀주고 모델이 예상대로 작동하지 않을 때 문제를 해결하는 데 도움이 된다.

**사전학습**
- 모델을 처음부터 학습하는 것, 모델 가중치가 무작위로 초기화
- 압도적으로 가장 많은 자원 필요, 많은 시간 필요

**파인튜닝**
- 이미 학습된 모델을 추가로 학습하는 것
- 모델 가중치는 이전 학습 과정에서 얻어진 값
- 사전학습보다 적은 자원

**사후 학습**
- 파인튜닝과 거의 같은 과정이다.
- 업계에서는 두 용어 구분하는데 보통 '누가'학습을 수행하는지를 기준으로 삼는다.
- 모델 제공업체가 수행하면 사후 학습, 애플리케이션 개발자가 수행하면 파인튜닝

+) 프롬프트 엔지니어링을 하면서 이를 파인튜닝이라고 부르면 엄연히 틀림

#### 2) 데이터셋 엔지니어링
- AI 모델의 학습과 조정에 필요한 데이터를 선별하고 생성하며 주석을 다는 것
- 전통적인 ML 엔지니어링에서 대부분의 활용 사례는 '폐쇄형'으로, 모델의 출력은 미리 정의된 값들 중 하나만 될 수 있다. ex) 스팸 분류
- 하지만 파운데이션 모델은 개방형이다.(개방형 질의에 주석을 다는 게 폐쇄형에 주석을 다는 것보다 훨씬 어렵고 이메일이 단순히 스팸인지 구분하는 것보다 글을 쓰는 것이 더 어렵다.)
- ML 엔지니어링: 정형 데이터, 파운데이션 모델을 이용한 AI 엔지니어링: 비정형 데이터
- 파인튜닝은 프롬프트 엔지니어링보다 더 많은 데이터가 필요하다.

#### 3) 추론 최적화(Inference optimization)
- 모델을 더 빠르고 저렴하게 만드는 것
- 파운데이션 모델의 한 가지 어려운 점은 이들이 종종 자기회귀적(autoregressive)이다.
    - 자기회귀적이란? 순차적인 데이터(sequence data)를 생성하는 방식
![](https://velog.velcdn.com/images/dkan9634/post/57adcce4-e551-41c7-85c3-a85142106681/image.png)

### 애플리케이션 개발
- 개발 계층은 평가, 프롬프트 엔지니어링, AI 인터페이스 역할로 구성
#### 1) 평가
- 위험을 완화하고 기회를 발견하는 과정
- 모델을 선택하고 진행 상황을 벤치마크하며, 애플리케이션의 배포 준비 여부를 판단하는 데 쓰인다.

#### 2) 프롬프트 엔지니어링 및 컨텍스트 구성
- 프롬프트 엔지니어링은 모델 가중치를 변경하지 않 고 입력만으로 AI 모델에서 원하는 동작을 이끌어 내는 것
- 단순히 모델에게 무엇을 하라고 말하는 것이 아니라 **주어진 작업을 수행하는 데 필요한 컨택스트와 도구를 모델에게 제공하는 것** 이다.

#### 3) AI 인터페이스
사용자가 AI와 상호작용하는 인터페이스

이전에는 조직의 제품에 통합되었으나, 이제는 독립 제품으로 제공하거나 다른 사람들이 개발한 제품에 탑재할 수 있다.

-   독립형 웹, 데스크탑, 모바일 애플리케이션
-   브라우저 확장 프로그램
-   슬랙, 디스코드, 위챗, 왓츠앱 등 채팅 애플리케이션에 통합된 챗봇
-   VS 코드, 쇼피파이, 마이크로소프트 365를 포함한 여러 제품이 개발자가 플러그인과 애드온 형태로 AI를 통합할 수 있는 API를 제공한다. (이런 API를 통해 AI Agent가 상호작용)
-   음성 기반, 실체화된 형태(VR, AR)일 수도 있음
![](https://velog.velcdn.com/images/dkan9634/post/493b57fb-2f89-4dc8-a92f-8e6f4e78ca48/image.png)

표 1-6 AI  엔지니어링과 ML 엔지니어링에서 앱 개발의 각 범주별 중요도



### AI 엔지니어링 vs 풀스택 엔지니어링
이전에는 ML 프레임워크들이 대부분 파이썬 API만 지원했으나 LangChain.js, Transformers.js, 오픈AI의 Node 라이브러리, Vercel의 AI SDK 등 자바스크립트 API에 대한 지원이 늘어나고 있다.

아이디어를 빠르게 데모로 만들고, 피드백을 받고, 개선할 수 있는 능력이 있는 웹 개발이나 풀스택 배경을 가진 사람들이 점점 늘어나고 있다.

-   ML: 모델 개발 & 제품 개발이 분리된 프로세스, ML 엔지니어는 제품의 의사 결정에 거의 참여하지 않았음
-   AI : AI 엔지니어가 제품 개발에 훨씬 더 많이 참여하는 경향이 있음
  

![그림 1-16 새로운 AI 엔지니어링 워크플로는 빠르게 반복할 수 있는 사람에게 유리하다.](images/AIE_Page_83_Index_666.png)

그림 1-16 새로운 AI 엔지니어링 워크플로는 빠르게 반복할 수 있는 사람에게 유리하다.

**웹 개발에 강점을 가진 AI 엔지니어**들이 등장하며 **AI 모델을 쉽게 활용**할 수 있는 다양한 툴들이 확산되고 있다.
전통적인 **ML 엔지니어링**은 **데이터 수집**과 **모델 학습** 중심인 반면, **AI 엔지니어링**은 **제품 개발**에 중점을 두고 **웹 툴**과 **자바스크립트 API**를 사용하여 **모델과 데이터**를 바탕으로 제품을 만든다.

## 마치며

- **이 장의 목적**
    - **파운데이션 모델**의 등장으로 하나의 분야로 자리잡게 된 **AI 엔지니어링**
    - 애플리케이션을 만드는 데 필요한 과정에 대해서 배움

- **전체 요약**
    - **파운데이션 모델 등장으로 AI 진입 장벽 하락**: LLM에서 파생된 파운데이션 모델(Foundation Models, FM)은 **새로운 능력(범용성)** 을 제공하고, **MaaS(Model-as-a-Service)** 형태로 제공되어 AI 애플리케이션 개발의 진입 장벽을 크게 낮추며 AI 엔지니어링의 성장을 가속화
    - **AI 엔지니어링의 핵심 역할과 과제**: AI 엔지니어링은 파운데이션 모델을 기반으로 실제 애플리케이션을 **설계하고 구축**하는 과정(모델 조정 및 평가 포함)을 뜻한다.
    - **ML 엔지니어링과의 차별점**: AI 엔지니어링은 모델의 직접 학습보다 **조정(프롬프트 엔지니어링, 파인튜닝)** 에 중점을 두고, 더 크고 자원 소모가 많은 모델을 다루며, **개방형 출력**을 평가해야 한다는 차이점이 있다.
    - **AI 엔지니어링 스택 및 Workflow**: AI 엔지니어링 스택은 **애플리케이션 개발, 모델 개발, 인프라** 계층으로 구성된다.
