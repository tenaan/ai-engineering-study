# chap 8. 데이터셋 엔지니어링

**데이터셋 엔지니어링**의 목표: 최고의 모델을 학습할 수 있는 데이터셋을 만드는 것(할당된 예산 내에서)

# 데이터 큐레이션
- 모델이 어떻게 학습하는지, 학습에 도움이 되는 자원이 무엇인지 이해해야 하는 분야
- 어떤 데이터가 필요한지는 하려는 일과 모델에게 무엇을 가르치고 싶은지에 달려 있다.
   - **자기 지도 학습 파인튜닝**에는 데이터 시퀀스가 필요
   - **지시 파인튜닝**에는 (지시) 응답 형식의 데이터가 필요
   - **선호도 파인튜닝**에는 (지시, 선호 응답, 비선호 응답) 형식
   - **보상 모델 학습**에는 선호도 파인튜닝과 같은 형식을 쓰거나 ((지시, 응답), 점수) 형식으로 각 예시에 주석이 달린 점수가 있는 데이터
- 학습 데이터에는 모델이 학습했으면 하는 행동을 먼저 보여줘야 한다.
- 좋은 데이터 주석을 확보 하는 건 항상 어렵지만, CoT 추론이나 도구 사용 같은 복잡한 행동을 모델에게 가르치려면 더욱 어렵다.

#### CoT 
- 모델이 최종 답을 내기 전 문제를 단계별로 풀어보도록 유도
- 모델이 단계별 응답을 생성하도록 가르치려면 학습 데이터에 CoT 응답이 들어 있어야 한다.
   - **파인튜닝 데이터에 단계별 응답**을 넣으면 여러 크기의 모델들이 CoT 작업에서 훨씬 좋은 성능을 보이고, 어떤 작업에서는 정확도가 거의 두 배까지 올라간다고 한다.
     
![](https://velog.velcdn.com/images/dkan9634/post/9e744986-3ebf-41a7-a19c-69fc9b2ee765/image.png)

-> CoT 데이터셋은 다른 지시 데이터셋에 비해 만들기 어렵다.

- 대화 인터페이스가 있는 애플리케이션용 데이터를 큐레이션할 땐, **싱글 턴 데이터가 필요한지, 멀티 턴 데이터가 필요한지, 아니면 둘 다 필요한지 고려**해야 한다.
   - 싱글 턴 데이터는 모델이 개별 지시에 답하는 법을 가르친다.
   - 멀티 턴 데이터는 모델에게 작업을 해결하는 방법을 가르친다.(실제 대부분의 작업은 주고받기를 포함하기 때문)
- 데이터 큐레이션은 모델이 새로운 행동을 배우도록 돕는 새 데이터를 만드는 것 뿐만 아니라, 나쁜 행동을 잊게 하려고 기존 데이터를 없애는 것도 포함한다.
- 데이터 큐레이션은 **데이터 품질, 데이터 커버리지, 데이터 양**이라는 세 가지 기준을 따른다.

## 데이터 품질
- 성능: 적은 양의 고품질 데이터 > 많은 양의 노이즈 있는 데이터
   - 노이즈가 있는 데이터란 관련이 없거나 일관성이 없는 데이터
- **고품질의 데이터**는 사람마다 기준이 조금씩 다른데 일반적으로 여섯 가지 특성을 가진 데이터를 고품질이라고 본다.
   - 관련성
   - 작업 요구사항 부합
   - 일관성
   - 올바른 형식
   - 충분한 고유성: 데이터에서 고유한 예시를 말한다.
   - 규정 준수

## 데이터 커버리지
- 다양한 사용 패턴을 담은 데이터를 확보하는 것이 모델이 좋은 성능을 내는 핵심
- 좋은 커버리지를 확보하려면 **데이터의 다양성이 필수적**이므로, 이 개념을 **데이터 다양성**이라고 부르기도 한다.
- 라마 3의 성능 향상은 **주로 데이터 품질과 다양성 개선, 그리고 늘어난 학습 규모에 의해** 이뤄졌다.
   - 해당 논문엔 사전 학습, 지도 파인튜닝, 선호도 파인튜닝 적용
   - 라마 3는 사후 학습에 합성 데이터를 사용하므로, 사람이 생성한 데이터와 AI가 생성한 데이터의 비율 또한, 중요한 요소로 고려된다.
   - 연구자들은 소량의 고품질 코드와 수학 데이터로 모델을 **어닐링(annealing)**하면 (학습률을 점진적으로 낮추면서 코드와 수학 데이터를 점진적으로 늘려가며 모델을 학습 시키면) 주요 벤치마크에서 모델 성능을 높일 수 있다고 밝혔다.
   
   ![](https://velog.velcdn.com/images/dkan9634/post/7f21f652-362a-4462-98fc-203d4b01805c/image.png)

- 데이터 다양성과 품질이 미치는 영향을 평가한 실험(크기는 2000개의 예시로 같지만, 특성이 다른 세 개의 데이터셋으로 70억 파라미터 언어 모델을 학습 시켰다.)
![](https://velog.velcdn.com/images/dkan9634/post/622532cd-f90e-4476-af92-8009d9ba3a7d/image.png)

## 데이터 양
- 얼마나 많은 데이터가 필요한지 묻는 것 = 얼마나 많은 돈이 필요한지 묻는 것
- 데이터 품질과 데이터 다양성 외에도 필요한 데이터 양을 결정하는 요소 3가지
   - **파인튜닝 기법**
      - (지시, 응답) 쌍이 수만 개 ~ 수백만 개 있다면 전체 파인튜닝 해볼 만하다.
      - 수백 개나 수천 개 정도 밖에 없다면 **PEFT**가 가장 효과적일 것
   - **과제 복잡성**
      - 제품 리뷰가 긍정, 부정인지 분류하는 것 같은 간단한 과제는 ㄱ므융 서류에 대한 질의응답 같은 복잡한 과제보다 훨씬 적은 데이터로 충분
   - **기본 모델의 성능**
      - 기본 모델이 원하는 성능에 가까울수록 목표에 도달하는 데 필요한 예시가 적다.
      - 즉, 기본 모델이 이미 똑똑할수록, 나중에 파인튜닝할 때 필요한 데이터가 적다
      - ![](https://velog.velcdn.com/images/dkan9634/post/7f1b31a6-d478-4276-9e16-e12bdf07b621/image.png)
      
- 간단히 말해, **데이터가 적다면 더 고급 모델에 PEFT 방법을 사용하는 게 좋고 반대로 데이터가 많다면 더 작은 모델로 전체 파인튜닝을 사용하는 게 좋다.**
- 대규모 데이터셋 구축에 투자하기 전, 먼저 잘 만들어진 소규모 데이터셋(50개 예시)으로 시작해서 파인튜닝이 모델을 개선할 수 있는지 확인해 보는 것이 좋다. 이런 소규모 데이터셋만으로도 원하는 성능을 달성할 수 있다면 더할 나위 없이 좋다.
- 하지만 소규모 데이터셋으로 파인튜닝해도 모델이 개선되지 않는다고 성급하게 결론내리지는 말아야 한다.
   - 파인튜닝 결과에 영향을 미칠 수 있는 요소는 데이터 외에도 하이퍼 파라미터 선택, 데이터 품질, 프롬프트 작성 방식 등 모두 영향을 미친다.
   
#### TIP) 고품질 데이터가 적을 때 파인튜닝 전략
**1. 자기 지도 학습 → 지도 학습**
- 상황
   - 법률 QA 모델을 만들고 싶지만 (질문, 응답) 데이터는 적고, 법률 문서 자체는 매우 많을 때
- 전략
   - 먼저 법률 문서를 사용해 자기 지도 학습(Self-Supervised Learning) 방식으로 파인튜닝
   - 이후 소량의 (질문, 응답) 데이터로 지도 학습 파인튜닝 수행
- 효과
   - 모델이 도메인 지식(법률 용어, 문맥) 을 먼저 학습
   - 적은 QA 데이터로도 높은 성능 도달 가능

**2. 관련성 낮은 데이터 → 관련성 높은 데이터**
- 상황
   - 제품 리뷰 감성 분류 모델을 만들고 싶지만 제품 리뷰 데이터는 적고, 트위터 감성 데이터는 매우 많을 때
- 전략
   - 트위터 감성 분류 데이터로 먼저 파인튜닝
   - 이후 제품 리뷰 감성 데이터로 추가 파인튜닝
- 효과
   - 감성 표현에 대한 일반적 패턴을 먼저 학습
   - 도메인 특화 데이터가 적어도 성능 개선 가능
   
**3. 합성 데이터 → 실제 데이터**
- 상황
   - 의료 보고서로 질병 예측 모델을 만들고 싶지만 데이터 민감성 때문에 실제 데이터가 매우 제한적일 때
- 전략
   - AI 모델을 사용해 대량의 합성 데이터(synthetic data) 생성
   - 합성 데이터로 먼저 파인튜닝
   - 이후 소량의 실제 의료 데이터로 추가 파인튜닝
- 주의점
   - 합성 데이터는 편향(bias) 이 존재할 수 있음 (두 단계 사이의 전환 조절이 매우 중요)
   - 잘못하면 많은 컴퓨팅 자원을 쓰고도 고품질 데이터만으로 학습했을 때보다 성능이 낮아질 수 있음
   
   
- 작은 데이터셋으로 실험해보면 앞으로 데이터가 얼마나 더 필요한지 추정할 수 있다.
   - 현재 데이터셋의 일부분(25%, 50%, 100%)으로 모델을 파인튜닝하고 데이터셋 크기에 따른 성능 변화를 그래프로 그려보자.
      - 데이터셋이 커질수록 성능이 가파르게 올라간다면 데이터를 두 배로 늘렸을 때 성능도 크게 좋아질 것이다.
      - 성능 증가폭이 없다면(평평) 데이터를 두 배로 늘려도 개선 효과는 미미할 것이다.
      
      ![](https://velog.velcdn.com/images/dkan9634/post/bd39ec55-adfb-4bed-8bd2-101a89c1e81b/image.png)

- 파인튜닝 예시가 많을수록 모델 성능이 일반적으로 좋아지지만, 예시의 다양성도 중요하다.
   - 논문에 따르면 파인튜닝 과제 수가 9개에서 282개로 늘어났을 때 모델 성능이 크게 향상됐다. 
   - 282개 과제를 넘어서면 성능 증가가 둔화되기 시작했지만, 1836개 과제까지는 계속해서 조금씩 개선됐다. 
   => **파인튜닝할 때 다양한 과제를 경험하는 게 모델에게 큰 도움이 된다는 걸 보여준다.**
   ![](https://velog.velcdn.com/images/dkan9634/post/b859e989-f0c8-477f-92e6-3de172610f3a/image.png)
- 데이터 다양성은 과제 종류(요약, 질의응답 등), 주제 다양성(패션, 금융, 기술 등), 출력 형식(JSON, 예/아니오 등)으로 나타날 수 있다.

## 데이터 수집과 주석
- 데이터 수집의 목표: 사용자 프라이버시를 존중하고 규정을 지키면서 필요한 품질과 다양성을 갖춘 충분한 크기의 데이터셋을 만드는 것
- 데이터 수집에는 공개 데이터 수집, 독점 데이터 구매, 데이터 주석 작업, 데이터 합성 등의 방법으로 데이터를 모으는 과정이 포함된다.

#### 공개 데이터셋 리소스
**데이터셋을 사용하기 전에 항상 라이선스를 확인하자.** 데이터가 어디서 나온 것인지 최대한 파악하려고 노력하자. 데이터셋이 상업적 사용을 허용하는 라이선스를 가지고 있더라도, 그 안의 일부가 허용하지 않는 출처에서 나왔을 수 있다.
1) `Hugging Face / Kaggle`: 다양한 도메인의 대규모 공개 데이터셋을 가장 쉽게 구할 수 있는 대표 플랫폼
2) `Google Dataset Search`: 잘 알려지지 않았지만 웹 전반의 데이터셋을 검색할 수 있는 유용한 도구
3) 정부 오픈 데이터 포털: `Data.gov, data.gov.in` 등 공공기관이 제공하는 방대한 공식 데이터
4) `ICPSR`: 사회과학·설문·행동 데이터에 특화된 대규모 연구 데이터 저장소
5) `UCI ML Repository / OpenML`: 머신러닝 벤치마크로 널리 쓰이는 전통적인 데이터셋 저장소
6) `Open Data Network`: 다양한 출처의 공개 데이터를 통합 검색할 수 있는 플랫폼
7) `AWS Open Data`: 클라우드 환경에서 바로 활용 가능한 공개 데이터셋 모음
8) ML 프레임워크 내장 데이터셋: TensorFlow 등에서 즉시 불러올 수 있는 소규모 실습용 데이터
9) 평가 벤치마크 데이터셋: lm-evaluation-harness처럼 파인튜닝 성능 평가에 적합한 표준 데이터
10) `Stanford Large Network Dataset Collection`: 그래프·네트워크 분석을 위한 전문 데이터셋 저장소

---
# 데이터 증강 및 합성
- 데이터를 프로그래밍으로 생성할 수 있는 건 업계 전체의 오랜 목표
   - 일반적으로 쓰이는 두 가지 방법
   1. **데이터 증강**
   - 기존 데이터(실제 데이터)에서 새로운 데이터를 만든다.
   2. **데이터 합성**
   - 실제 데이터의 특성을 모방하는 데이터를 생성한다.
   - ex) 마우스가 웹페이지에서 어떻게 움직이는지 시뮬레이션해서 봇의 움직임 패턴에 대한 데이터를 생성할 수 있다.
- 다시 말해, 증강된 데이터는 실제 데이터에서 나오지만 합성 데이터는 실제가 아니다.

## 데이터 합성을 하는 이유
- 합성 데이터가 매력적인 이뉴는 데이터의 세 가지 주요 측면인 **양, 커버리지, 품질을 개선**할 수 있다. 
- 또한, 프라이버시 문제를 해결하고 모델을 증류하기 위해서 데이터를 합성할 수 있다.

## 전통적인 데이터 생성 기법
- 데이터 합성은 AI에만 있는 기술이 아니다.
- 사람이 만들지 않고 **알고리즘으로 데이터를 생성하는 것**을 **절차적 생성**이라고 부른다.
   - 게임에서 레벨, 맵, 아이템, 캐릭터 같은 콘텐츠를 실시간으로 만드는 데 많이 쓰인다.

### 규칙 기반
- 데이터를 생성하는 가장 간단한 방법은 **미리 정해둔 규칙과 템플릿을 사용**하는 것
- ex) 신용카드 거래 내역을 만들려면 거래 템플릿으로 시작해서 Faker 같은 난수 생성기로 각 필드를 채운다.
- 기존 데이터에 **간단한 변형**을 가해서 새로운 데이터를 절차적으로 생성할 수도 있다.
![](https://velog.velcdn.com/images/dkan9634/post/f082845b-08c2-429b-8e92-6448d89c8a74/image.png)

- 흥미로운 변형 중 하나는 **섭동(peturbation)**
   - 기존 데이터에 노이즈를 넣어서 새로운 데이터를 생성하는 것
   - 이미지: 밝기 조정, 눈 효과 추가, 대비 변경, 노이즈 추가 등
      - ex) `ImageNet-C`, `ImageNet-P`
   - 텍스트: 토큰을 무작위 단어로 교체
      - ex) BERT에서는 토큰의 1.5%를 교체했다.

### 시뮬레이션
- 실제 세계에서 실험을 통해 데이터를 모으는 건 비용도 많이 들고 위험할 수 있어서, 이런 실험들을 가상으로 시뮬레이션할 수 있다.
   - ex) 자율주행차가 고속도로에서 말을 만났을 때 반응을 테스트하기 위해 시뮬레이션
- 시뮬레이션을 사용하면 사고나 물리적 손상 없이 최소 비용으로 여러 실험을 할 수 있다.

## AI 기반 데이터 합성
- AI의 바꿔쓰기나 번역 능력은 기존 데이터셋을 늘리는 데 사용할 수 있다.
   - ex) "내 비밀번호 어떻게 재설정해?"
      - AI가 이를 바꿔써서 새로운 질의 세 개를 만들 수 있다.
      - "비밀번호를 잊어버렸어", "비밀번호를 어떻게 변경할 수 있어?", "비밀번호 재설정 단계"
- **역번역**으로 번역품질을 확인할 수도 있다.
   - 원래 영어 문장이 X고 번역된 한국어 문장이 Y라고 하면 다른 모델로 번역본을 다시 원래 언어로 번역해서 X'를 만든 다음, X'를 원래 문장 X와 비교할 수 있다.
- AI는 사전 학습과 사후 학습 모두를 위한 데이터를 생성할 수 있지만, **합성 데이터**는 사전 학습보다 **사후 학습**에서 훨씬 더 자주 쓰인다. 
   - 이런 이유는 사전 학습의 목표가 모델의 지식을 늘리는 것인데, AI가 기존 지식을 다른 형식으로 합성할 수 있어도 새로운 지식을 합성하긴 더 어렵기 때문이다.

### 지시 데이터 합성
지시 파인튜닝에서는 각 데이터가 지시(instruction)와 응답(response) 으로 구성되며, 이 둘은 AI·사람 어느 쪽이든 생성할 수 있다.

- **지시·응답 생성 방식**
   - **지시 생성**: 주제·키워드·지시 유형 목록을 만들고, 템플릿 기반으로 다수의 지시를 생성
   - ** 응답 생성**: 하나의 지시에 대해 하나 또는 여러 개의 응답 생성 가능
- **대표 사례**
   - UltraChat: ChatGPT로 일상 주제 → 세부 주제 → (지시, 응답) 데이터 생성
   - Alpaca: 소량의 Seed 데이터(Self-Instruct) → GPT-3로 대규모 (지시, 응답) 확장
   ![](https://velog.velcdn.com/images/dkan9634/post/9366d938-4b69-49a4-8618-42b7b8de9fbb/image.png)


- 고급 합성 기법
   - 역지시(Reverse Instruction): 기존의 고품질 긴 콘텐츠(책, 위키 등)로부터
→ 그 콘텐츠를 유도할 수 있는 지시를 생성해 환각을 줄이고 지시 품질을 향상

   - 반복적 자기 개선 루프:
1. 소량 데이터로 약한 모델 학습
2. 모델로 고품질 지시 생성
3. 다시 파인튜닝
4. 목표 성능까지 반복

- **롱 컨텍스트 파인튜닝**
   - 긴 문서를 짧은 덩어리로 분할
   - 각 덩어리마다 (질의, 응답) 생성
   - 응답 시 원래의 긴 문서를 컨텍스트로 사용 → 확장 컨텍스트 이해 능력 학습

- **코드 지시 데이터 합성** (LLaMA 3 사례)
   - AI로 문제 설명 → 해결 코드 생성 → 테스트 생성 → 오류 수정 → 번역·문서화
   - 파서·린터·단위 테스트로 품질 검증
   - 통과한 예시만 파인튜닝 데이터로 사용
   - 이 파이프라인으로 수백만 개 이상의 고품질 합성 코드 데이터 생성 가능

> 지시 데이터 합성은 AI를 활용해 고품질 파인튜닝 데이터를 대규모로 생성하고, 반복적·검증 기반 파이프라인으로 품질을 보장하는 전략이다.

### 데이터 검증
- 데이터 품질이 모델 성능을 좌우하므로, 합성 데이터도 반드시 검증이 필요하다.
- 검증 방법은 크게 두 가지:
1. 기능적 정확성(코드 실행, 테스트 등)
2. AI 검증기(AI verifier) 를 이용한 품질 평가(점수화, 분류, 기준 충족 여부 판단)
- 휴리스틱·이상 탐지로 반복, 너무 짧거나 긴 지시, 입력 복사형 응답 등 저품질 예시를 제거한다.

=> 합성 데이터의 최종 평가는 모델 성능이 실제로 개선되는지로 판단해야 한다.

#### AI 생성 데이터의 한계
- 품질 차이: 인간 데이터보다 품질이 낮을 수 있음
- 피상적 모방 한계: 겉모습만 따라 배우고 진짜 추론·일반화는 못할 수 있음
- 모델 성능 저하 위험: 잘못된 합성 데이터가 학습을 망칠 수 있음
- 데이터 계보 불투명: 데이터 출처 추적이 어려워짐

> 합성 데이터는 강력하지만, 검증 없이는 ‘쓰레기가 들어가면 쓰레기가 나온다(Garbage In, Garbage Out)’는 원칙을 피할 수 없다.

### 모델 성능 저하 & 데이터 계보 문제
- AI 생성 데이터만 반복 학습하면 성능이 오히려 떨어질 수 있음 → 이를 모델 붕괴(model collapse) 라고 한다.
- 모델 붕괴는 VAE, GMM, LLM 등 다양한 모델에서 발생하며, 사전학습·사후학습 모두에서 나타날 수 있다.
- 원인 중 하나는 모델이 확률이 높은(안전한) 패턴만 반복 생성하고, 드물지만 중요한 패턴을 점점 잊어버리기 때문.
- AI 생성 데이터는 데이터 계보(provenance)가 불명확해져서
   - 저작권 침해 위험
   - 벤치마크 오염(평가 데이터로 학습했을 가능성)
   - 상업적 활용 및 성능 신뢰성 저하 문제가 발생한다.

> 합성 데이터는 보조적으로 사용해야 하며, 반복 사용 시 모델 붕괴와 데이터 계보 불투명성이라는 심각한 위험이 따른다.

## 모델 증류
- **지식 증류**라고도 한다.
   - 작은 모델(학생)이 큰 모델(교사)을 모방하도록 학습시키는 방법
   - 큰 모델의 지식이 작은 모델로 증류되어 들어간다고 해서 증류라는 용어를 쓴다.
- 전통적인 모델 증류의 목표: 배포용으로 더 작은 모델 만들기
   - ex) `DistilBERT`는 BERT 크기의 40%이지만 언어 이해 능력의 97%를 유지하고 60% 더 빠르다.

+) 그렇다고 모든 모델을 증류할 수 있는 건 아니다. 많은 모델 라이선스가 자신의 출력을 다른 모델, 특히 경쟁 모델 학습에 사용하는 것을 금지한다.

- 합성 지시 데이터는 LoRA 같은 어댑터 기반 기법과 함께 사용된다.
   - ex) BuzzFeed는 LoRA와 오픈 AI의 text-davinci-003이 생성한 예시를 사용해 Flan-T5 모델을 파인튜닝함. 모델 추론 비용을 80% 줄였지만, 모델 성능이 어느 정도인지는 불분명했다.
- **합성 데이터로 학습한다고 해서 모두 모델 증류인 것은 아니다.**

---
# 데이터 처리
## 데이터 검사
- 원시 데이터셋을 모은 후 먼저 **데이터를 살펴보고 그 품질을 파악**해야한다.
   - 기본 정보와 통계를 확인(데이터셋이 어디서 나왔는지, 어떻게 처리 됐는지, 다른 용도로는 어떻게 사용 됐는지)
- 다음으로 토큰 분포(어떤 토큰이 흔한지 보기 위해), 입력 길이, 응답 길이 등을 그래프로 그리자
   - 데이터가 특별한 토큰이 쓰였나? 데이터의 주제와 언어 분포를 구할 수 있는가? 이런 주제와 언어들이 우리의 과제와 얼마나 관련이 있는가?
![](https://velog.velcdn.com/images/dkan9634/post/d7755c1b-4389-4b3b-b147-dfa8e5f0fd45/image.png)

-> GPT-4는 동사-명사 조합이 더 넓고 다양하고 더 긴 응답을 생성하는 경향

- 이런 분포들을 데이터 출처, 시간, 주석자 등으로 나눠서 그려보자.
   - 더 길거나 짧은 응답, 또는 더 높거나 낮은 점수를 받는 질의 패턴이 있나? 이상값이 있는가? 이런 이상값으 원인은 무엇일까? 이것들을 어떻게 처리할 것인가?
- 점수가 정규분포를 따라야 한다면, 모든 주석자의 점수가 정규분포를 따르는가? 

## 데이터 중복 제거
- 중복된 데이터는 데이터 분포를 **왜곡**하고 모델에 **편향**을 만들 수 있다.
- 문서 데이터셋에서의 중복
   - **전체 문서 중복**: 같은 문서가 여러 번
   - **문서 내 중복**: 같은 단락이 한 문서에서 두 번
   - **문서 간 중복**: 같은 유명한 인용구가 여러 문서에서 나타나는 것
   => **무엇을 중복으로 볼지도 정의에 따라 다르다.**
   - 문서 수준, 단락 수준, 문장 수준, 토큰 수준
중복으로 간주되려면 어느정도 같아야 하는지

#### 데이터 중복을 제거하는 방법
1. **쌍대 비교**
- 정확한 일치, n-gram 유사도, 퍼지 매칭 또는 의미적 유사도 점수를 사용해 데이터셋의 각 예시를 다른 모든 예시와 유사도 점수를 계산
- 큰 데이터셋에서는 비용이 많이 든다.
2. **해싱**
- 서로 다른 버킷으로 해싱하고 같은 버킷에 속하는 예시들 중에서만 확인
- 해시 관련 중복 제거 방법에는 `MinHash`와 `Bloom filter`가 있다.
3. **차원 축소**
- 차원 축소 기법을 사용해 먼저 데이터의 차원을 줄인 후 쌍대 비교를 한다.

+) 중복 제거에 도움이 되는 라이브러리들 : `DupeGuru`, `Dedupe`, `datasketch`, `TextDistance`, `TheFuzz`, `deduplicate-text-datasets`

### 데이터 정리 및 필터링
- 모델을 성능 좋고 안전하게 만들려면 데이터를 정리해야 한다.

## 데이터 형식 맞추기
- 데이터를 중복 제거하고 정리했다면, **파인튜닝할 모델이 기대하는 형식**에 맞춰야 한다.
- 각 모델은 특정 토크나이저를 사용하고 특정 채팅 템플릿 형식의 데이터를 기대한다.
- 지도 파인튜닝을 한다면 데이터는 대부분 (지시, 응답) 형식일 것이다. 지시는(시스템 프롬프트, 사용자 프롬프트)로 더 세분화할 수 있다.
- 프롬프트 엔지니어링에서 파인튜닝으로 넘어갔다면, 파인튜닝에 쓰는 지시가 프롬프트 엔지니어링에서 쓰던 지시와 다를 수 있다.
   - 파인튜닝에선 지시에 보통 과제 설명이나 예시가 필요 없다.
   
> 프롬프트 예시는 그대로 파인튜닝 데이터가 될 수 있다
파인튜닝을 하면 프롬프트를 극단적으로 단순화할 수 있다
대신, 학습 데이터 형식 ≠ 추론 프롬프트 형식이면 성능이 무너진다
그래서 데이터 포맷 설계 자체가 모델 성능의 일부다

---
# Chap 9. 추론 최적화
이번 챕터에서는 **모델을 더 빠르고 저렴하게 만드는 방법**에 집중한다.

# 추론 최적화 이해하기
## 추론 개요
- 운영 환경에서 모델 추론을 실행하는 구성 요소를 **추론 서버**라고 한다.
   - 추론 서버는 여러 모델들을 호스팅하고 필요한 하드웨어를 사용할 수 있다.
   - 애플리케이션에서 요청이 들어오면 리소스를 할당해서 적절한 모델을 실행하고 결과를 사용자에게 반환한다.
   - 추론 서비스는 요청을 받아서 적절한 곳으로 보내고 추론 서버에 도달하기 전에 전처리하는 역할도 담당한다.
   ![](https://velog.velcdn.com/images/dkan9634/post/56221f1c-6a52-4ea7-990b-aa2adb463cd0/image.png)
   - 오픈AI나 구글에서 제공하는 **모델 API들이 추론 서비스**다.

### 연산 병목
- 최적화는 병목을 해결하는 일이다.
- 주요 연산 병목에는 **연산 제약과 메모리 대역폭 제약**이 있다.
#### 연산 제약
- 작업을 끝내는 데 걸리는 시간이 연산량에 따라 결정되는 경우
- ex) 암호 해독은 암호화 알고리즘을 뚫기 위해 복잡한 수학 연산을 많이 해야 해서 보통 연산 제약을 받는다.
- 해결: 더 많은 칩에 분산시키거나 연산 성능이 더 좋은 칩(FLOP/s 수치가 높은)을 활용해 속도를 높일 수 있다.

#### 메모리 대역폭 제약
- 시스템 내부의 데이터 전송 속도에 제약을 받는 경우
- 특히 메모리와 프로세서 간의 데이터 전송 속도가 핵심적인 병목 지점이 된다.
- ex) CPU 메모리에 데이터를 저장하고 GPU에서 모델을 학습한다면 CPU에서 GPU로 데이터를 옮기는 데 시간이 오래 걸릴 수 있다.
- 해결: 대역폭이 더 넓은 칩을 활용해 속도를 높일 수 있다.

- 수학적으로는 **산술 강도**로 연산이 어느 쪽 제약을 받는지 구분할 수 있다.
   - 산술 강도: 메모리 1바이트에 접근할 떄 몇 번의 산술을 하는지를 뜻한다.
=> 엔비디아 엔사이트 같은 프로파일링 도구를 쓰면 **루프라인 차트**로 작업에 **연산 제약인지 메모리 대역폭 제약인지** 볼 수 있다.

![](https://velog.velcdn.com/images/dkan9634/post/970fc80a-e2cb-436d-a454-3722b35cec90/image.png)

-> 차트가 지붕 모양과 비슷해 루프라인 차트라고 보르고, 하드웨어 성능 분석에 자주 쓰이는 방법

- 모델 구조와 작업 종류에 따라 연산 병목도 다르게 나타난다.
   - stable diffusion 같은 이미지 생성 모델 추론은 보통 연산 제약
   - 자기회귀 언어 모델 추론은 보통 메모리 대역폭 제약
- 트랜스포머 기반 언어 모델 추론은 **프리필**, **디코딩** 두 단계로 나뉜다.
   - **프리필**: 모델이 입력 토큰들을 병렬로 처리, 한 번에 처리할 수 있는 토큰 개수는 하드웨어가 정해진 시간에 실행할 수 있는 연산량에 달려 있다. => **연산 제약**
   - **디코딩**: 모델이 출력 토큰을 한 번에 하나씩 생성한다. 하드웨어가 얼마나 빨리 데이터를 메모리로 불러올 수 있는지에 따라 제한된다. => **메모리 대역폭 제악**
   
   ![](https://velog.velcdn.com/images/dkan9634/post/46c2571b-2e2c-48c2-afe8-1fc2f7fca062/image.png)

### 온라인과 배치 추론 API
- 많은 모델 제공 업체가 온라인과 배치, 두 종류의 추론 API를 제공한다.
- **온라인 API**: 지연 시간 최적화, 요청이 들어오면 바로 처리한다. **낮은 지연 시간**에 집중
- **배치 API**: 비용을 최적화, 요청을 모아서 한 번에 처리하거나 저렴한 하드웨어를 쓰는 등 다양한 최적화 기법을 쓸 수 있다. **높은 처리량**에 집중

## 추론 성능 지표
- 사용자는 지연 시간이 중요하지만 애플리케이션 개발자는 애플리케이션 운영 비용을 결정하는 처리량과 활용률도 신경 써야 한다.

### 지연 시간, TTFT, TPOT
- 지연 시간은 사용자가 질의를 보낸 시점부터 완전한 응답을 받기까지 걸리는 시간

#### 첫 토큰까지 걸리는 시간(TTFT)
- 프리필 단계에 해당하고 입력 길이에 따라 달라진다.

#### 출력 토큰당 시간(TPOT)
- 첫 번째 토큰 이후 각 토큰이 얼마나 빨리 생성되는지 측정

#### 토큰 간 시간, 토큰 간 지연 시간
- 비슷한 지표로 토큰 간 시간(TBT)과 토큰 간 지연 시간(ITL)이 있다.
- 둘 다 출력 토큰 사이 사이 걸리는 시간을 측정한다.

> 전체 지연 시간 = TTFT + TPOT*(출력 토큰 수)

### 처리량과 굿풋
#### 처리량 
- 추론 서비스가 모든 사용자와 요청을 통틀어서 **초당 몇 개의 출력 토큰을 만들어낼 수 있는지**를 측정
- 일부 팀은 처리량을 연산할 때 입력 토큰과 출력 토큰을 함께 세지만, 입력 토큰 처리(프리필)와 출력 토큰 생성(디코딩)은 병목 지점이 다르고, 최신 추론 서버에서는 둘을 분리해서 처리하는 경우가 많아 입력과 출력 처리량을 따로 연산해야 한다.
- 보통 처리량이라고 하면 출력 토큰을 의미한다.
- 처리량은 주로 token/s(TPS)로 측정한다. 여러 사용자에게 서비스한다면 token/s/user로 사용자가 늘어날 떄 시스템이 어떻게 확장되는지 평가하기도 한다.
- 처리량은 정해진 시간 동안 완료한 요청 개수로 측정할 수도 있다.
- 많은 애플리케이션에서 **초당 요청 수(RPS)**를 사용한다.
- 파운데이션 모델 기반 애플리케이션에서는 요청 하나가 완료되는 데 몇 초씩 걸릴 수 있어서 **분당 완료 요청수(RPM)** 많이 쓴다.
- 처리량이 높을수록 보통 비용이 낮다.
> 요청당 총비용 = 프리필 비용 + 디코딩 비용
+) 링크드인에 따르면 TTFT, TPOT를 조금 희생하면 처리량을 2~3배 올릴 수 있는 경우가 많다.

#### 굿풋
- 소프트웨어 수준 목표(SLO)를 만족하는 초당 요청 개수를 측정
![](https://velog.velcdn.com/images/dkan9634/post/0e3c9aa7-ec4d-4e5f-82ac-8090513bf5d4/image.png)

- TTFT 최대 200ms, TPOT 최대 100ms 추론 서비스가 분당 100개 요청을 완료할 수 있다고 하자. 이 100개 요청 중 30개만 SLO를 만족한다면 이 서비스의 굿풋은 30RPM이다.

### 활용률, MFU, MBU
- **활용률** 지표는 리소스가 얼마나 효율적으로 사용하고 있는지 측정
   - 보통 전체 사용 가능한 용량 중에서 실제로 쓰이고 있는 비율
   
사람들이 자주 보는 지표 중 하나가 GPU 활용률(GPU Utilization) 이다. 엔비디아에서 제공하는 공식 모니터링 도구인 nvidia-smi가 보여주는 이 지표는, GPU가 실제로 작업을 수행하고 있었던 시간의 비율을 의미한다.

예를 들어 GPU 클러스터에서 10시간 동안 추론을 수행했는데, 그중 5시간 동안만 GPU가 실제 연산을 했다면 GPU 활용률은 50%가 된다. 하지만 여기서 중요한 점은 GPU가 작업 중이라고 해서 성능을 효율적으로 쓰고 있다는 뜻은 아니라는 것이다.

극단적인 예를 들어보자. 어떤 GPU는 초당 100개의 연산을 처리할 수 있다. 그런데 실제로는 초당 1개의 연산만 계속 수행하고 있다. nvidia-smi 기준에서는 GPU가 쉬지 않고 연산을 하고 있으므로 **GPU 활용률은 100%**로 표시된다. 하지만 실제로는 GPU 성능의 1%만 사용하고 있는 셈이다.

즉, GPU 활용률은 “일하고 있느냐”만 보여줄 뿐, “얼마나 잘 쓰고 있느냐”는 알려주지 못한다.
그래서 이 지표만 보고 GPU를 잘 쓰고 있다고 판단하는 것은 위험하다.
그래서 등장한 개념이 MFU(Model FLOPs Utilization) 다.

#### MFU
- 시스템이 이론적으로 낼 수 있는 최대 FLOPs 성능 대비,
실제로 모델이 어느 정도의 연산 성능을 사용하고 있는지를 나타내는 지표다.
- 예를 들어, 칩 제조사는 초당 100 token 생성이 가능하다고 광고했지만 실제 추론 서비스에서는 초당 20 token만 생성된다면 이 경우 **MFU는 20%**가 된다.
- MFU는 GPU 활용률과 달리, 연산 성능을 얼마나 효율적으로 쓰고 있는지를 직접적으로 보여주는 지표다.
![](https://velog.velcdn.com/images/dkan9634/post/acc3db9a-b506-4474-8b5d-97af62cf8036/image.png)


#### MBU
- 메모리 효율을 보는 지표
- 연산 성능뿐 아니라 메모리 대역폭도 매우 비싸고 중요한 자원이다.
이를 평가하기 위한 지표가 MBU(Model Bandwidth Utilization) 다.
- 사용 가능한 메모리 대역폭 중, 실제로 모델이 사용하는 비율을 의미한다.
- 예를 들어, GPU의 최대 메모리 대역폭이 1 TB/s인데 실제 추론 과정에서 500 GB/s만 사용하고 있다면 **MBU는 50%**가 된다.
![](https://velog.velcdn.com/images/dkan9634/post/7b70492a-32d7-4683-b750-142fecd11b05/image.png)

-> 수치가 떨어지는 이유는 사용자가 늘어나면 연산 부하가 커져서 병목이 대역폭에서 연산으로 옮겨지기 때문인 것으로 보인다.

## AI 가속기
### 가속기의 정의
- 가속기는 단순하게 설명하면 **특정 종류의 연산 작업을 빠르게 처리하도록 만들어진 칩**
- 가장 널리 쓰이는 AI 가속기는 GPU
- CPU와 GPU의 주요 차이점은 CPU는 범용 작업용, GPU는 병렬 처리용으로 만들어졌다.
- 엔비디아 GPU의 성공은 많은 AI 워크로드의 속도를 높이기 위해 설계된 많은 가속기의 등장을 이끌었다. 여기에는 AMD의 최신 GPU, 구글의 텐서 처리 장치(TPU), 인텔의 하바나 가우디, 그래프코어의 지능형 처리 장치(IPU) 등이 포함된다.
- 추론 비용이 학습 비용을 넘어설 수 있고 이미 배포되어 운영 중인 AI 시스템은 ML 관련 비용의 최대 90%를 추론이 차지하는 것으로 나타났다.
- 하드웨어 아키텍처마다 메모리 레이아웃과 특화된 연산 유닛이 다르다.
![](https://velog.velcdn.com/images/dkan9634/post/660bb2bb-4ecd-4663-992f-00dc300eec9a/image.png)

   - 한 칩 안엔 여러 데이터 유형에 최적화된 다양한 연산 유닛이 함께 들어 있을 수 있다.
      - ex) **GPU**: 원래 벡터 연산을 지원했지만, 최신 GPU 대부분은 행렬과 텐서 연산에 특화된 텐서 코어를 포함한다. 
**TPU**: 처음부터 텐서 연산을 주된 연산 방식으로 삼아 만들어졌다.  

### 연산 성능
- 보통 칩이 정해진 시간에 수행할 수 있는 연산 수로 측정
- 가장 많이 쓰이는 지표: 초당 부동 소수점 연산 횟수를 측정하는 FLOP/s(보통 FLOPS로 표기)
- 칩이 1초에 수행할 수 있는 연산 횟수는 수치 정밀도에 따라 달라진다.
   - 정밀도가 높을수록 칩이 실행할 수 있는 연산은 줄어든다.
   ![](https://velog.velcdn.com/images/dkan9634/post/fb5a3b08-1d70-46aa-ba1c-2702962da6c4/image.png)

-> 엔비디아 H100 SXM 칩의 여러 정밀도 형식별 FLOP/s 사양

### 메모리 크기와 대역폭
- GPU는 수많은 코어가 병렬로 작동하기 때문에, 메모리에서 이 코어들로 데이터를 계속해서 옮겨야 하므로 **데이터 전송 속도가 중요**하다.
- **GPU 메모리는 CPU 메모리보다 더 넓은 대역폭과 더 낮은 지연 시간이 필요**하고, 따라서 GPU 메모리는 더 고급 메모리 기술이 필요하다.
=> GPU 메모리가 CPU 메모리보다 비싼 이유 중 하나
- CPU는 보통 2D 구조인 DDR SDRAM, GPU는 3D 적층 구조인 HBM을 많이 사용
- **가속기의 메모리는 크기와 대역폭으로 평가**된다.
- GPU 같은 가속기는 다음 그림처럼 세 단계 메모리와 상호작용한다.
![](https://velog.velcdn.com/images/dkan9634/post/394816c5-3189-4956-9932-64dc412407f2/image.png)
#### CPU 메모리(DRAM)
- 가속기는 보통 CPU와 함께 사용되어 CPU 메모리에 접근할 수 있다.
- 이런 메모리 유형 중 **대역폭이 가장 낮고**, 메모리 크기는 다양하다.
#### GPU 고대역폭 메모리(HBM)
- GPU 전용 메모리로 CPU 메모리보다 빠르게 접근하기 위해 GPU 가까이에 둔다.
- HBM은 훨씬 높은 대역폭을 제공하고 대량 데이터 전송과 높은 처리량 작업을 효율적으로 처리하는 데 꼭 필요하다. 
#### GPU 온칩 SRAM
- 칩 안에 바로 들어 있는 메모리로 자주 쓰이는 데이터와 지시를 거의 바로 접근할 수 있게 저장한다.
- SRAM으로 만들어진 L1, L2 캐시가 포함되고 일부 구조는 L3 캐시도 포함된다.
- 전송속도는 빠르고 메모리 크기는 작다.

### 전력 소모
- 칩은 연산할 때 트랜지스터를 사용한다.
- 각 연산은 트랜지스터가 on off 되는데 이때 에너지가 필요하다. GPU는 수십억 개의 트랜지스터가 들어 있다. 
   - ex) A100: 540억 개, H100: 800억 개
- 가속기를 제대로 활용하면 수십억 개의 트랜지스터가 빠르게 상태를 바꾸면서 엄청난 양의 에너지를 소비하고 상당한 열을 발생시킨다. 이 열을 식히려면 냉각 시스템이 필요한데, 이 시스템에도 전기가 필요하므로 **데이터센터 전체 에너지 소비가 늘어난다.**
- 가속기는 보통 최대 전력 소모량이나 대체 지표인 **열 설계 전력(TDP)로 전력 소모를 표시**한다.
    - TDP는 칩이 일반적인 작업을 할 때 냉각 시스템이 방출해야 하는 최대 열을 나타낸다.
 
#### 가속기 선택
- 연산 중심 작업이라면 FLOP/s가 높은 칩
- 메모리 중심 작업이라면 대역폭이 넓고 메모리 용량이 큰 칩에 투자하는 것이 좋다.
- 칩을 살 때 세 가지 핵심 질문
1. 이 하드웨어로 원하는 작업을 실행할 수 있는가?
2. 실행하는 데 얼마나 걸리는가?
3. 비용이 얼마나 드는가?

---
[chap8 블로그](https://velog.io/@dkan9634/AI-Engineering-Chap-8.-%EB%8D%B0%EC%9D%B4%ED%84%B0%EC%85%8B-%EC%97%94%EC%A7%80%EB%8B%88%EC%96%B4%EB%A7%81)

[chap9 블로그](https://velog.io/@dkan9634/AI-Engineering-Chap-9.-%EC%B6%94%EB%A1%A0-%EC%B5%9C%EC%A0%81%ED%99%94)
