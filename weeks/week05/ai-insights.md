# Week 05 - AI Engineering 인사이트

각 팀원이 작성한 study-note를 바탕으로 개인별 인사이트와 학습 내용을 정리합니다.

---

## 김성언 (Kim Seong-Eon)

### 핵심 인사이트
- **하이브리드 검색의 두 가지 대표 패턴**을 깊이 있게 분석
  - 병렬(Parallel) 하이브리드 + 퓨전: 점수 기반 퓨전(가중합) vs 순위 기반 퓨전(RRF)
  - 계단식(Cascade, 2-stage) 하이브리드: BM25 → Dense → Reranker의 단계적 접근
- **리랭커(Reranker)**에 대한 심층 분석: Cross-Encoder, Bi-Encoder, LLM 기반, LTR 기반 등 다양한 유형 정리
- 멀티모달 RAG의 세 가지 구현 옵션 비교 (CLIP 임베딩 기반, 이미지→텍스트 요약, 요약 + 원본 이미지 활용)

### 독특한 관점 또는 흥미로운 발견
- 점수 기반 퓨전의 중요한 주의점: **스코어 스케일이 다르기 때문에 정규화 없이는 가중치(α)가 의미 없어짐** → 실무에서 순위 기반 퓨전이 더 선호되는 이유
- "LLM이 계획 수립에 취약한 이유"에 대한 분석: 백트래킹 문제, 하지만 A→B 경로 수정도 일종의 백트래킹으로 볼 수 있지 않을까?라는 질문 제기
- 도구 사용 패턴에서 X→Y 흐름이 자주 보이면 합쳐서 새로운 Skill로 만들 수 있다는 아이디어

### 실무 적용 아이디어
- 검색 솔루션 평가 체크리스트 활용: 검색 방식 지원, 확장성, 색인화 시간, 질의 지연 시간, 가격 체계 등
- 표 형식 데이터 처리를 위한 Text-to-SQL 파이프라인 구축
- VLM/멀티모달 기반 문서 파싱 도구(PaddleOCR, Unstructured, Docling) 활용

### 추가 학습이 필요한 부분
- 계층적 계획 수립 방법론의 구체적 구현
- 에이전트의 복잡한 제어 흐름(순차, 병렬, 조건문, 반복문) 설계

---

## 안태현 (Ahn Tae-Hyun)

### 핵심 인사이트
- **컨텍스트 구성의 핵심 두 패턴**: RAG(외부 데이터 검색)와 에이전트(도구 활용)의 명확한 구분
- **검색기의 두 가지 핵심 기능**: 색인화(Indexing)와 질의(Query)
- 메모리의 세 가지 유형 정리: 내부 지식, 단기 메모리(컨텍스트), 장기 메모리(외부 데이터 소스)
- 에이전트에게 강력한 모델이 필요한 이유: **누적되는 오류**와 **더 큰 위험성**

### 독특한 관점 또는 흥미로운 발견
- 클로드 조언 인용: 지식 베이스가 200,000 토큰(약 500페이지) 미만이면 RAG 없이 전체를 프롬프트에 포함해도 됨
- **ANN 벤치마크의 네 가지 지표** 정리: 재현율, QPS(초당 질의 수), 구축 시간, 색인 크기
- 스킬 매니저 개념: 에이전트가 습득한 기술을 추적하고 스킬 라이브러리에 추가하는 메커니즘

### 실무 적용 아이디어
- FAISS, ScaNN, Annoy, Hnswlib 등 벡터 검색 라이브러리 비교 활용
- 도구 전환 연구를 통한 도구 최적화: 자주 함께 사용되는 도구는 하나로 합치기
- 에이전트 실패 유형별 평가 데이터셋 구축

### 추가 학습이 필요한 부분
- 각 ANN 알고리즘(HNSW, LSH, IVF 등)의 세부 구현 및 트레이드오프
- RAG 시스템 전체를 처음부터 끝까지 파인튜닝하는 방법론

---

## 이은정 (Lee Eun-Jeong)

### 핵심 인사이트
- **RAG = 모든 질의에 동일한 컨텍스트를 사용하지 않고, 각 질의에 특화된 컨텍스트를 만들어내는 기술**
- 용어 기반 검색 vs 임베딩 기반 검색의 명확한 비교표 제시:
  - 속도: 용어 기반 > 임베딩 기반
  - 성능: 임베딩 기반이 파인튜닝으로 개선 가능
  - 비용: 용어 기반이 훨씬 저렴
- 컨텍스트 검색의 핵심: **각 청크에 관련 컨텍스트(태그, 메타데이터, 제목, 요약)를 추가**

### 독특한 관점 또는 흥미로운 발견
- **컨텍스트 재순위화가 전통적 검색과 다른 점**: 항목의 정확한 위치(순위)가 덜 중요함
- 앤트로픽의 컨텍스트 검색 프롬프트 예시 소개: 청크와 원본 문서의 관계를 설명하는 50~100 토큰의 "숏 컨텍스트" 생성
- 임베딩 변환 시 키워드가 희석되는 문제점 지적 (예: EADDRNOTAVAIL(99) 같은 오류 코드)

### 실무 적용 아이디어
- 역순위 퓨전(RRF)을 활용한 하이브리드 검색 구현
- 에이전트의 세 가지 도구 유형 설계: 지식 증강, 능력 확장, 쓰기 행동
- RAG 품질 평가 프레임워크: 검색 품질 → RAG 출력 평가 → 임베딩 품질 평가

### 추가 학습이 필요한 부분
- 멀티모달 임베딩 모델(CLIP 등)의 실제 활용 방법
- Text-to-SQL에서 테이블이 많을 때 적절한 테이블 선택 전략

---

## 허채연 (Heo Chae-Yeon)

### 핵심 인사이트
- **수학적 공식을 통한 검색 알고리즘 이해**:
  - IDF(t) = log(N/C(t))
  - RRF Score(D) = Σ(1/(k + r_i(D)))
- 에이전트 작업 수행 과정의 체계적 정리: **계획 생성 → 추론 → 실행 → 추론**
- **리플렉션(Reflexion) 프레임워크**: 평가자(Evaluator) + 성찰(Reflection) 모듈로 구성

### 독특한 관점 또는 흥미로운 발견
- LLM의 계획 수립 한계에 대한 양면적 분석:
  - (-) 자기회귀 모델이라 백트래킹 불가, 도구 부족
  - (+) 세계에 대한 방대한 정보로 행동 결과 예측 가능
- 계획의 세부성에 대한 절충점: 세부적 계획은 생성 어렵지만 실행 쉬움, 큰 틀의 계획은 생성 쉽지만 실행 어려움 → **계층적 계획**으로 해결
- **성찰 오류**: 작업을 완료하지 못했는데도 완료했다고 확신하는 에이전트의 실패 유형

### 실무 적용 아이디어
- 메모리 관리 전략 적용: FIFO, 중복 감지(요약 활용), 성찰 분류기
- 에이전트 평가 지표 설계: 유효한 계획 비율, 유효한 도구 호출 비율, 평균 단계 수, 비용
- 함수 호출 API 활용: required/none/auto 옵션을 상황에 맞게 설정

### 추가 학습이 필요한 부분
- 멀티 에이전트 구조에서의 성찰 구현
- 에이전트의 도구 선택 최적화를 위한 실험 설계

---

## 통합 토론 주제

스터디 세션에서 함께 논의하면 좋을 질문들을 자유롭게 추가해주세요.

### 공통 질문
- RAG vs 롱 컨텍스트: 200,000 토큰 기준 외에 어떤 상황에서 RAG가 더 유리한가?
- 하이브리드 검색에서 점수 기반 퓨전 vs 순위 기반 퓨전(RRF), 각각 어떤 상황에서 유리한가?
- 에이전트의 "성찰 오류"를 어떻게 탐지하고 방지할 수 있는가?

### 심화 토론
- LLM이 계획 수립에 본질적으로 취약한가? 아니면 적절한 도구와 결합하면 극복 가능한가?
- 임베딩 기반 검색에서 키워드가 희석되는 문제를 해결하기 위한 방법은? (하이브리드 검색 외에)
- 에이전트의 도구 수가 많아질수록 효율성이 떨어지는 문제를 어떻게 해결할 수 있는가?

### 다음 주차 연결 포인트
- 파인튜닝을 통해 RAG 시스템의 검색기와 생성기를 함께 최적화하는 방법 (Week 06 연결)
- 에이전트 계획 수립 능력 향상을 위한 파인튜닝 전략
- 메모리 관리 전략에서 요약 모델의 역할과 파인튜닝 가능성
