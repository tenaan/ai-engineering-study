[6장 velog 링크](https://velog.io/@algorithm_cell/AI-%EC%97%94%EC%A7%80%EB%8B%88%EC%96%B4%EB%A7%81-6%EC%9E%A5.-RAG%EC%99%80-%EC%97%90%EC%9D%B4%EC%A0%84%ED%8A%B8)



모델이 작업을 처리하려면, 수행 방법에 대한 지시와 정보 모두 필요하다. 

사람이 정보가 부족할 때 잘못된  응답을 하기 쉬운 것 처럼, **AI 모델도 컨텍스트가 부족할 때 실수를 하거나 환각을 일으킬 가능성이 높다.** 

따라서, 이번 장에서는 각 질의에 적절한 컨텍스트를 구성하는 방법에 대해 다루고자 한다.


# 1) RAG

**RAG *retrieval-augmented generation***

: 외부 데이터베이스나 문서에서 사용자 질문과 가장 관련된 문서를 찾고 검색된 문서를 입력으로 받아, LLM이 근거 기반으로 자연어 답변을 생성한다. 

: 외부 메모리 소스에서 관련 정보를 검색하기에 모델의 생성 능력을 향상시킬 수 있다.

<p align="center">
  <img src="https://velog.velcdn.com/images/algorithm_cell/post/dc3d3b1d-b8d0-4fc7-a184-3a58f5f894f3/image.png" />
<p align="center">위키피디아 페이지를 검색하고, 페이지 정보를 사용해 응답을 생성</p>


RAG는 모든 질의에 동일한 컨텍스트를 사용하지 않고, 각 질의에 특화된 컨텍스트를 만들어 내는 기술로 볼 수 있다.

이는 특정 사용자에 관한 질의가 들어올 때만 사용자 데이터를 컨텍스트에 포함하면 되기 때문에 사용자 데이터 관리에도 용이하다. 


## 아키텍쳐 

<p align="center">
  <img src="https://velog.velcdn.com/images/algorithm_cell/post/f0368925-ee42-4753-bfe2-a27ee0f9308b/image.png" />
<p align="center">기본 RAG 아키텍쳐</p>

- Retriever → 정보 검색기
	
    - **색인화 기능** : 나중에 빠르게 검색할 수 있도록 데이터를 처리하는 작업
    
    - **질의 기능** : 관련 데이터를 검색하기 위해 시스템에 요청을 전송하는 과정
    

- Generator → 자연어 생성기

- RAG = 검색 기반 생성형 QA

RAG 시스템의 성공은 **검색기의 품질**에 달려 있다.


## 검색 알고리즘

**검색 *retrieval***은 일반적으로 하나의 데이터베이스나 시스템에 국한되는 반면, **search**는 다양한 시스템을 걸친 검색을 포함한다. 이 장에서는 검색과 서치를 구분없이 표현한다.


### 1. 용어 기반 검색 

**용어 기반 검색 방법**

1. **TF-IDF**

- TF (Term Frequency): 특정 용어가 문서 D에 얼마나 자주 등장하는가

- IDF (Inverse Document Frequency): 해당 용어가 전체 문서 집합에서 얼마나 희귀한가

$$
\text{IDF}(t) = \log \frac{N}{C(t)}
$$

$$
\text{Score}(D, Q) = \sum_{i=1}^{l} \text{IDF}(t_i) \times f(t_i, D)
$$



2. **BM25**

BM25는 **TF-IDF를 개선한 방식**으로 문서 길이를 고려해 정규화를 진행하는 방식이다.

문서가 길수록 특정 단어를 포함할 확률이 자연히 높아지기 때문에, 이를 보정하지 않으면 긴 문서가 과대평가될 수 있다. 


3. **엘라스틱서치**

**역색인(Inverted Index)**이라는 데이터 구조를 활용하는 방식이다.

역색인은 **용어를 문서로 매핑하는 사전**이다. 

따라서 이 사전 덕분에 어떤 용어가 주어졌을 때 관련 문서를 빠르게 찾을 수 있다.**용어 빈도나 해당 용어 포함 문서 개수 같은 추가 정보도 저장**할 수 있다. 

![](https://velog.velcdn.com/images/algorithm_cell/post/33758177-a8e9-4d60-b348-9cb0bfa32e65/image.png)

4. **토큰화**

- uni-gram : 개별 단어로 분리되면서 본래의 의미가 사라질 수 있다.

- n-gram : 같이 등장하는 토큰들이 있다면 묶어서 하나의 용어로 취급하는 방식이다.

- 토큰화 도구 : NLTK, spaCy, CoreNLP 등


**용어 기반 검색의 장점**

- 색인화와 질의 모두에서 일반적으로 임베딩 기반 검색보다 훨씬 빠르다. 용어 추출은 임베딩 생성보다 빠르고, 용어에서 그 용어를 포함하는 문서로의 매핑은 최근접 이웃 검색보다 계산 비용이 적을 수 있다.
- 별도의 설정 없이도 잘 작동한다. 

**용어 기반 검색의 단점**
- 단순하다. 단순함은 성능 향상을 위해 조정할 수 있는 구성 요소가 적다는 것을 의미하기도 한다.


### 2. 임베딩 기반 검색

이러한 방식은 의미 기반 검색이라고도 한다.
임베딩 기반 검색에선느 색인화 과정이 하나 더 필요하다. **원본 데이터 청크를 임베딩으로 변환해야한다.**


![](https://velog.velcdn.com/images/algorithm_cell/post/50e4a909-a995-40f0-b423-16adfb084f09/image.png)

- 지연 시간을 줄이기 위한 캐시, 후보들의 순위를 매기는 재순위 모듈도 포함될 수 있다.


**벡터 검색 알고리즘**

1. **K-최근접 이웃 알고리즘** : 주어진 질의에 대해 k개의 가장 가까운 벡터를 찾는 방법

2. **지역 민감 해싱 *LSH*** : 유사한 벡터를 같은 버킷에 해싱하여 유사도 검색 속도를 높이는 방식으로, 정확도 일부를 희생하는 대신 **효율성을 얻는다**.

3. **계층적 탐색이 가능한 소규모 세계 *HNSW*** : 노드가 벡터를 연결하는 다중 레이러 그래프를 구성하고, 이 그래프 엣지를 따라 이동하며 최근접 이웃을 찾는다.

4. **제품 양자화** : 각 벡터를 여러 하위 벡터로 분해하여 훨씬 단순한 저차원 벡터로 표현하는 방식으로, 거리 계산을 빠르게 수행할 수 있다.

5. **역파일 색인 *IVF*** : K-평균 클러스터링을 사용해 유사한 벡터를 같은 클러스터로 묶고, 질의 임베딩과 가장 가까운 클러스터 중심을 찾고, 해당 클러스터에 속한 벡터들이 후보 이웃이 된다. 

6. **근사 최근접 이웃 탐색** : 여러 이진 트리를 구축하여 벡터를 클러스터로 나누는데, 무작위로 그은 선을 기준으로 벡터를 두 그룹으로 나누는 과정을 반복한다. 검색할 때는 이런 트리를 순회해 후보 이웃을 수집한다.

7. **공간 분할 트리 및 그래프 *SPTAG*** 

8. **최근접 이웃을 위한 빠른 라이브러리 *FLANN***

**임베딩 기반 검색의 장점**

- 용어 기반 검색보다 더 좋은 성능을 낼 수 있다. 

- 임베딩 모델과 검색기를 각각 따로 파인튜닝하거나, 둘을 함께 파인튜닝하거나, 아니면 생성 모델까지 포함해 전체적으로 파인튜닝할 수 있다. 

**임베딩 기반 검색의 단점**

- 그러나 데이터를 임베딩으로 변환하면 EADDRNOTAVAIL(99) 같은 특정 오류 코드나 제품 이름과 같은 키워드가 희석되어 나중에 검색하기 어려워질 수 있다.





| 구분 | 용어 기반 검색 | 임베딩 기반 검색 |
|------|---------------|------------------|
| 질의 처리 속도 | 임베딩 기반 검색보다 훨씬 빠르다. | 질의 임베딩 생성과 벡터 검색으로 인해 느릴 수 있다. |
| 성능 | 일반적으로 초기 성능이 뛰어나지만 개선하기 어렵다. 용어의 모호성 때문에 잘못된 문서를 검색할 수 있다. | 파인튜닝을 통해 용어 기반 검색을 능가할 수 있다. |
| 비용 | 임베딩 기반 검색보다 훨씬 저렴하다. | 임베딩 생성, 벡터 저장, 그리고 벡터 검색 솔루션에 비용이 많이 들 수 있다. |


### 3. 검색 알고리즘 결합

용어 기반 검색과 임베딩 기반 검색을 결합하여 사용하는 것을 **하이브리드 검색**이라고 한다.

**일반적으로 사용하는 방식**

1. **용어 기반 검색기**로 후보군을 추려낸다.
2. **의미 기반 검색기**를 통해 **재순위화**한다. 즉, 후보군들을 k-최근접 이웃과 같이 더 정확하지만 비용이 많이 드는 방식으로 최상의 결과를 찾는다.

**역순위 퓨전 *RRF***

- 서로 다른 알고리즘이 매긴 순위를 결합하는 알고리즘이다.

- RRF (Reciprocal Rank Fusion) 점수 계산식

$$
\text{Score}(D) = \sum_{i=1}^{n} \frac{1}{k + r_i(D)}
$$


- **n**: 순위 목록의 수 ,   각 순위 목록은 검색기에 의해 생성된다.

- **$r_i(D)$**: 검색기 *i*에 의해 결정된 문서 *D*의 순위

- **k**:  
  - 0으로 나누는 것을 방지하고  
  - 낮은 순위 문서의 영향력을 제어하기 위한 상수  
  - 일반적인 값은 **60**
  
### 4.검색기의 품질 평가

RAG 시스템 품질 평가를 위해서는 
**1. 검색 품질을 평가한다.**
**2. 최종 RAG 출력 결과를 평가한다.**
**3. 임베딩 기반 검색을 사용한다면 임베딩 품질도 평가한다.**


**데이터의 품질로 평가** 

- context precision : 검색된 모든 문서 중에서 실제로 질의와 관련된 문서의 비율은 얼마인가?

- context recall : 질의와 관련된 모든 문서 중 실제로 검색된 문서의 비율은 얼마인가?

**문서 순서가 중요한 경우 사용하는 지표**

- NDCG (Normalized Discounted Cumulative Gain)

- MAP (Mean Average Precision)

- MRR (Mean Reciprocal Rank)

**임베딩 기반 검색의 추가 평가 요소**

비슷한 문서가 벡터 공간에서 가까이 위치하면 좋은 임베딩이고, 독립적으로 품질 평가 가능하다.

- 대표 벤치마크: MTEB (Muennighoff et al., 2023) → 검색, 분류, 클러스터링 등 다양한 작업에서 임베딩 성능 평가

- 지연시간 : 질의 임베딩 생성과 백터 검새겡 따른 추가 지연 시간

- 비용 : 임베딩을 생성하는 드는 비용

**index와 질의 사이의 균형 유지**


- 색인이 상세할수록 **검색 과정은 더 정확해지지만**, **메모리 사용량이 많아지고 느려진다.**
	
    - ex) 고객 정보 색인에 이름, 회사, 이메일, 관심사까지 추가하면 검색은 쉬워지지만, 구축 시간, 저장 공간은 증가한다.

- HNSW 같은 상세한 색인은 높은 정확도와 빠른 질의 제공하지만, 구축하는데 상당한 시간과 메모리 필요

- LSH 같은 단순한 색인은 생성하는데 더 빠르고 메모리가 적게 들지만, 질의 속도가 느리고 정확도도 떨어진다.


**ANN 벤치마크 주요 지표**

- 재현율 (Recall) : 실제 최근접 이웃을 얼마나 잘 찾는가

- QPS (Queries Per Second) : 초당 처리 가능한 질의 수

- 구축 시간 : 색인 생성에 걸리는 시간 (데이터 변경 잦을수록 중요)

- 색인 크기 : 저장 공간 및 확장성 평가



## 검색 최적화


### 1. 청킹 전략

**청크**란, 텍스트 데이터를 작은 조각으로 나누는 것을 말한다.



- 가장 단순한 전략은 특정 단위를 기준으로 문서를 **동일한 길이의 청크**로 나누는 것이다.

- 각 청크가 크기 안에 들어올 때까지 점점 작은 단위를 사용해 **문서를 재귀적으로 분할**할 수도 있다.

- 문서를 겹침 없이 나누면, 중요한 컨텍스트에서 끊겨 정보가 손실 될 수 있기 때문에, 청크 간의 겹침은 중요한 경계 정보가 최소한 하나의 청크에 포함되게 보장해준다.

- 임베딩 기반 접근법을 사용할 때 청크 크기는 임베딩 모델의 컨텍스트 제한을 넘으면 안된다. 

- 생성 모델의 토크나이저가 나누는 토큰을 기준으로 청킹할 수 있지만, 생성 모델을 바꾸면 데이터를 처음부터 다시 색인화 해야한다는 단점이 있다.


청크 크기가 작을수록 모델은 더 많은 청크를 포함할 수 있기 때문에 다양한 정보를 가질 수 있다.

하지만, 청크 단위가 너무 작으면 중요한 정보가 손실 될 수 있으며 계산 부담도 증가시킨다. 

따라서, 적당한 크기의 청크를 실험을 통해 찾아야한다.


### 2. 재순위화

검색기가 생성한 초기 문서 순위는 더 정확하게 재순위될 수 있다. 재순위화는 모델의 컨텍스트에 맞추거나, 입력 토큰 수를 줄이기 위해 검색된 문서 수를 줄여야할 때 특히 유용하다.


### 3. 질의 재작성

질의 재구성, 질의 정규화, 질의 확장 모두 질의 재작성에 포함된다.

- **전통적인 검색 엔진에서는 휴리스틱을 사용**해 질의 재작성을 수행하는 경우가 많다.

- **AI 애플리케이션에서는 프롬프트를 사용**해 다른 AI모델로 질의 재작성을 요청할 수 있다.

<p align="center">
  <img src="https://velog.velcdn.com/images/algorithm_cell/post/e69c72f7-4bd1-4fc8-bc1f-01c92510b082/image.png" />
<p align="center">다른 생성 모델에게 질의 재작성을 요청하는 예시</p>
	

### 4. 컨텍스트 검색

컨텍스트 검색의 핵심 아이디어는 **각 청크에 관련 컨텍스트를 추가해** 필요한 청크를 더 쉽게 검색할 수 있게 하는 것이다.

- 메타데이터(태그, 키워드)로 청크를 보강할 수 있다.
	
    - ex) 전자상거래의 경우 상품 설명과 리뷰를 함께 저장할 수 있다. 
    - ex) 이미지나 동영상을 제목이나 캡션을 통해 검색할 수 있다.
    
- 청크에서 자동으로 추출된 개체 또한 메타데이터에 포함될 수 있다.

- 각 청크에 실제로 물을 수 있는 질의들을 추가할 수 있다.

**문서를 여러 청크로 나누면, 일부 청크는 검색기가 내용을 이해하는 데 필요한 컨텍스트가 부족**해질 수 있다.

- 이를 방지하기 위해 원본 문서의 제목, 요약, 혹은 위치 정보를 각 청크에 추가한다.

- ex) Anthropic은 AI 모델을 활용해 각 청크의 위치를 알려주는 context로 보강해 컨텍스트 검색을 용이하게 했다.

![](https://velog.velcdn.com/images/algorithm_cell/post/3a845950-d742-4bd9-9446-7524f459f086/image.png)


## 멀티모달 RAG

### 1. 이미지 데이터

- 텍스트 데이터베이스 + 이미지 데이터베이스를 함께 사용해 질의에 답하는 RAG 구조

- 텍스트 정보만으로 부족한 질문을 이미지 정보로 보완할 수 있다.
![](https://velog.velcdn.com/images/algorithm_cell/post/1b629289-e1db-43d1-bb4e-498614909ddc/image.png)

**이미지 검색 방식**

1. **메타데이터 기반**

	- 이미지에 제목, 태그, 캡션 같은 텍스트 메타데이터가 있는 경우 **질의와 메타데이터의 텍스트 유사도**로 검색
    
2. **내용 기반 (멀티모달 임베딩)**

	- 이미지 내용 자체를 기준으로 검색하려면, 텍스트와 이미지를 같은 벡터 공간으로 변환해야 하기 때문에  멀티모달 임베딩 모델을 사용한다.
	
    - ex) **CLIP** : 텍스트와 이미지를 공통 임베딩 공간에 매핑해 **텍스트–이미지 간 유사도 계산이 가능**하다.

### 2. 표 형식 데이터
  
대부분의 애플리케이션은 텍스트, 이미지 같은 비정형 데이터뿐 만 아니라 표 형식(tabular) 데이터도 함께 처리한다.
  
표 형식 데이터로 context를 보강하는 과정은 일반적인 RAG workflow와 상당히 다르기 때문에 예시를 통해 살펴보자.
  
> EX)![](https://velog.velcdn.com/images/algorithm_cell/post/c98abf51-30d8-4c3e-aedb-04a5fb499046/image.png)
>
>
> 
> **질문 : “지난 7일 동안 과일 페도라가 몇 개 팔렸나요?”**
> 단순 검색으로는 답을 할 수 없기 때문에, **제품명이 과일 페도라인 주문 필터링, 최근 7일 조건 적용, 판매 수량 합산**을 거쳐야한다.
> **즉, 집계 연산이 필요하고, SQL로 조회한다.**
>
>**전체 파이프라인**
> - Text-to-SQL : 사용자 질의 + 테이블 스키마를 입력으로 받아 필요한 SQL 쿼리를 생성
> - SQL 실행 : 생성된 SQL을 실제 데이터베이스에서 실행
> - 응답 생성 : SQL 실행 결과를 바탕으로 응답 생성
> 
> ![](https://velog.velcdn.com/images/algorithm_cell/post/bbf9e716-588e-4615-8a91-907462d93ced/image.png)
 

---



# 2) 에이전트

- **에이전트**는 자신의 환경을 인식하고 그 환경에서 행동할 수 있는 행동할 수 있는 모든 것을 말한다.

- 에이전트의 환경은 **활용 사례**에 따라 결정되고, 행동 집합은 **접근할 수 있는 도구**에 의해 확장된다.

- **환경**은 에이전트가 잠재적으로 사용할 수 있는 **도구를 결정**하고, 에이전트의 **도구** 목록은 **활동할 수 있는 환경을 제한**한다.
	
    - ex) 환경 : 체스 게임 -> 행동 : 체스 규칙에서 허용된 움직임
    
    - ex) 행동 : 수영 -> 환경 : 물이 있는 환경만 가능

  
<p align="center">
  <img src="https://velog.velcdn.com/images/algorithm_cell/post/a03c4164-319d-4190-aadf-88360ba3f69d/image.png" />
<p align="center">코딩 에이전트</p>


- **환경** : 터미널과 파일 시스템이 있는 컴퓨터
- **행동 집합** : 저장소 탐색, 파일 검색, 파일 보기 등등



## 에이전트 개요

RAG 에이전트를 예시로 살펴 보자

> **RAG 에이전트의 기본 구조**
>
> 에이전트는 응답 생성 / SQL 쿼리 생성 / SQL 실행의 3가지 행동을 수행한다.
>
>> **1.** 질문: 향후 3개월간 과일 페도라 판매 수익 예측
>> **2.** 예측에 필요한 정보(과거 5년 매출)를 판단
>> **3.** 과거 매출 데이터를 조회하는 SQL 쿼리 생성
>> **4.** SQL 쿼리 실행
>> **5.** 결과가 충분한지 평가 → 부족하다고 판단
>> **6.** 추가 정보(과거 마케팅 캠페인) 필요성 판단
>> **7.** 마케팅 데이터 쿼리 생성 및 실행
>> **8.** 정보가 충분하다고 판단 후 예측 생성
>> **9.** 작업 완료 판단
>
> **핵심: 중간 결과를 평가하며 필요한 정보를 추가로 요청하는 다단계 추론**
>
>> **더 강력한 모델이 필요한 이유**
>> **1. 누적 오류 문제** : 단계가 많아질수록 오류가 누적된다.
>> **2. 위험성 증가** : 더 많은 도구를 사용할수록 영향력 있는 작업 가능하지만, 실패 시 더 큰 피해를 유발할 수 있다.


따라서, **에이전트 성공의 핵심 요인**은 **사용할 수 있는 도구의 종류, 그리고 AI의 계획 수립 능력**에 달려 있다.


## 도구

- 많은 모델 제공업체는 이미 **함수 호출 *function calling***을 통해 다양한 도구를 사용할 수 있게 지원한다.

- 에이전트 환경에 따라 다양한 도구를 활용할 수 있다.


### 1. 지식 증강

- 1) 조직의 비공개 프로세스와 정보 활용

- 2) 웹 브라우징 : 인터넷과 같은 공개 정보에도 접근

### 2. 능력 확장

- AI 모델의 고유한 한계를 보완하는 도구

- 모델 자체를 더 똑똑하게 학습시키는 것보다 필요한 작업을 도구에 맡기는 것
	
    - ex) 캘린더, 시간대 변환기, 단위 변환기, 코드 인터프리터 
    
    - ex) **멀티모달 능력 확장** : 외부 도구를 통해 텍스트 전용 모델도 멀티모달화 가능
 
- 도구 활용은 프롬프트 엔지니어링이나 파인튜닝보다도 모델 성능을 크게 향상시킬 수 있다.


### 3. 쓰기 행동

- 데이터 소스를 변경하는 쓰기 행동도 수행할 수 있고, 이는 시스템이 더 많은 일을 할 수 있게 해준다.
	
    - ex) 잠재 고객 조사, 연락처 찾기, 이메일 초안 작성, 이메일 발송, 후속 조치, 데이터베이스에 새 주문 정보 업데이트 
 
- 시스템이 악의적인 사용자에 의해 조작되어 해로운 행동을 하지 않도록 철저히 방어해야 한다.


## 계획 수립


무의미한 실행을 피하기 위해서는 계획 수립과 실행을 분리해야 한다. 따라서, 먼저 에이전트에게 계획을 만들어 달라고 요청하고, 이 계획이 검증된 후에만 실행한다. 


![](https://velog.velcdn.com/images/algorithm_cell/post/50364769-a2d0-4506-ab6a-cc689e73bcb1/image.png)

이때 시스템은 3가지 구성요소를 가진다.

1. **계획을 생성하는 요소**
2. **계획을 검증하는 요소** == **성찰과 오류 수정** == **추론**
3. **계획을 실행하는 요소**

그리고 일반적으로 작업을 해결하는 과정은 **계획 생성 → 추론 → 실행 → 추론**이다.


### 1. 계획 수립자

계획을 세운다는 것은 일종의 **탐색 과정**이고, 탐색에는 **백트래킹**이 포함된다.

**LLM**

- (-) 자기회귀 모델이다. 백트래킹이 안된다.
- (-) 계획에 필요한 도구를 제대로 갖추기 못했다.
- (+) 세계에 대한 방대한 정보를 담고 있어 각 행동의 결과를 예측할 수 있다.

따라서 AI는 완벽하게 계획을 세울 수 없다 .. 하지만, 계획 수립 시스템의 일부로는 활용될 수 있다.


### 2. 계획 생성

모델을 계획 생성기로 바꾸기 위해서는 프롬프트 엔지니어링을 진행하면 된다. 

에이전트의 계획 수립 능력을 향상시키기 위한 몇가지 방법은 다음과 같다.

- 더 많은 예시가 포함된 더 나은 시스템 프롬프트를 작성한다.

- 모델이 더 잘 이해할 수 있도록 도구와 파라미터에 대해 더 자세하게 설명한다.

- 계획 생성을 위해 모델을 파인튜닝한다.

- 더 강력한 모델을 사용한다.


### 3. 복잡한 계획

**제어 흐름**은 행동이 실행되는 순서를 의미한다. 실행 중 결과에 따라 계속 분기,수정되는 계획이다.

1. **순차 실행** : 작업 B가 A에 의존해 A가 끝난 후 B를 수행하는 방식이다.
2. **병렬 실행** : 작업 A,B를 동시에 실행하는 방식이다.
3. **If 조건문** : 이전 단계의 결과에 따라 작업 B,C을 분기되는 방식이다.
4. **For 반복문** : 특정 조건이 충족될 때까지 작업A를 반복하는 방식이다.

![](https://velog.velcdn.com/images/algorithm_cell/post/d0114f00-5669-4b2d-890d-9fbedb3c7f7b/image.png)

### 4. 계획의 세부성 

계획과 실행 사이에는 절충점이 있다. 세부적인 계획은 생성하기 어렵지만 실행하기는 쉽다. 반면 큰 틀의 계획은 생성하기 쉽지만 실행하기 어렵다. 이런 절충을 피하기 위해 **계층적으로 계획**을 세운다.


### 5. 성찰 및 오류 수정 == 추론

아무리 뛰어난 계획이라도 성공 가능성을 높이려면 **계속해서 평가하고 조정**해야 한다. 성찰은 에이전트 작동에 반드시 필요하진 않아도, 성공적으로 임무를 완수하기 위해 필요한 과정이다.

사용자 질의를 받은 후 요청이 실현 가능한 지 , 각 실행 단계 이후 올바른 방향으로 진행되고 있는 지 등과 같은 작업에서 유용하게 쓰일 수 있다.

**성찰을 통해 얻은 통찰력은 수정이 필요한 오류를 발견하는 데 도움이 된다.**

![](https://velog.velcdn.com/images/algorithm_cell/post/f4c31472-d173-47ed-9680-9ac932a3ff80/image.png)

![](https://velog.velcdn.com/images/algorithm_cell/post/d65b1027-89c7-4627-b2ca-9e4be987cc6c/image.png)

- 성찰은 멀티 에이전트 구조로도 구현이 가능하다. 한 에이전트는 계획 수립 및 실행을 담당하고, 다른 에이전트는 각 단계 또는 전체 결과를 평가하는 역할을 수행한다. 작업이 실패했을 경우, 에이전트에게 왜 실패했는지, 어떻게 개선할 수 있는지를 스스로 분석하도록 유도한다.


**리플렉션(Reflexion) 프레임워크**

![](https://velog.velcdn.com/images/algorithm_cell/post/ffeacee9-7bcb-4b59-9429-8f891031ad91/image.png)


두 개의 주요 모듈로 구성된다.

- **평가자(Evaluator)**: 결과의 성공,실패를 판단한다.

- **성찰(Reflection)**: 무엇이 잘못됐는지 추적, 분석한다.

각 단계 후, 에이전트는 **새로운 궤적 *trajectory***을 제안한다.


계획 생성만 사용하는 방식보다 구현이 상대적으로 쉽고 성능 향상 폭이 큰 경우가 많지만, 지연 시간과 비용이 증가한다.

### 6. 함수 호출

많은 모델 제공업체는 모델에 도구 사용 기능을 제공하며, 도구가 곧 함수이기 때문에 이를 함수 호출이라고 부른다.

일반적으로 함수 호출을 다음과 같이 작동한다.

1. **도구 목록 생성** : 모델이 사용할 수 있는 모든 도구를 사전에 정의한다.

2. **에이전트가 사용할 도구 지정** : 질의마다 필요한 도구가 다르므로, API는 각 요청마다 사용할 도구 범위를 제한할 수 있게 한다.

- 일부 API는 도구 사용 방식을 세밀하게 제어할 수 있다.
	
    ㅠㅗㅓ- required: 모델이 반드시 하나 이상의 도구를 사용해야 함
    - none: 모델이 도구를 사용하지 않아야 함
    - auto: 모델이 스스로 도구 사용 여부를 결정

![](https://velog.velcdn.com/images/algorithm_cell/post/fbd5d06e-a39c-4fb4-9cce-4faea469fabd/image.png)

- 어떤 도구를 사용할지, 필ㅇ한 파라미터를 자동으로 생성하지만 파라미터 값까지는 보장하지 못한다.

- 따라서, 에이전트를 활용할 때는 항상 시스템이 각 함수 호출에 어떤 파라미터 값을 사용했는지 알려주도록 설정하는 것이 좋다. 

### 7. 도구 선택

도구가 많을수록 에이전트의 능력은 향상되지만, 그만큼 이를 효율적으로 사용하기는 어려워진다. 
따라서, 도구 선택에는 **실험과 분석**이 필요하다.

![](https://velog.velcdn.com/images/algorithm_cell/post/92ff9aab-8017-4f0f-9615-b46a9d9045ec/image.png)

- 작업마다 필요한 모두가 다르고, 모델마다 선호하는 도구가 다른 것을 확인할 수 있다.


### 8. 도구 전환

주어진 도구를 사용하는 것뿐 아니라 **간단한 도구를 조합해 더 강력한 도구를 만들어** 생산성을 향상시킨다.



## 에이전트 실패 유형

### 1. 계획 수립 실패

무엇을 할지 계획 자체가 잘못된 실패를 의미한다.

**1) 도구 사용 실패**

가장 흔하게 발생하는 계획 수립 실패 중 하나이다.

- 유효하지 않은 도구

- 유효한 도구, 유효하지 않는 파라미터

- 유효한 도구, 잘못된 파라미터 값

**2) 목표 달성 실패**

계획한 작업을 해결하지 못하거나, 제약 조건을 따르지 않고 작업을 해결하여 목표를 달성하지 못했을 때를 의미한다.

**작업 시간**이 이에 해당한다. 시간이 오래 걸릴 수록 에이전트의 유용성은 급격히 떨어진다.


**3) 성찰 오류**

에이전트가 실제로는 작업을 완료하지 못했는데도 완료했다고 확신하는 것이다. 

**4) 평가를 위해 활용할 수 있는 요소**

**(작업 task, 도구 목록 tool inventory) 쌍으로 구성된 계획 수립 데이터셋을 생성**하고, 각 작업에 대해 에이전트가 K개의 계획을 생성하도록 한 뒤, 아래 지표들을 계산한다.

- **계획 관련 지표**
	
    - 생성된 모든 계획 중 유효한 계획의 비율
    
    - 주어진 작업에서 유효한 계획을 얻기 위해 평균적으로 필요한 계획 생성 수
   

- **도구 호출 관련 지표**
	
    - 전체 도구 호출 중 유효한 호출의 비율
    
    - 유효하지 않은 도구가 호출되는 빈도
    
    - 유효한 도구가 유효하지 않은 파라미터로 호출되는 빈도
    
    - 유효한 도구가 잘못된 파라미터 값으로 호출되는 빈도


### 2.도구 실패

올바른 도구를 사용했지만, 그 결과가 잘못된 경우에 발생한다.

**1) 도구 자체가 잘못된 출력을 내놓는 경우**

**2) 적절한 도구를 가지고 있지 않는 경우**

도구 실패는 도구마다 다르게 나타나기 때문에, 개별적으로 테스트 되어야한다. 항상 모든 도구 호출과 그 결과를 출력해 검사하고 평가해야한다.

### 3.효율성

에이전트가 올바른 도구로 유요한 계획을 세워 작업을 완수하더라도, 과정이 비효율적일 수 있다.

**평가를 위해 활용할 수 있는 요소**

- 에이전트가 작업을 완료하는 데 평균적으로 몇 단계가 필요한가?

- 에이전트가 작업을 완료하는 데 평균적으로 얼마의 비용이 드는가?

- 각 행동을 보통 얼마의 시간이 걸리고, 특히 시간이나 비용이 많이 드는 행동은 무엇인가?





---

# 3) 메모리

메모리는 모델이 정보를 저장하고 활용할 수 있게 하는 방식이다.

**RAG** 시스템은 검색된 정보로 컨텍스트를 보강하고, 이를 처리하기 위해 메모리를 사용한다.

**Agent** 기반 시스템은 지시, 예시, 컨텍스트, 도구 목록, 성찰 등을 저장하기 위해 메모리를 사용하다.

## AI 모델의 메모리

### 1. 내부 지식

- 모델이 학습한 데이터로부터 얻은 모든 지식을 의미한다.

- 모델이 새로 업데이트되지 않는 한 변하지 않는다.

- 모델은 모든 질의에 대해서 이 지식에 접근할 수 있다.

### 2. 단기 메모리

- 모델의 컨텍스트를 의미한다. 컨텍스틑 작업(질의)가 끝나면 사라지기 때문에, 단기 메모리라고 볼 수 있다.

- 이전 대화 내용을 컨텍스트에 추가하면 모델이 다음 응답을 생성할 때 이 정보를 활용한다.

- 접근 속도는 빠르지만, 용량이 한정되어 있기 때문에 **현재 작업에서 가장 중요한 정보들을 저장하는데 사용한다.**

### 3. 장기메모리

- 모델이 검색을 통해 접근할 수 있는 외부 데이터 소스를 의미한다. 이 정보는 작업이 끝나고 유지되므로, 장기 메모리로 볼 수 있다.

- 모델의 내부 지식과 달리, 장기 메모리의 정보는 모델 자체를 업데이트 하지 않고도 수정하거나 삭제할 수 있다.


## AI 메모리 핵심 기능

### 1. 메모리 관리

- 어떤 정보를 단기 및 장기 메모리에 저장할지 관리한다.

- 외부 메모리 저장 공간은 상대적으로 저렴하고 쉽게 확장할 수 있지만, 단기 메모리는 모델의 최대 컨텍스트 길이에 의해 제한되기 때문에 무엇을 추가하고 삭제할지에 대한 전략이 필요하다.


> ### 메모리 관리 전략
> **1. 선입선출 (FIFO)**
> : 가장 먼저 추가된 정보가 가장 먼저 외부 저장소로 이동하는 방식이다.
> : 긴 대화에서 이 전략은 **초기 메시지가 현재 대화와 덜 관련이 있다고 가정한다.**
> : 하지만, 첫 메시지가 가장 중요한 정보를 담고 있을 수 있기 때문에, FIFO는 구현하기 쉽지만, 모델이 중요한 정보를 놓치게 만들 위험이 있다.
>
>
> **2. 중복을 줄이기**
> : 중복을 자동으로 감지하는 방법이 있다면 메모리 사용량은 크게 줄어들 것이다.
> : 이를 위해 **대화의 요약**을 활용한다.
>
> **3. 성찰 분류기**
> : 각 행동을 한 후에, 에이전트는 두 가지 수행을 하도록 요청받는다.
>> 1. 방금 생성된 정보에 대해 성찰한다.
>> 2. 이 새로운 정봅가 추가되어야하는지, 병헙되어야 하는지, 대체해야 하는지 결정한다.


### 2. 메모리 검색

- 장기 메모리에서 작업과 관련된 정보를 검색한다.



## AI 메모리 장점

### 1. 세션 내 정보 과부화 관리 

- 에이전트는 작업 중 많은 정보를 얻게 되며, 컨텍스트 한계를 넘는 정보는 장기 메모리 시스템에 저장해 관리할 수 있다. 

### 2. 세션 간 정보 유지의 중요성

- 사용자의 이전 대화나 취향을 기억하면 반복 설명이 필요 없어진다. 이를 통해 개인화된 서비스 제공이 가능해진다.

### 3. 모델의 일관성 향상

- 이전 응답을 기억하면 동일하거나 유사한 질문에 대해 더 일관된 답변을 할 수 있다.

### 4. 데이터 구조 무결성 유지

- 텍스트 컨텍스트는 비정형이라 구조 보장이 어렵다. 따라서 엑셀, 큐 등 구조화된 메모리 시스템을 활용하면
데이터의 구조와 작업 순서를 안정적으로 관리할 수 있다.
