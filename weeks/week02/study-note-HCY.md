파운데이션 모델을 학습하는 것은 매우 복잡하고 비용이 많이 들고, 대부분의 기업에서도 기밀 유지로 인해 비법을 공개할 수 없고, 파운데이션 모델을 활용해 **서비스를 개발할 때 중요한 설계 요소들에 대해서만 설명한다.**

모델의 학습 과정은 주로 사전학습/사후학습으로 나눈다.
사후학습이 사람의 의도에 맞게 모델을 작동하게끔 하는 것이다. 따라서, 대부분의 사람들은 모델 성능에 학습이 미치는 영향에 대해서는 잘 알고 이해하고 있다. 하지만, **샘플링(모델이 선택 가능한 옵션 중 어떤 것을 출력으로 선택할 것인지)** 에 미치는 영향에 대해서는 간과하기 때문에, 이번 장에서는 **샘플링**을 주로 다뤄보려고 한다.

# 1) 학습 데이터

학습 데이터가 모델의 성능에 미치는 영향에 대해 알아보자. 

AI 모델은 학습한 데이터의 특성에 따라 할 수 있는 일이 정해진다. 따라서 모델의 특정 작업 성능을 높이기 위해, 관련된 데이터를 더 많이 추가하고 싶지만, 이는 비용적으로나 구조적으로 어렵다.

- 커먼 크롤 *Common Crawl* : 비영리단체가 인터넷의 웹사이트를 주기적으로 크롤링하여 만든 데이터셋

	
    - C4 : 구글에서 제공하는 커먼 크롤의 정제된 부분집합 데이터
    - 낚시성, 허위 정도 등의 내용들도 포함되어 있기 때문에 품질을 보장할 수는 없다. 따라서, GPT2 학습 당시에는 레딧에서 최소 3개 이상의 추천을 받은 게시글을 사용했다. (* 레딧=미국의 소셜 뉴스 집계, 콘텐츠 등급 및 토론 웹사이트)

- 언어 및 도메인별 파운데이션 모델은 처음부터 학습할 수도 있지만, 범용 모델 + 가진 데이터로 학습 **즉, 파인튜닝**하는 것도 일반적이다.

## 1-1) 다국어 모델
 
<p align="center">
  <img src="https://velog.velcdn.com/images/algorithm_cell/post/61f15322-d59f-4feb-aeab-9b99a9fdafb5/image.png" />
<p align="center"> 커먼 크롤의 주요 언어 분포</p>

- 해당 언어들은 커먼 크롤에서 1% 이상을 차지하는 언어들의 목록이다.

- 이에 해당하지 않는 언어들은 학습 시킬 데이터가 부족할고 이를 **저자원 언어**라고 한다.


<p align="center">
  <img src="https://velog.velcdn.com/images/algorithm_cell/post/4f084a98-56ab-4343-8c76-f9bf1a5b286b/image.png" />
<p align="center"> 커먼 크롤에서 적은 비중을 차지하지만, 사용 인구는 많은 언어</p>

- 사용하는 인구는 많아도, 커먼 크롤에 많이 포함되지 않아서 잘 학습되지 않는 언어들도 있다.


![](https://velog.velcdn.com/images/algorithm_cell/post/bd1c05bd-9437-4680-9a59-133663ec20b9/image.png) | ![](https://velog.velcdn.com/images/algorithm_cell/post/ea06ae10-ccc7-4e72-a1db-83c6e08b3d27/image.png)
---|---|

- 대부분의 데이터가 영어였기 때문에, 영어에 대한 작업 성능이 눈에 띄게 좋은 것을 확인할 수 있다.


## 1-2) 도메인 특화 모델 

<p align="center">
  <img src="https://velog.velcdn.com/images/algorithm_cell/post/e458cb02-1788-437a-95ed-dc4fbd41123d/image.png" />
<p align="center"></p>

- 범용 모델은 코딩, 법률, 과학, 비즈니스, 스포츠, 환경을 포함한 다양한 영역에서 높은 성능을 보이는데 이는 학습 데이터야 다양한 도메인을 포함하기 때문이다.

- 반면, 학습 과정에서 접하지 못한 도메인 특화 작업에서는 좋은 성능을 내기 어렵다.

따라서, 도메인 특화 작업에서 좋은 성능을 내는 모델을 학습하려면, 해당 분야의 전문적인 데이터셋이 필요하다.

- ex) AlphaFold, Med-PaLM2, BioNeMo ..

---

# 2) 모델링

- 모델 학습 전, 어떤 아키텍처를 따를지, 파라미터 개수 등을 정하는 것이 모델의 성능을 결정한다.

## 2-1) 모델 아키텍처


![](https://velog.velcdn.com/images/algorithm_cell/post/64daf2a2-fd00-4408-9913-a037c07cde35/image.png)

- **seq2seq** : 입력을 처리하는 인코더, 출력을 생성하는 디코더로 구성된다. (RNN 구조)

- 인코더는 입력 토큰을 순차적으로 처리하여 입력을 표현하는 *hidden state*를 출력하고, 디코더는 이 최종 hidden state와 이전에 생성된 토큰을 기반으로 출력 토큰을 순차적으로 생성한다.

### seq2seq의 단점 

1) 기본적은 seq2seq 디코더는 입력의 최종 은닉 상태만 사용해 출력 토큰을 생성하기 때문에 초반 정보가 잘 반영되지 않을 수 있다.


2) RNN 인코더, 디코더는 모두 입/출력이 순차적으로 이루어지므로 long sequnece를 다룰 때 느려진다.

### 트랜스포머 아키텍처

트랜스포머 아키텍처는 어텐션 메커니즘으로 두 문제를 모두 해결한다. **Attention**을 통해 모델은 각 출력 토큰을 새성할 때 입력 토큰의 중요도에 가중치를 줄 수 있다. 

![](https://velog.velcdn.com/images/algorithm_cell/post/d6766993-e867-4eb9-b793-55b2d22f056d/image.png)

- RNN을 사용하지 않고 설계되었기 때문에 순환 구조가 아니다.

- 트랜스포머는 **입력 토큰을 벙렬로 처리할 수 있기 때문에 속도가 크게 상승했다.**


### 1. 트랜스포머 추론 단계

하지만, 자기회귀 *auto-regressive* model은 여전히 순차적 출력의 병목 현상이 남아있다. 이런 특성으로 트랜스포머 기반 언어 모델의 추론은 두 단계로 이어진다.

#### 1. 프리필

- 모델이 입력 토큰을 병렬로 처리한다.

- 첫 번째 출력 토큰을 생성하는 데 필요한 중간 상태를 만든다. (입력 토큰의 키 벡터와 값 벡터가 저장된다.)


#### 2. 디코드
 
 - 모델이 출력 토큰을 한 번에 하나씩 생성한다.

### 2. ★ 에텐션 메커니즘 

![](https://velog.velcdn.com/images/algorithm_cell/post/0a5ab711-9691-4736-b33d-d566f19af118/image.png)


- 내부적으로 Key, Value, Query vector를 활용한다
	
    - query vector : 디코더의 현재 상태
    - Key vector : 이전 토큰
    - Value vector

 
$$
\text{Attention}(Q, K, V) = \text{softmax}\left(\frac{QK^{T}}{\sqrt{d}}\right)V
$$
 
- query와 key vector간의 **내적**을 통해 입력 토큰에 얼마나 주목할지 계산하고 이를 저장한다.

- 토큰마다 키 벡터와 값 벡터가 있기 때문에 sequence가 길어질수록 많은 데이터를 계산하고 저장해야하기 때문에 transformer model의 context의 길이를 늘리는 일이 어려움으로 남아있다. (**단, 파라미터 수에는 영향을 미치지 않는다**(

#### 1. multi-head attention


- cnn에서도 filter를 여러 개 두는 것이 더 좋은 것처럼, 여러개 쌓자.

- 모든 어텐션 헤드의 출력은 이어 붙여진다. (concat)

- concat한 결과는 출력 투영 행렬을 통과하고 연산 단계로 넘어간다. 

#### 2. transformer block

![](https://velog.velcdn.com/images/algorithm_cell/post/05762911-e165-49d4-a64d-28dbfb5cb40c/image.png)

- 트랜스포머는 여러개의 트랜스포머 블록으로 구성된다.

- 정확한 내용은 모델마다 다르지만, 일반적으로 attention module, MLP module을 포함한다.


### 3. attention module

- query, key, value, 출력 투영이라는 4개의 가중치 행렬로 이루어져있다.

### 4. MLP module

- 비선형 활성화 함수로 구분된 선형 레이어들로 구성된다.

- 선형 레이어는 Feed Foward layer라고 부르기도 한다.

---

### 5. transformer block 이전 

- **임베딩 모듈** : 임베딩 벡터로 변환하는 **임베딩 행렬** + 위치 정보를 추가해주는 **위치 임베딩 행렬**

- 임베딩 행렬과 위치 임베딩 행렬 정보를 단순 합한다.

### 6. transformer block 이후 

- **출력 레이어** : 모델 출력을 샘플링하는 데 사용되는 토큰 확률로 매핑한다. 


### 다른 모델의 아키텍쳐

트랜스포머 기반 모델이 현재 주류이고, 트랜스포머의 많은 한계점을 고려할 때 이를 능가하는 아키텍처를 개발하기는 어려울 것으로 보인다.

하지만, 현재 *RWKV* 모델도 관심을 받고 있다.
- **RWKV** : 병렬로 학습할 수 있는 RNN 기반 모델


## 2-2) 모델 크기

일반적으로 모델의 파라미터 수가 늘어나면, 학습 용량이 커져서 성능은 향상된다. 파라미터 수를 기반으로 모델을 학습하고 실행하는데 필요한 컴퓨팅 자원을 추정한다. 단, 모델이 희소하다면 0이 아닌 파라미터 개수가 적다는 것이고 이는 더 적은 컴퓨팅 자원으로도 실행할 수 있다는 것을 의미한다.

### 전문가 혼합 (MoE *mixture of experts*)

- 희소 모델의 한 종류이다.

- 파라미터를 여러 개의 그룹으로 나누고, 각 그룹이 특정 작업에 특화된 전문가 역할을 한다. 즉, 토큰을 처리할 때는 전문가 중 일부만 활성화된다.


모델 크기를 논할 때는 학습에 사용된 데이터의 크기도 고려하는 것이 중요하다. 이는 사용한 데이터 개수로 측정할 수도 있다. 하지만, 언어모델의 경우에는 이보다는 토큰의 개수를 세는 것이 더 좋은 측정 방법이다. 토큰 역시 완벽한 기준은 아니다. 왜냐하면 모델마다 토큰화하는 방식이 다 다르기 때문이다. 그럼에도 토큰 수로 판단하는 이유는 모델이 실제로 토큰 단위로 작동하기 때문이다.

### 역스케일링
 
사후학습을 더 많이 진행하면 할수록 모델이 사람의 선호도와 멀어진다 ?

엔트로픽의 논문에 따르면, 사후학습을 더 많이 한 모델이 특정 정치적 견해와 종교적 견해를 더 자주 표현하고, 자신이 의식을 가졌다고 주장하며 도덕적 가치를 강조하는 모습을 보였다고 한다.

### 스케일링 법칙 

1. **모델의 성능**은 모델의 크기와 데이터셋의 크기에 좌우된다.

2. 모델과 데이터셋이 커질수록 더 많은 컴퓨팅 자원이 필요하다.

3. 이런 **컴퓨팅 자원**에는 상당한 비용이 수반된다.

따라서 고정된 예산 내에서 치고 성능을 달성할 수 있는 모델을 **컴퓨팅-최적 모델** *compute-optimal model*이라고 한다. 

그리고 컴퓨팅 예산이 주어졌을 때 **최적의 모델 크기와 데이터셋 크기를 계산하는 규칙**을 **친칠라 스케일링 법칙**이라고 한다.

현재는 특정 모델 성능을 달성하는 비용이 점차 감소하고 있지만서도, 모델 성능 향상에 드는 비용은 여전히 높다.

그럼에도 많은 연구자들이 모델 성능 향상에 힘을 쓰는 이유는 언어모델링, 이미지넷 정확도에서의 작은 성능 향상은 다운스트림 애플리케이션에서 **큰 품질 차이**를 만들어낼 수 있기 때문이다. 

### 스케일링 외삽 (하이퍼파라미터 전이)

* 외삽 : 다른 변수와의 관계에 기초해 변수 값을 추정하는 과정

먼저 파라미터와 하이퍼파라미터를 구분해야한다.

1. **파라미터** : 학습 과정 중에 **모델에 의해 학습되는 값**

2. **하이퍼파라미터** : **사용자가 모델을 구성하고 모델의 학습 방식을 제어**하기 위해 설정하는 값
	- ex) **모델을 구성하는 하이퍼파라미터** : 레이어 수, 모델 차원, 어휘 크기 / **학습방식 제어** : 배치 크기, 에포크 수, 학습률 등
   

다양한 크기의 모델에서 **하이퍼파라미터**가 미치는 영향을 연구하고, 이 하이퍼파라미터가 목표 모델 크기에서 어떻게 작동할지 외삽하는 것이다. 
    
    
스케일링 외삽은 모델의 규모가 커져야만 의미가 있는데(창발력), 대규모 모델 연구경험을 가진 사람이 많지 않기 때문에 여전히 소수 전문가들만 관심을 가지는 분야이다. 
추가적으로, 하이퍼파라미터의 수가 많고 서로 상호작용하는 방식 때문에도 수행하기 어렵다. 


### 스케일링 병목 현상

#### 1. 학습 데이터 부족
![](https://velog.velcdn.com/images/algorithm_cell/post/fb6a1f3f-b081-454a-ac86-a3cac7c12eca/image.png)

- 파운데이션 모델이 이미 너무 많은 데이터를 사용하기 때문에 앞으로 몇 년 안에 인터넷 데이터가 부족해질 수 있다. 

- 일부 사람들은 이런 사실을 이용해 자신이 원하는 데이터를 모델에 주입하고자 인터넷에 게시한다.

- 현재, 인터넷에는 AI 모델이 생성한 데이터가 빠르게 늘어나고 있다. 기업들이 계속해서 인터넷 데이터를 통해 모델을 학습시킨다면 AI 학습 데이터는 결국 AI가 생산한 데이터가 될 것이다.

- 따라서, 저작권 있는 책, 유전체 서열, 계약서 등의 **고유한 독점 데이터**는 AI 경쟁에서 우위를 점하는 요소로 자리 잡을 것이다.

#### 2. 전기

- 데이터 센터는 전 세계 전기의 약 1-2%를 소비하는 것으로 추정된다. 그리고 이 수치는 2030년 4-20% 사이에 도달할 것으로 예상되고, 만일 더 많은 에너지를 생산할 방법을 찾기 못한다면 데이터센터 역시 성장하지 못할 것이다.

따라서, 현재 모델이 더 성장하지 못하는 즉, **스케일링 병목현상**은 학습 데이터와 전기 때문이라고 할 수 있을 것이다.


---

# 3) 사후학습

사전학습 모델 = **자기 지도 학습**을 사용해 학습되고, 이는 **대화**보단 **텍스트 완성**을 잘하도록 학습된다. 따라서, 출력물이 인종차별적이거나, 무례하거나, 틀린 답일 수 있다.

- **사후 학습의 목적은 , 이 두 가지 문제를 해결하는 것이다.**

- 사후 학습은 사전 학습된 모델이 이미 가지고 있지만, 단순히 **프롬프트 수정만으로는 제대로 활용하기 어려운 능력을 끌어내는 과정**이라고 볼수 있다.

## 사후학습 단계

![](https://velog.velcdn.com/images/algorithm_cell/post/4edb116e-498a-4be5-812d-cc2d7e9cee2a/image.png)

## 1. 지도 파인튜닝 (SFT)

대화를 위해 모델을 최적화하기 위해 **고품질 지시 데이터**로 사전 학습된 모델을 파인튜닝한다. 

모델이 적절한 응답을 생성하도록 응답의 예시(지침)을 보여주면 된다. 즉, **시연 데이터**를 제공한다.

예시) 
![](https://velog.velcdn.com/images/algorithm_cell/post/7cdcf449-62d8-4127-a3f9-b726c0f72309/image.png)



## 2. 선호도 파인튜닝

지도 파인튜닝으로 대화하는 방법에 대해 학습했다면 이제는, **사람의 선호도에 맞는 응답**을 출력할 수 있도록 모델을 파인튜닝한다.

보편적인 사람의 선호가 존재한다고 가정하고 이를 AI에 내장할 수 있다고 가정하는 것이기 때문에 난이도가 높은 목표다. 

선호도 파인튜닝을 위해 잘 쓰는 알고리즘은 **RLHF**이다.

### RLHF의 두 과정


### 1. 보상 모델 학습

파운데이션 모델의 출력에 점수를 매기는 보상 모델을 학습한다.

**(프롬프트, 응답)** 쌍이 주어지면, 그 응답이  얼마나 좋은지 점수를 매긴다. 이를 위해 신뢰도 있는 데이터를 얻는 것이 중요하다.

문제점 
1. 레이블러에 따라 혹은 상황에 따라 점수가 다르게 매겨질 수 있다.

2. 좋은 응답의 기준이 사람마다 달라서, 선호도를 수학적 공식으로 표현하기 어렵다.

3. 두 응답을 비교하는 간단한 작업도 시간이 꽤 소요된다.

> 따라서 여러 응답을 한 번에 평가할 수 있도록 한다. 예시로 A>B>C 라고 매기면 자동으로 (A>B) (B>C) (A>C) 이렇게 세 쌍의 비교 결과를 만든다.

비교 데이터만으로 모델이 구체적인 점수를 매기도록 하려면, **목적 함수**를 잘 설계해야한다.
목적 함수는 **선호 응답과 비선호 응답의 출력 점수 차이를 크게 하는 것이다.**
![](https://velog.velcdn.com/images/algorithm_cell/post/d9517e27-fc5c-4428-a2bf-5b1b349a6147/image.png)
![](https://velog.velcdn.com/images/algorithm_cell/post/ff87f197-21e2-4832-8085-5feee54b878e/image.png)

### 2. 보상 모델을 통한 파인튜닝

보상 모델이 최대 점수를 줄 응답을 생성하도록 파운데이션 모델을 최적화한다.

- 이과정에서 강화학습 알고리즘인 **PPO** *Proximal policy optimization*를 수행한다.

---

# 4) 샘플링

모델은 샘플링이라는 과정을 통해 출력을 생성하고, 샘플링은 **AI의 출력**을 **확률적**으로 만든다.

## 4-1) 확률 계산 방법

- 입력이 주어지면 신경망은 **logit vector**를 출력한다. 로짓은 확률 값을 나타내지는 않기 때문에 *Softmax activation function* 을 홯용해 로짓 값을 확률로 변환해준다. 


- 이 경우에는 다음 토큰으로 올바른 것에 대한 로짓 값이 출력되었다.
![](https://velog.velcdn.com/images/algorithm_cell/post/0707f7be-22ad-414e-97eb-32843d98a809/image.png)


## 4-2) 전략

### 1. 온도

- 확률 분포에 따라 후속 토큰을 샘플링하면 **창의성이 떨어질 수 있다.**

- **가능한 값들의 확률을 재분배하기 위해** 온도를 사용해 샘플링한다.

	- **높은 온도**는 흔한 토큰의 확률을 줄여서 **희귀한 토큰의 확률을 증가**시키므로 더 창의적인 응답으 만들 수 있다.
    
![](https://velog.velcdn.com/images/algorithm_cell/post/a6ff3ca1-83b9-4f8b-8e13-5d4d984b8a1f/image.png)

- 온도가 0에 가까워질수록 확률이 높은 것을 선택할 확률이 높은 것을 확인할 수 있다.


하지만, 모델의 출력을 일관되게 만들려면 온도를 0으로 설정해야하는데, 실제로 온도를 0으로 설정하면 모델은 로짓 조정과 소프트맥스 계산을 하지 않고 가장 큰 로짓을 가진 토큰을 선택한다.

**로그프롭*logprob***

- log probability의 줄임말로, 로그 스케일로 표현된 확률을 의미한다.

- 작은 숫자들은 0으로 내림할 수 있기 때문에 도움이 된다.

![](https://velog.velcdn.com/images/algorithm_cell/post/12f46eb8-077e-4ee3-848b-f370541d1a8a/image.png)

### 2. top-k
	
상위 k개의 로짓을 선택하고, 이 k개에 대해서만 소프트 맥스를 수행한다.
따라서 소프트맥스 계산 부하를 **반드시** 줄여준다고 볼 수 있다.

### 3. top-p : 뉴클리어스 샘플링

top-k에서 k는 **고정된 수**이다.
k값이 상황에 따라 변해야한다면 **top-p**를 사용한다. 샘플링할 값을 동적으로 선택할 수 있다.

top-p 샘플링에서 모델은 가장 가능성이 높은 다음 값의 확률을 내림차순으로 합산하고 합이 P에 도달ㄹ하면 중단하고, **누적 확률**에 포함된 단어들만 다음 단어 후보로 고려된다.

miss-p는 샘플링 중 **고려 대상이 될 토큰의 최소 확률** 을 설정한다.

![](https://velog.velcdn.com/images/algorithm_cell/post/5716beb6-d707-402b-974e-4f1442c78d28/image.png)

- top-p = 90% 이면 [yes, maybe] 만 고려하고, 99%라면 [yes, maybe, no]를 고려한다.


반면 top-p는 소프트맥스 계산 부하를 반드시 줄여주지는 않는다.

### 4. 중단 조건

자기회귀 언어 모델은 토큰을 하나씩 생성하면서 sequence를 생성하기 대문에, 긴 출력 sequence는 **더 많은 시간과 비용이 든다.**
따라서, 모델이 시퀀스 생성을 중단하는 조건을 설정할 수 있다.

여러가지 중단 조건이 있다.

- 모델이 일정 개수의 토큰을 생성한 후에 중단하도록 한다.

	- 출력이 문장 중간에 잘릴 가능성이 있다.
   
- 중단 토큰이나 중단 단어를 사용한다.

단점으로는 만약, 특정 형식으로 출력을 생성하기를 원하는 경우 조기 중단으로 인해 출력 형식이 잘못될 수 있다. 예시로는 JSON 파일이 있다.

## 4-3) 테스트 시점 연산

모델의 응답 품질을 향상시키기 위해서는 테스트 시점 연산을 사용할 수 있다. 테스트 시점 연산의 효과를 높이려면 출력의 다양성을 높이는 것이다. 다양한 옵셕 집합이 더 나은 후보를 산출할 가능성이 높다. 

### 1. best of N

무작위로 여러 개의 출력을 생성하고, 가장 적합한 출력을 선택한다.
하지만 모든 출력을 무작위로 생성하면 가능성이 낮은 후보들이 많이 포함될 수 있기 때문에 **빔 검색**(시퀀스 생성 단계마다 가장 가능성이 높은 후보(빔)들을 정해진 개수만큼 생성)을 사용한다.


    
여러 개의 답변을 생성하는 것 역시 **많은 비용**이 들기 때문에, 

+ 사용자에게 여러 출력을 보여주고 가장 마음에 드는 것을 고르도록 할 수도 있다.

+ 자동으로 가장 좋은 출력을 선택하는 방법



## 4-4) 구조화된 출력

- 실제 서비스에서는 모델이 특정 형식을 따르는 출력을 생성해야하는 경우도 있다.

### 구조화된 출력이 필요한 작업

1. 시맨틱 파싱
2. 다운스트림 애플리케이션에서 출력이 사용되는 작업


### 구조화된 출력을 만드는 방법

### 1. framework 활용

구조화된 출력을 지원하는 framework : `guidance`, `outlines`, `instructor`, `llama.cpp`


<p align="center">
  <img src="https://velog.velcdn.com/images/algorithm_cell/post/cae3ee6b-ceb7-407c-85fe-ab9bd9d65baf/image.png" />
<p align="center">guidance를 사용해 제약이 있는 출력을 생성하는 예시</p>

 
### 2. 프롬프팅

모델에게 어떤 형식으로든 출력을 생성하도록 지시하는 것이다.

하지만, 모델이 이 지시를 따를 수 있는지는 **모델의 지시 수행능력과 지시의, 명확성**에 달려있다. 

### 3. 후처리

파운데이션 모델은 **여러 질의에서 비슷한 실수를 반복**하는 경향이 있다. 따라서, 모델이 자주 하는 실수를 파악하면 이를 수정하는 스크립트를 작성해 오류를 고칠 수 있다.

간단하고 비용이 적게 들지만 큰 효과를 볼 수 있다. 단, 수정하기 쉬운 실수에만 효과가 있다. 

### 4. 제약 샘플링

특정 제약 조건에 맞게 텍스트 생성을 유도하는 기법이고, 주로 **출력 도구**와 함께 사용된다.

![](https://velog.velcdn.com/images/algorithm_cell/post/7cc90d98-05bb-4da0-8538-b26f48cc7bba/image.png)

- 로짓 벡터에서 제약 조건을 만족하는 토큰만 걸러내고, 그 중에서 하나를 뽑는 과정이다.

- 정규직, JSON 등 각 출력 형식에는 고유한 문법이 필요하기 때문에, 제약 샘플링은 **일반화하기 어렵다.**

- 따라서, 외부 도구에서 지원하거나 자체적으로 개발한 문법이 있는 형식에서만 사용할 수 있다.

- 문법 검증은 결국 **생성 시간 지연**을 유발한다.

### 5. 파인튜닝

원하는 형식에 맞는 예시로 모델을 학습시키는 것이다.이 형식대로 출력을 생성하게 만드는 가장 효과적이고 일반적인 방법이다.

특정 작업에 대해서는 파인튜닝 전에 **모델 아키텍처를 수정하여** 출력 형식을 보장할 수 있다.

![](https://velog.velcdn.com/images/algorithm_cell/post/da9780be-9d71-4832-b3fa-7ec4aa204b01/image.png)

- 이 예시 에서는, 모델 구조에 분류기 헤드를 붙여서 모델이 미리 정해준 class 중 1개만 출력하도록 만들었다.

- 이러한 방식을 **특성 기반 전이**라고 한다.

- 파인튜닝할 때는 모델 전체를 처음~끝 재학습 할 수 있고, 분류기 헤드처럼 일부만 학습할 수도 있다.


## 4-5) AI의 확률적 특성

AI 모델이 응답을 샘플링하는 방식은 **확률적**이다.


### 확률적 특성으로 인해 나타나는 현상

### 1. 비일관성

샘플링 과정의 무작위성에서 발생한다.

![](https://velog.velcdn.com/images/algorithm_cell/post/8cad28be-b3e9-45fb-84fd-266d73ca1f88/image.png)


- 같은 입력과 프롬프트를 주어도 완전히 다른 응답이 나올 수 있다.

	- 모델을 직접 호스팅하면 사용하는 하드웨어를 어느 정도 제어할 수 있다.


- 프롬프트를 아주 조금만 바꿔도 매우 같은 출력이 나올 수 있다.


### 2. 환각

환각은 샘플링 과정만으로는 설명하기 어렵다. 어떤 아이디어가 학습 데이터에 있는지 역시 확인할 수 없기 때문에, 어디서 출력의 아이디어가 나왔는지 알 수 없다.

이는 **우리가 감당하지 못할 만큼의 복잡한 것을 만들어 낸 결과이고**, 이는 **축복이자 저주이다.**


### 환각이 나타나는 이유(가설)

따라서, 환각을 일으키는 이유에 대한 **가설**에 대해서만 알아보겠다.

**1. 언어 모델이 주어진 데이터와 자신이 생성한 데이터를 구분하지 못했기 때문이다.**

<p align="center">
  <img src="https://velog.velcdn.com/images/algorithm_cell/post/44ae4856-cfa4-4ebb-be8c-8b5bcaafdd08/image.png" />
<p align="center"> 자기기만 예시</p>

- 이러한 종류의 환각을 **자기 기만**이라고 한다.

추가적으로, 모델은 **자신의 잘못된 첫 가정을 정당화하기 위해 계속 환각**을 일으킨다.

![](https://velog.velcdn.com/images/algorithm_cell/post/97d85071-95cf-4f6f-8732-18252970dfa4/image.png)

**2. 모델의 내부 지식과 레이블러의 내부 지식이 일치하지 않기 때문이다.**

이론적으로 레이블러가 응답을 작성할 때 사용한 지식을 모델에게 같이 전달하면, 모델은 근거가 있는 응답인지 아닌지를 알게 되고, 모델이 자신이 알고 있는 정보만을 사용하도록 만들 수 있겠지만 이는 사실상 불가능에 가깝다.

<p align="center">1
  <img src="https://velog.velcdn.com/images/algorithm_cell/post/65c06f74-04e2-4f76-bff2-e9869b561cb7/image.png" />
<p align="center">RLHF와 SFT를 모두 사용하는 모델이 더 환각이 심한 예시</p>

### 3. 창의성

파운데이션 모델은 대규모 데이터셋으로부터 학습되기 때문에, 그 안에 다양한 가능성들이 담겨 있다. 또한 이는 수많은 사람의 의견과 관점이 반영된 결과이다. 



### 환각을 줄일 수 있는 방법

### 1번 문제에 대한 해결책

**1. 강화학습을 활용**해 모델이 **사용자가 제공한 프롬프트**와 **모델이 생성한 토큰**을 **구분하도록** 만든다.

**2. 지도학습을 활용**해 **학습 데이터에 사실과 반사실적 데이터를 모두 포함시킨다.**


### 2번 문제에 대한 해결책

자신이 아는 정보만을 바탕으로 응답하도록 강제한다.

**1. 응답에 대해 모델에게 응답의 근거가 되는 출처를 검색하도록 요청한다.**

**2. 강화학습을 활용**해 모델이 환각 현상을 보일 때 더 큰 불이익을 준다.

